{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45721903",
   "metadata": {},
   "source": [
    "# 05e - Vertex AI > Training > Training Pipelines - With Python Source Distribution\n",
    "\n",
    "### 05 Series Overview\n",
    "Where a model gets trained is where it consumes computing resources.  With Vertex AI, you have choices for configuring the computing resources available at training.  This notebook is an example of an execution environment.  When it was set up there were choices for machine type and accelerators (GPUs).  \n",
    "\n",
    "In the `05` notebook, the model training happened directly in the notebook.  The models were then imported to Vertex AI and deployed to an endpoint for online predictions. \n",
    "\n",
    "In this `05a-05i` series of demonstrations, the same model is trained using managed computing resources in Vertex AI as custom training jobs.  These jobs will be demonstrated as:\n",
    "\n",
    "-  Custom Job from a python script (`05a`), python source distribution (`05b`), and custom container (`05c`)\n",
    "-  Training Pipeline that trains and saves models from a python script (`05d`), python source distribution (`05e`), and custom container (`05f`)\n",
    "-  Hyperparameter Tuning Jobs from a python script (`05g`), python source distribution (`05h`), and custom container (`05i`)\n",
    "\n",
    "### This Notebook (`05e`): An extension of `05b` as a Training Pipeline that saves the model to Vertex AI > Models \n",
    "This notebook trains the same Tensorflow Keras model from `05` by first modifying and saving the training code to a python script (same as `05a`).  Then a Python source distribution is built containing the script.  While this example fits nicely in a single script, larger examples will benefit from the flexibility offered by source distributions and this notebook gives an example of making the shift. \n",
    "\n",
    "The source distribution is then used as an input for a Vertex AI > Training > Training Pipeline that is also assigned compute resources and a [pre-built container for custom training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers) for executing the training in a managed service.  This is done with the [Vertex AI Python SDK](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#) using the class [`aiplatform.CustomPythonPackageTrainingJob()`](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.CustomPythonPackageTrainingJob).\n",
    "\n",
    "The client used here is `aiplatform.CustomPythonPackageTrainingJob(python_package_gcs_uri=)` which is very similar to what was used for the source distribution in `05b` `aiplatform.CustomJob()`. The functional difference is that this method automatically uploads the final saved model to Vertex AI > Models.  Running the job this way first triggers a job in Vertex AI > Training > Training Pipeline.  This Training Pipeline triggers a Custom Job in Vertex AI > Training > Custom Jobs.  If The Custom Job completes successfully then the final saved model is registered in Vertex AI > Models.\n",
    "\n",
    "The training can be reviewed with Vertex AI's managed Tensorboard under Vertex AI > Experiments > Experiments, or by clicking on the `05e...` custom job under Vertex AI > Training > Custom Jobs and then clicking the 'Open Tensorboard' link. \n",
    "\n",
    "<p align=\"center\" width=\"100%\"><center><img src=\"../architectures/overview/training.png\" width=\"50%\"></center></p>\n",
    "\n",
    "### Prerequisites:\n",
    "-  01 - BigQuery - Table Data Source\n",
    "-  Understanding:\n",
    "    -  05 - Vertex AI > Notebooks - Models Built in Notebooks with Tensorflow\n",
    "        -  Contains a more granular review of the Tensorflow model training\n",
    "\n",
    "### Resources:\n",
    "-  [BigQuery Tensorflow Reader](https://www.tensorflow.org/io/tutorials/bigquery)\n",
    "-  [Keras Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)\n",
    "   -  [Keras API](https://www.tensorflow.org/api_docs/python/tf/keras)\n",
    "-  [Python Client For Google BigQuery](https://googleapis.dev/python/bigquery/latest/index.html)\n",
    "-  [Tensorflow Python Client](https://www.tensorflow.org/api_docs/python/tf)\n",
    "-  [Tensorflow I/O Python Client](https://www.tensorflow.org/io/api_docs/python/tfio/bigquery)\n",
    "-  [Python Client for Vertex AI](https://googleapis.dev/python/aiplatform/latest/aiplatform.html)\n",
    "-  [Create a Python source distribution](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container) for a Vertex AI custom training job\n",
    "-  Containers for training (Pre-Built)\n",
    "   -  [Overview](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container)\n",
    "   -  [List](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers)\n",
    "\n",
    "### Conceptual Flow & Workflow\n",
    "<p align=\"center\">\n",
    "  <img alt=\"Conceptual Flow\" src=\"../architectures/slides/05e_arch.png\" width=\"45%\">\n",
    "&nbsp; &nbsp; &nbsp; &nbsp;\n",
    "  <img alt=\"Workflow\" src=\"../architectures/slides/05e_console.png\" width=\"45%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b7e917",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752b96a1",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f0ed1ad-c3b2-413a-b788-b2275a027c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30ec57de",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = '05e'\n",
    "SERIES = '05'\n",
    "\n",
    "# source data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'fraud'\n",
    "BQ_TABLE = 'fraud_prepped'\n",
    "\n",
    "# Resources\n",
    "TRAIN_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-7:latest'\n",
    "DEPLOY_IMAGE ='us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest'\n",
    "TRAIN_COMPUTE = 'n1-standard-4'\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id' # add more variables to the string with space delimiters\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f91c78a",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c170ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca571c8",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66beb723",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bigquery = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9f6a3a",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2486e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = PROJECT_ID\n",
    "URI = f\"gs://{BUCKET}/{BQ_DATASET}/models/{SERIES}/{EXPERIMENT}\"\n",
    "DIR = f\"temp/{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26de5859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1026793852137-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Give service account roles/storage.objectAdmin permissions\n",
    "# Console > IMA > Select Account <projectnumber>-compute@developer.gserviceaccount.com > edit - give role\n",
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b465ba",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "371f830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed92d527-e55e-4b9c-aa62-71839d882fb8",
   "metadata": {},
   "source": [
    "Experiment Tracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "505895a9-be45-48a1-9e03-08c75fd292c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMEWORK = 'tf'\n",
    "TASK = 'classification'\n",
    "MODEL_TYPE = 'dnn'\n",
    "EXPERIMENT_NAME = f'experiment-{SERIES}-{EXPERIMENT}-{FRAMEWORK}-{TASK}-{MODEL_TYPE}'\n",
    "RUN_NAME = f'run-{TIMESTAMP}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730374eb-13fb-4e4f-a81b-5e7c92f85ba7",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Get Vertex AI Experiments Tensorboard Instance Name\n",
    "[Vertex AI Experiments](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview) has managed [Tensorboard](https://www.tensorflow.org/tensorboard) instances that you can track Tensorboard Experiments (a training run or hyperparameter tuning sweep).  \n",
    "\n",
    "The training job will show up as an experiment for the Tensorboard instance and have the same name as the training job ID.\n",
    "\n",
    "This code checks to see if a Tensorboard Instance has been created in the project, retrieves it if so, creates it otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98492615-c9ef-4e3d-ad7d-e63256e69548",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = aiplatform.Tensorboard.list(filter=f\"labels.series={SERIES}\")\n",
    "if tb:\n",
    "    tb = tb[0]\n",
    "else: \n",
    "    tb = aiplatform.Tensorboard.create(display_name = SERIES, labels = {'series' : f'{SERIES}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9593c67-525b-4767-adc9-ccb80a5f2ac8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/1026793852137/locations/us-central1/tensorboards/7179142426307592192'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb07b125-3f32-43a8-a14a-908a4e1ad2e3",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup Vertex AI Experiments\n",
    "\n",
    "The code in this section initializes the experiment and starts a run that represents this notebook.  Throughout the notebook sections for model training and evaluation information will be logged to the experiment using:\n",
    "- [.log_params](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_params)\n",
    "- [.log_metrics](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_metrics)\n",
    "- [.log_time_series_metrics](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_time_series_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "218ba499-a4b4-4872-8716-008be2c8f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(experiment = EXPERIMENT_NAME, experiment_tensorboard = tb.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2517acf",
   "metadata": {},
   "source": [
    "---\n",
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7518796-5a26-448a-a551-48062696d6af",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Assemble Python File for Training\n",
    "\n",
    "This is the training code from the notebook based training in `05` restructured as a Python Script that has parameter inputs and creates a Vertex AI Experiment run.\n",
    "\n",
    "Create the main python trainer file as `/train.py`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40841c7f-2946-49e4-8764-39ebcbc1828b",
   "metadata": {},
   "source": [
    "#### Review Pre-Built `05_train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f61f37c-9b4c-4607-a77d-7bddee725fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "# package import\n",
       "from tensorflow.python.framework import dtypes\n",
       "from tensorflow_io.bigquery import BigQueryClient\n",
       "import tensorflow as tf\n",
       "from google.cloud import bigquery\n",
       "from google.cloud import aiplatform\n",
       "import argparse\n",
       "import os\n",
       "import sys\n",
       "\n",
       "# import argument to local variables\n",
       "parser = argparse.ArgumentParser()\n",
       "# the passed param, dest: a name for the param, default: if absent fetch this param from the OS, type: type to convert to, help: description of argument\n",
       "parser.add_argument('--epochs', dest = 'epochs', default = 10, type = int, help = 'Number of Epochs')\n",
       "parser.add_argument('--batch_size', dest = 'batch_size', default = 32, type = int, help = 'Batch Size')\n",
       "parser.add_argument('--var_target', dest = 'var_target', type=str)\n",
       "parser.add_argument('--var_omit', dest = 'var_omit', type=str, nargs='*')\n",
       "parser.add_argument('--project_id', dest = 'project_id', type=str)\n",
       "parser.add_argument('--bq_project', dest = 'bq_project', type=str)\n",
       "parser.add_argument('--bq_dataset', dest = 'bq_dataset', type=str)\n",
       "parser.add_argument('--bq_table', dest = 'bq_table', type=str)\n",
       "parser.add_argument('--region', dest = 'region', type=str)\n",
       "parser.add_argument('--experiment', dest = 'experiment', type=str)\n",
       "parser.add_argument('--series', dest = 'series', type=str)\n",
       "parser.add_argument('--experiment_name', dest = 'experiment_name', type=str)\n",
       "parser.add_argument('--run_name', dest = 'run_name', type=str)\n",
       "args = parser.parse_args()\n",
       "\n",
       "# clients\n",
       "bigquery = bigquery.Client(project = args.project_id)\n",
       "aiplatform.init(project = args.project_id, location = args.region)\n",
       "\n",
       "# Vertex AI Experiment\n",
       "expRun = aiplatform.ExperimentRun.create(run_name = args.run_name, experiment = args.experiment_name)\n",
       "expRun.log_params({'experiment': args.experiment, 'series': args.series, 'project_id': args.project_id})\n",
       "\n",
       "# get schema from bigquery source\n",
       "query = f\"SELECT * FROM {args.bq_project}.{args.bq_dataset}.INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{args.bq_table}'\"\n",
       "schema = bigquery.query(query).to_dataframe()\n",
       "\n",
       "# get number of classes from bigquery source\n",
       "nclasses = bigquery.query(query = f'SELECT DISTINCT {args.var_target} FROM {args.bq_project}.{args.bq_dataset}.{args.bq_table} WHERE {args.var_target} is not null').to_dataframe()\n",
       "nclasses = nclasses.shape[0]\n",
       "expRun.log_params({'data_source': f'bq://{args.bq_project}.{args.bq_dataset}.{args.bq_table}', 'nclasses': nclasses, 'var_split': 'splits', 'var_target': args.var_target})\n",
       "\n",
       "# Make a list of columns to omit\n",
       "OMIT = args.var_omit + ['splits']\n",
       "\n",
       "# use schema to prepare a list of columns to read from BigQuery\n",
       "selected_fields = schema[~schema.column_name.isin(OMIT)].column_name.tolist()\n",
       "\n",
       "# all the columns in this data source are either float64 or int64\n",
       "output_types = [dtypes.float64 if x=='FLOAT64' else dtypes.int64 for x in schema[~schema.column_name.isin(OMIT)].data_type.tolist()]\n",
       "\n",
       "# remap input data to Tensorflow inputs of features and target\n",
       "def transTable(row_dict):\n",
       "    target = row_dict.pop(args.var_target)\n",
       "    target = tf.one_hot(tf.cast(target, tf.int64), nclasses)\n",
       "    target = tf.cast(target, tf.float32)\n",
       "    return(row_dict, target)\n",
       "\n",
       "# function to setup a bigquery reader with Tensorflow I/O\n",
       "def bq_reader(split):\n",
       "    reader = BigQueryClient()\n",
       "\n",
       "    training = reader.read_session(\n",
       "        parent = f\"projects/{args.project_id}\",\n",
       "        project_id = args.bq_project,\n",
       "        table_id = args.bq_table,\n",
       "        dataset_id = args.bq_dataset,\n",
       "        selected_fields = selected_fields,\n",
       "        output_types = output_types,\n",
       "        row_restriction = f\"splits='{split}'\",\n",
       "        requested_streams = 3\n",
       "    )\n",
       "    \n",
       "    return training\n",
       "\n",
       "# setup feed for train, validate and test\n",
       "train = bq_reader('TRAIN').parallel_read_rows().prefetch(1).map(transTable).shuffle(args.batch_size*10).batch(args.batch_size)\n",
       "validate = bq_reader('VALIDATE').parallel_read_rows().prefetch(1).map(transTable).batch(args.batch_size)\n",
       "test = bq_reader('TEST').parallel_read_rows().prefetch(1).map(transTable).batch(args.batch_size)\n",
       "expRun.log_params({'training.batch_size': args.batch_size, 'training.shuffle': 10*args.batch_size, 'training.prefetch': 1})\n",
       "                   \n",
       "# Logistic Regression\n",
       "\n",
       "# model input definitions\n",
       "feature_columns = {header: tf.feature_column.numeric_column(header) for header in selected_fields if header != args.var_target}\n",
       "feature_layer_inputs = {header: tf.keras.layers.Input(shape = (1,), name = header) for header in selected_fields if header != args.var_target}\n",
       "\n",
       "# feature columns to a Dense Feature Layer\n",
       "feature_layer_outputs = tf.keras.layers.DenseFeatures(feature_columns.values(), name = 'feature_layer')(feature_layer_inputs)\n",
       "\n",
       "# batch normalization then Dense with softmax activation to nclasses\n",
       "layers = tf.keras.layers.BatchNormalization(name = 'batch_normalization_layer')(feature_layer_outputs)\n",
       "layers = tf.keras.layers.Dense(64, activation = 'relu', name = 'hidden_layer')(layers)\n",
       "layers = tf.keras.layers.Dense(32, activation = 'relu', name = 'embedding_layer')(layers)\n",
       "layers = tf.keras.layers.Dense(nclasses, activation = tf.nn.softmax, name = 'prediction_layer')(layers)\n",
       "\n",
       "# the model\n",
       "model = tf.keras.Model(\n",
       "    inputs = feature_layer_inputs,\n",
       "    outputs = layers,\n",
       "    name = args.experiment\n",
       ")\n",
       "opt = tf.keras.optimizers.SGD() #SGD or Adam\n",
       "loss = tf.keras.losses.CategoricalCrossentropy()\n",
       "model.compile(\n",
       "    optimizer = opt,\n",
       "    loss = loss,\n",
       "    metrics = ['accuracy', tf.keras.metrics.AUC(curve='PR', name = 'auprc')]\n",
       ")\n",
       "\n",
       "# setup tensorboard logs and train\n",
       "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=os.environ['AIP_TENSORBOARD_LOG_DIR'], histogram_freq=1)\n",
       "history = model.fit(train, epochs = args.epochs, callbacks = [tensorboard_callback], validation_data = validate)\n",
       "expRun.log_params({'training.epochs': history.params['epochs']})\n",
       "for e in range(0, history.params['epochs']):\n",
       "    expRun.log_time_series_metrics(\n",
       "        {\n",
       "            'train_loss': history.history['loss'][e],\n",
       "            'train_accuracy': history.history['accuracy'][e],\n",
       "            'train_auprc': history.history['auprc'][e],\n",
       "            'val_loss': history.history['val_loss'][e],\n",
       "            'val_accuracy': history.history['val_accuracy'][e],\n",
       "            'val_auprc': history.history['val_auprc'][e]\n",
       "        }\n",
       "    )\n",
       "\n",
       "# evaluations:\n",
       "loss, accuracy, auprc = model.evaluate(test)\n",
       "expRun.log_metrics({'test_loss': loss, 'test_accuracy': accuracy, 'test_auprc': auprc})\n",
       "loss, accuracy, auprc = model.evaluate(validate)\n",
       "expRun.log_metrics({'val_loss': loss, 'val_accuracy': accuracy, 'val_auprc': auprc})\n",
       "loss, accuracy, auprc = model.evaluate(train)\n",
       "expRun.log_metrics({'train_loss': loss, 'train_accuracy': accuracy, 'train_auprc': auprc})\n",
       "\n",
       "# output the model save files\n",
       "model.save(os.getenv(\"AIP_MODEL_DIR\"))\n",
       "expRun.log_params({'model.save': os.getenv(\"AIP_MODEL_DIR\")})\n",
       "expRun.end_run()\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "with open(f'05_train.py', 'r') as file:\n",
    "    data = file.read()\n",
    "md(\"```python\" + data + \"```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04f1e20-6ff5-4878-b3fc-c8051c4e4dcc",
   "metadata": {},
   "source": [
    "#### Copy Script to This Experiment\n",
    "\n",
    "Create the main python trainer file as `/train.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82a3afcc-654b-4754-ad35-1b5efe3dea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {DIR}/source/trainer\n",
    "!cp 05_train.py {DIR}/source/trainer/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dcae82",
   "metadata": {},
   "source": [
    "### Assemble Python Source Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f6c306",
   "metadata": {},
   "source": [
    "create `setup.py` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df799abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "setupfile = f\"\"\"from setuptools import setup\n",
    "from setuptools import find_packages\n",
    "\n",
    "REQUIRED_PACKAGES = ['tensorflow_io', 'google-cloud-aiplatform>={aiplatform.__version__}']\n",
    "\n",
    "setup(\n",
    "    name = 'trainer',\n",
    "    version = '0.1',\n",
    "    install_requires = REQUIRED_PACKAGES, \n",
    "    packages = find_packages(),\n",
    "    include_package_data = True,\n",
    "    description='Training Package'\n",
    ")\n",
    "\"\"\"\n",
    "with open(f'{DIR}/source/setup.py', 'w') as f:\n",
    "    f.write(setupfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a1cb9",
   "metadata": {},
   "source": [
    "add `__init__.py` file to the trainer modules folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94134421",
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch {DIR}/source/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71fd136",
   "metadata": {},
   "source": [
    "Create the source distribution and copy it to the projects storage bucket:\n",
    "- change to the local direcory with the source folder\n",
    "- remove any previous distributions\n",
    "- tar and gzip the source folder\n",
    "- copy the distribution to the project folder on GCS\n",
    "- change back to the local project directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2cda78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/vertex-ai-mlops/05 - TensorFlow/temp/05e\n",
      "source/\n",
      "source/setup.py\n",
      "source/trainer/\n",
      "source/trainer/__init__.py\n",
      "source/trainer/train.py\n",
      "Copying file://source.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  2.6 KiB/  2.6 KiB]                                                \n",
      "Operation completed over 1 objects/2.6 KiB.                                      \n",
      "/home/jupyter/vertex-ai-mlops/05 - TensorFlow\n"
     ]
    }
   ],
   "source": [
    "%cd {DIR}\n",
    "\n",
    "!rm -f source.tar source.tar.gz\n",
    "!tar cvf source.tar source\n",
    "!gzip source.tar\n",
    "!gsutil cp source.tar.gz {URI}/{TIMESTAMP}/source.tar.gz\n",
    "\n",
    "temp = '../'*(DIR.count('/')+1)\n",
    "%cd {temp}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d30ca0",
   "metadata": {},
   "source": [
    "### Setup Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a7c3d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMDARGS = [\n",
    "    \"--epochs=\" + str(EPOCHS),\n",
    "    \"--batch_size=\" + str(BATCH_SIZE),\n",
    "    \"--var_target=\" + VAR_TARGET,\n",
    "    \"--var_omit=\" + VAR_OMIT,\n",
    "    \"--project_id=\" + PROJECT_ID,\n",
    "    \"--bq_project=\" + BQ_PROJECT,\n",
    "    \"--bq_dataset=\" + BQ_DATASET,\n",
    "    \"--bq_table=\" + BQ_TABLE,\n",
    "    \"--region=\" + REGION,\n",
    "    \"--experiment=\" + EXPERIMENT,\n",
    "    \"--series=\" + SERIES,\n",
    "    \"--experiment_name=\" + EXPERIMENT_NAME,\n",
    "    \"--run_name=\" + RUN_NAME\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2f6a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingJob = aiplatform.CustomPythonPackageTrainingJob(\n",
    "    display_name = f'{EXPERIMENT}_{BQ_DATASET}_{TIMESTAMP}',\n",
    "    python_package_gcs_uri = f\"{URI}/{TIMESTAMP}/source.tar.gz\",\n",
    "    python_module_name = \"trainer.train\",\n",
    "    container_uri = TRAIN_IMAGE,\n",
    "    model_serving_container_image_uri = DEPLOY_IMAGE,\n",
    "    staging_bucket = f\"{URI}/{TIMESTAMP}\",\n",
    "    labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d5166",
   "metadata": {},
   "source": [
    "### Run Training Job AND Upload The Model\n",
    "The training job will automatically upload the model to the Vertex AI Model Registy and return the link to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed9b1dd5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Already in Registry:\n",
      "Loading model as new default version.\n",
      "Training Output directory:\n",
      "gs://statmike-mlops-349915/fraud/models/05/05e/20220827025727 \n",
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/7074947481779306496?project=1026793852137\n",
      "CustomPythonPackageTrainingJob projects/1026793852137/locations/us-central1/trainingPipelines/7074947481779306496 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "View backing custom job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/3390433439567052800?project=1026793852137\n",
      "View tensorboard:\n",
      "https://us-central1.tensorboard.googleusercontent.com/experiment/projects+1026793852137+locations+us-central1+tensorboards+7179142426307592192+experiments+3390433439567052800\n",
      "CustomPythonPackageTrainingJob projects/1026793852137/locations/us-central1/trainingPipelines/7074947481779306496 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomPythonPackageTrainingJob projects/1026793852137/locations/us-central1/trainingPipelines/7074947481779306496 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomPythonPackageTrainingJob projects/1026793852137/locations/us-central1/trainingPipelines/7074947481779306496 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomPythonPackageTrainingJob projects/1026793852137/locations/us-central1/trainingPipelines/7074947481779306496 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomPythonPackageTrainingJob projects/1026793852137/locations/us-central1/trainingPipelines/7074947481779306496 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomPythonPackageTrainingJob run completed. Resource name: projects/1026793852137/locations/us-central1/trainingPipelines/7074947481779306496\n",
      "Model available at projects/1026793852137/locations/us-central1/models/model_05e_fraud_2\n"
     ]
    }
   ],
   "source": [
    "modelmatch = aiplatform.Model.list(filter = f'labels.series={SERIES} AND labels.experiment={EXPERIMENT}')\n",
    "if modelmatch:\n",
    "    print(\"Model Already in Registry:\")\n",
    "    if RUN_NAME in modelmatch[0].version_aliases:\n",
    "        print(\"This version already loaded, no action taken.\")\n",
    "        model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n",
    "    else:\n",
    "        print('Loading model as new default version.')\n",
    "        model = trainingJob.run(\n",
    "            model_display_name = f'{EXPERIMENT}_{BQ_DATASET}',\n",
    "            model_labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'},\n",
    "            model_id = f'model_{EXPERIMENT}_{BQ_DATASET}',\n",
    "            parent_model = modelmatch[0].resource_name,\n",
    "            is_default_version = True,\n",
    "            model_version_aliases = [RUN_NAME],\n",
    "            model_version_description = RUN_NAME,\n",
    "            base_output_dir = f\"{URI}/{TIMESTAMP}\",\n",
    "            service_account = SERVICE_ACCOUNT,\n",
    "            args = CMDARGS,\n",
    "            replica_count = 1,\n",
    "            machine_type = TRAIN_COMPUTE,\n",
    "            accelerator_count = 0,\n",
    "            tensorboard = tb.resource_name\n",
    "        )\n",
    "else:\n",
    "    print('This is a new model, creating in model registry')\n",
    "    model = trainingJob.run(\n",
    "        model_display_name = f'{EXPERIMENT}_{BQ_DATASET}',\n",
    "        model_labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'},\n",
    "        model_id = f'model_{EXPERIMENT}_{BQ_DATASET}',\n",
    "        is_default_version = True,\n",
    "        model_version_aliases = [RUN_NAME],\n",
    "        model_version_description = RUN_NAME,\n",
    "        base_output_dir = f\"{URI}/{TIMESTAMP}\",\n",
    "        service_account = SERVICE_ACCOUNT,\n",
    "        args = CMDARGS,\n",
    "        replica_count = 1,\n",
    "        machine_type = TRAIN_COMPUTE,\n",
    "        accelerator_count = 0,\n",
    "        tensorboard = tb.resource_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bd4c1f-2013-4968-9f2b-b07a9dc10c01",
   "metadata": {},
   "source": [
    "Get the backing Custom Job for the Training Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47f7697b-c2f3-4f2c-9e3b-3db869a03c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "clientPL = aiplatform.gapic.PipelineServiceClient(client_options = {'api_endpoint': f'{REGION}-aiplatform.googleapis.com'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7fd024b-f7e1-4805-8a10-7aa6b827b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf.json_format import MessageToDict\n",
    "\n",
    "backingCustomJob = MessageToDict(clientPL.get_training_pipeline(name = trainingJob.resource_name)._pb)['trainingTaskMetadata']['backingCustomJob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1757724f-095f-41e5-aa80-d4f11ac31568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('projects/1026793852137/locations/us-central1/customJobs/3390433439567052800',\n",
       " '05e_fraud_20220827025727-custom-job')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customJob = aiplatform.CustomJob.get(backingCustomJob)\n",
    "customJob.resource_name, customJob.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff0daa0-93db-48fc-b3d3-75075c02484d",
   "metadata": {},
   "source": [
    "Create hyperlinks to job and tensorboard here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50b0944f-73f4-456b-905c-c5a80b51806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_link = f\"https://console.cloud.google.com/vertex-ai/locations/{REGION}/training/{customJob.resource_name.split('/')[-1]}/cpu?cloudshell=false&project={PROJECT_ID}\"\n",
    "board_link = f\"https://{REGION}.tensorboard.googleusercontent.com/experiment/{tb.resource_name.replace('/', '+')}+experiments+{customJob.name.split('/')[-1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b374a3f5-2f2a-4a03-b5af-d8b7f7a55ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the Job here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/training/3390433439567052800/cpu?cloudshell=false&project=statmike-mlops-349915\n",
      "Review the TensorBoard From the Job here:\n",
      "https://us-central1.tensorboard.googleusercontent.com/experiment/projects+1026793852137+locations+us-central1+tensorboards+7179142426307592192+experiments+3390433439567052800\n"
     ]
    }
   ],
   "source": [
    "print(f'Review the Job here:\\n{job_link}')\n",
    "print(f'Review the TensorBoard From the Job here:\\n{board_link}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc02a2b6",
   "metadata": {},
   "source": [
    "---\n",
    "## Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c27ed6-ff52-47a7-8e34-3fb1aaa5e235",
   "metadata": {},
   "source": [
    "### Vertex AI Experiment Update and Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d35467ee-5ea5-4423-ac21-ba0881598166",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun = aiplatform.ExperimentRun(run_name = RUN_NAME, experiment = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d947289-5c62-4feb-9d0a-8429c742b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun.log_params({\n",
    "    'model.uri': model.uri,\n",
    "    'model.display_name': model.display_name,\n",
    "    'model.resource_name': model.resource_name,\n",
    "    'model.version_id': model.version_id,\n",
    "    'model.versioned_resource_name': model.versioned_resource_name,\n",
    "    'trainingPipelines.display_name': trainingJob.display_name,\n",
    "    'trainingPipelines.resource_name': trainingJob.resource_name,\n",
    "    'customJobs.display_name': customJob.display_name,\n",
    "    'customJobs.resource_name': customJob.resource_name,\n",
    "    'customJobs.link': job_link,\n",
    "    'customJobs.tensorboard': board_link\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da31e5a0-1570-4714-82c3-3fb0c833db3f",
   "metadata": {},
   "source": [
    "Complete the experiment run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4134d53-cea2-42da-a4d6-b6c71e835b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun.update_state(state = aiplatform.gapic.Execution.State.COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d17ccfe-5942-4dcb-b06a-d2ba8c270d2c",
   "metadata": {},
   "source": [
    "Retrieve the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57b4e1d3-9836-4aac-9286-c0a07d4ccdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = aiplatform.Experiment(experiment_name = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65d603e1-b034-4469-a245-de9ab1334d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>run_type</th>\n",
       "      <th>state</th>\n",
       "      <th>param.training.batch_size</th>\n",
       "      <th>param.trainingPipelines.display_name</th>\n",
       "      <th>param.training.prefetch</th>\n",
       "      <th>param.customJobs.display_name</th>\n",
       "      <th>param.training.epochs</th>\n",
       "      <th>param.experiment</th>\n",
       "      <th>...</th>\n",
       "      <th>metric.val_accuracy</th>\n",
       "      <th>metric.train_loss</th>\n",
       "      <th>metric.train_auprc</th>\n",
       "      <th>metric.test_accuracy</th>\n",
       "      <th>time_series_metric.train_auprc</th>\n",
       "      <th>time_series_metric.train_accuracy</th>\n",
       "      <th>time_series_metric.val_loss</th>\n",
       "      <th>time_series_metric.val_auprc</th>\n",
       "      <th>time_series_metric.train_loss</th>\n",
       "      <th>time_series_metric.val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experiment-05-05e-tf-classification-dnn</td>\n",
       "      <td>run-20220827025727</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>100.0</td>\n",
       "      <td>05e_fraud_20220827025727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>05e_fraud_20220827025727-custom-job</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05e</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>0.999605</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999686</td>\n",
       "      <td>0.999417</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.999625</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>0.999256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>experiment-05-05e-tf-classification-dnn</td>\n",
       "      <td>run-20220826174636</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>100.0</td>\n",
       "      <td>05e_fraud_20220826174636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>05e_fraud_20220826174636-custom-job</td>\n",
       "      <td>10.0</td>\n",
       "      <td>05e</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.004351</td>\n",
       "      <td>0.999569</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999692</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.999256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           experiment_name            run_name  \\\n",
       "0  experiment-05-05e-tf-classification-dnn  run-20220827025727   \n",
       "1  experiment-05-05e-tf-classification-dnn  run-20220826174636   \n",
       "\n",
       "               run_type     state  param.training.batch_size  \\\n",
       "0  system.ExperimentRun  COMPLETE                      100.0   \n",
       "1  system.ExperimentRun  COMPLETE                      100.0   \n",
       "\n",
       "  param.trainingPipelines.display_name  param.training.prefetch  \\\n",
       "0             05e_fraud_20220827025727                      1.0   \n",
       "1             05e_fraud_20220826174636                      1.0   \n",
       "\n",
       "         param.customJobs.display_name  param.training.epochs  \\\n",
       "0  05e_fraud_20220827025727-custom-job                   10.0   \n",
       "1  05e_fraud_20220826174636-custom-job                   10.0   \n",
       "\n",
       "  param.experiment  ...  metric.val_accuracy metric.train_loss  \\\n",
       "0              05e  ...             0.999256          0.003671   \n",
       "1              05e  ...             0.999256          0.004351   \n",
       "\n",
       "  metric.train_auprc metric.test_accuracy time_series_metric.train_auprc  \\\n",
       "0           0.999605             0.999404                       0.999686   \n",
       "1           0.999569             0.999404                       0.999692   \n",
       "\n",
       "   time_series_metric.train_accuracy time_series_metric.val_loss  \\\n",
       "0                           0.999417                    0.004981   \n",
       "1                           0.999408                    0.005863   \n",
       "\n",
       "  time_series_metric.val_auprc time_series_metric.train_loss  \\\n",
       "0                     0.999625                      0.003324   \n",
       "1                     0.999623                      0.003218   \n",
       "\n",
       "  time_series_metric.val_accuracy  \n",
       "0                        0.999256  \n",
       "1                        0.999256  \n",
       "\n",
       "[2 rows x 42 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.get_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203610f1-fc41-4e06-b4b7-666ee1eccd92",
   "metadata": {},
   "source": [
    "Review the Experiments TensorBoard to compare runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ce18389-8484-4d5d-a30e-c4841eb52e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Experiment TensorBoard Link:\n",
      "https://us-central1.tensorboard.googleusercontent.com/experiment/projects+1026793852137+locations+us-central1+tensorboards+7179142426307592192+experiments+experiment-05-05e-tf-classification-dnn\n"
     ]
    }
   ],
   "source": [
    "print(f\"The Experiment TensorBoard Link:\\nhttps://{REGION}.tensorboard.googleusercontent.com/experiment/{tb.resource_name.replace('/', '+')}+experiments+{exp.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37b9fded-da22-4c24-8d8c-54fefb07e1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>train_auprc</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_auprc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-08-27 03:06:04.700000+00:00</td>\n",
       "      <td>0.998828</td>\n",
       "      <td>0.994471</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>0.999339</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>0.998938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-08-27 03:06:04.832000+00:00</td>\n",
       "      <td>0.999586</td>\n",
       "      <td>0.999162</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>0.999186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-08-27 03:06:04.896000+00:00</td>\n",
       "      <td>0.999606</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>0.999529</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>0.999221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-08-27 03:06:04.964000+00:00</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>0.999338</td>\n",
       "      <td>0.005718</td>\n",
       "      <td>0.999530</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.999256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-08-27 03:06:05.038000+00:00</td>\n",
       "      <td>0.999621</td>\n",
       "      <td>0.999355</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.999578</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.999256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2022-08-27 03:06:05.145000+00:00</td>\n",
       "      <td>0.999656</td>\n",
       "      <td>0.999364</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.999578</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.999256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2022-08-27 03:06:05.227000+00:00</td>\n",
       "      <td>0.999639</td>\n",
       "      <td>0.999364</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>0.999625</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.999256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2022-08-27 03:06:05.296000+00:00</td>\n",
       "      <td>0.999685</td>\n",
       "      <td>0.999364</td>\n",
       "      <td>0.005123</td>\n",
       "      <td>0.999625</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>0.999256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2022-08-27 03:06:05.366000+00:00</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>0.999382</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>0.999625</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>0.999256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2022-08-27 03:06:05.460000+00:00</td>\n",
       "      <td>0.999686</td>\n",
       "      <td>0.999417</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.999625</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>0.999256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step                        wall_time  train_auprc  train_accuracy  \\\n",
       "0     1 2022-08-27 03:06:04.700000+00:00     0.998828        0.994471   \n",
       "1     2 2022-08-27 03:06:04.832000+00:00     0.999586        0.999162   \n",
       "2     3 2022-08-27 03:06:04.896000+00:00     0.999606        0.999316   \n",
       "3     4 2022-08-27 03:06:04.964000+00:00     0.999609        0.999338   \n",
       "4     5 2022-08-27 03:06:05.038000+00:00     0.999621        0.999355   \n",
       "5     6 2022-08-27 03:06:05.145000+00:00     0.999656        0.999364   \n",
       "6     7 2022-08-27 03:06:05.227000+00:00     0.999639        0.999364   \n",
       "7     8 2022-08-27 03:06:05.296000+00:00     0.999685        0.999364   \n",
       "8     9 2022-08-27 03:06:05.366000+00:00     0.999663        0.999382   \n",
       "9    10 2022-08-27 03:06:05.460000+00:00     0.999686        0.999417   \n",
       "\n",
       "   val_loss  val_auprc  train_loss  val_accuracy  \n",
       "0  0.007795   0.999339    0.024887      0.998938  \n",
       "1  0.006418   0.999475    0.005120      0.999186  \n",
       "2  0.006013   0.999529    0.004341      0.999221  \n",
       "3  0.005718   0.999530    0.004131      0.999256  \n",
       "4  0.005501   0.999578    0.003990      0.999256  \n",
       "5  0.005375   0.999578    0.003791      0.999256  \n",
       "6  0.005240   0.999625    0.003705      0.999256  \n",
       "7  0.005123   0.999625    0.003554      0.999256  \n",
       "8  0.005031   0.999625    0.003450      0.999256  \n",
       "9  0.004981   0.999625    0.003324      0.999256  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expRun.get_time_series_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126bfdad-d07d-4d9d-99e5-66b738696c11",
   "metadata": {},
   "source": [
    "### Compare This Run Using Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f07dd-8a84-43b1-bd6f-f9ee29ca97d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Get a list of all experiments in this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb42949a-a4ab-4ef0-b163-ce89d2b58c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = aiplatform.Experiment.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9328219-b085-436d-8be8-f68412acc45f",
   "metadata": {},
   "source": [
    "Remove experiments not in the SERIES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9fd9424-3b50-4921-868e-e08eb6e2c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [e for e in experiments if e.name.split('-')[0:2] == ['experiment', SERIES]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80593d05-e6e5-465d-ab7e-4467f45dadae",
   "metadata": {},
   "source": [
    "Combine the runs from all experiments in SERIES into a single dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb7352f4-d50a-43c1-a342-a15ba06b1ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment-05-05i-tf-classification-dnn\n",
      "experiment-05-05h-tf-classification-dnn\n",
      "experiment-05-05g-tf-classification-dnn\n",
      "experiment-05-05f-tf-classification-dnn\n",
      "experiment-05-05e-tf-classification-dnn\n",
      "experiment-05-05d-tf-classification-dnn\n",
      "experiment-05-05c-tf-classification-dnn\n",
      "experiment-05-05b-tf-classification-dnn\n",
      "experiment-05-05a-tf-classification-dnn\n",
      "experiment-05-05-tf-classification-dnn\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for experiment in experiments:\n",
    "        results.append(experiment.get_data_frame())\n",
    "        print(experiment.name)\n",
    "results = pd.concat(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1d6415-e38a-4f67-a333-66d944d4c571",
   "metadata": {},
   "source": [
    "Create ranks for models within experiment and across the entire SERIES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7cd876a4-7984-4687-b42b-c829952c2ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.model.display_name</th>\n",
       "      <th>param.model.version_id</th>\n",
       "      <th>metric.test_auprc</th>\n",
       "      <th>series_rank</th>\n",
       "      <th>experiment_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20220825143943</td>\n",
       "      <td>05_fraud</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999398</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20220825161109</td>\n",
       "      <td>05_fraud</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999397</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20220825175329</td>\n",
       "      <td>05_fraud</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999344</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>experiment-05-05-tf-classification-dnn</td>\n",
       "      <td>run-20220827023100</td>\n",
       "      <td>05_fraud</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>experiment-05-05a-tf-classification-dnn</td>\n",
       "      <td>run-20220826104731</td>\n",
       "      <td>05a_fraud</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>experiment-05-05i-tf-classification-dnn</td>\n",
       "      <td>run-20220826194138-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999628</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>experiment-05-05i-tf-classification-dnn</td>\n",
       "      <td>run-20220826194138-6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999629</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>experiment-05-05i-tf-classification-dnn</td>\n",
       "      <td>run-20220826194138-7</td>\n",
       "      <td>05i_fraud</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>experiment-05-05i-tf-classification-dnn</td>\n",
       "      <td>run-20220826194138-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999628</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>experiment-05-05i-tf-classification-dnn</td>\n",
       "      <td>run-20220826194138-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999673</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            experiment_name              run_name  \\\n",
       "63   experiment-05-05-tf-classification-dnn    run-20220825143943   \n",
       "62   experiment-05-05-tf-classification-dnn    run-20220825161109   \n",
       "61   experiment-05-05-tf-classification-dnn    run-20220825175329   \n",
       "60   experiment-05-05-tf-classification-dnn    run-20220827023100   \n",
       "59  experiment-05-05a-tf-classification-dnn    run-20220826104731   \n",
       "..                                      ...                   ...   \n",
       "12  experiment-05-05i-tf-classification-dnn  run-20220826194138-5   \n",
       "11  experiment-05-05i-tf-classification-dnn  run-20220826194138-6   \n",
       "17  experiment-05-05i-tf-classification-dnn  run-20220826194138-7   \n",
       "10  experiment-05-05i-tf-classification-dnn  run-20220826194138-8   \n",
       "9   experiment-05-05i-tf-classification-dnn  run-20220826194138-9   \n",
       "\n",
       "   param.model.display_name param.model.version_id  metric.test_auprc  \\\n",
       "63                 05_fraud                      1           0.999398   \n",
       "62                 05_fraud                      2           0.999397   \n",
       "61                 05_fraud                      3           0.999344   \n",
       "60                 05_fraud                      4           0.999394   \n",
       "59                05a_fraud                      1           0.999627   \n",
       "..                      ...                    ...                ...   \n",
       "12                      NaN                    NaN           0.999628   \n",
       "11                      NaN                    NaN           0.999629   \n",
       "17                05i_fraud                      1           0.999812   \n",
       "10                      NaN                    NaN           0.999628   \n",
       "9                       NaN                    NaN           0.999673   \n",
       "\n",
       "    series_rank  experiment_rank  \n",
       "63         45.0              1.0  \n",
       "62         46.0              2.0  \n",
       "61         55.0              4.0  \n",
       "60         49.0              3.0  \n",
       "59         31.0              1.0  \n",
       "..          ...              ...  \n",
       "12         25.0              9.0  \n",
       "11         20.0              6.0  \n",
       "17          1.0              1.0  \n",
       "10         24.0              8.0  \n",
       "9          15.0              5.0  \n",
       "\n",
       "[64 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ranker(metric = 'metric.test_auprc'):\n",
    "    ranks = results[['experiment_name', 'run_name', 'param.model.display_name', 'param.model.version_id', metric]].copy().reset_index(drop = True)\n",
    "    ranks['series_rank'] = ranks[metric].rank(method = 'dense', ascending = False)\n",
    "    ranks['experiment_rank'] = ranks.groupby('experiment_name')[metric].rank(method = 'dense', ascending = False)\n",
    "    return ranks.sort_values(by = ['experiment_name', 'run_name'])\n",
    "    \n",
    "ranks = ranker('metric.test_auprc')\n",
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dae6903c-1986-47f8-b1e7-f05777ca6fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.model.display_name</th>\n",
       "      <th>param.model.version_id</th>\n",
       "      <th>metric.test_auprc</th>\n",
       "      <th>series_rank</th>\n",
       "      <th>experiment_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>experiment-05-05e-tf-classification-dnn</td>\n",
       "      <td>run-20220827025727</td>\n",
       "      <td>05e_fraud</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999628</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            experiment_name            run_name  \\\n",
       "50  experiment-05-05e-tf-classification-dnn  run-20220827025727   \n",
       "\n",
       "   param.model.display_name param.model.version_id  metric.test_auprc  \\\n",
       "50                05e_fraud                      2           0.999628   \n",
       "\n",
       "    series_rank  experiment_rank  \n",
       "50         28.0              1.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_rank = ranks.loc[(ranks['param.model.display_name'] == model.display_name) & (ranks['param.model.version_id'] == model.version_id)]\n",
    "current_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e45ccb7-8f93-4c12-9b7d-666fd8fa238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current model is ranked 1.0 within this experiment and 28.0 across this series.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The current model is ranked {current_rank['experiment_rank'].iloc[0]} within this experiment and {current_rank['series_rank'].iloc[0]} across this series.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c33a3c-a8ce-4548-8249-3e4fd29d0ba7",
   "metadata": {},
   "source": [
    "### Create/Retrieve The Endpoint For This Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cc28d98-b525-4385-9b95-489bf574f967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Exists: projects/1026793852137/locations/us-central1/endpoints/4573537362990071808\n"
     ]
    }
   ],
   "source": [
    "endpoints = aiplatform.Endpoint.list(filter = f\"labels.series={SERIES}\")\n",
    "if endpoints:\n",
    "    endpoint = endpoints[0]\n",
    "    print(f\"Endpoint Exists: {endpoints[0].resource_name}\")\n",
    "else:\n",
    "    endpoint = aiplatform.Endpoint.create(\n",
    "        display_name = f\"{SERIES}_{BQ_DATASET}\",\n",
    "        labels = {'series' : f\"{SERIES}\"}    \n",
    "    )\n",
    "    print(f\"Endpoint Created: {endpoint.resource_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a538bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05_fraud'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a0029bd-9744-4449-91f0-56ef7ca5e535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5475220460650102784': 100}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85d06eba-82dc-4d50-8405-800d756e3584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"5475220460650102784\"\n",
       " model: \"projects/1026793852137/locations/us-central1/models/model_05i_fraud\"\n",
       " display_name: \"05i_fraud\"\n",
       " create_time {\n",
       "   seconds: 1661565734\n",
       "   nanos: 379696000\n",
       " }\n",
       " dedicated_resources {\n",
       "   machine_spec {\n",
       "     machine_type: \"n1-standard-4\"\n",
       "   }\n",
       "   min_replica_count: 1\n",
       "   max_replica_count: 1\n",
       " }\n",
       " explanation_spec {\n",
       "   parameters {\n",
       "     integrated_gradients_attribution {\n",
       "       step_count: 50\n",
       "     }\n",
       "   }\n",
       "   metadata {\n",
       "     inputs {\n",
       "       key: \"Amount\"\n",
       "       value {\n",
       "         input_tensor_name: \"Amount\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"Time\"\n",
       "       value {\n",
       "         input_tensor_name: \"Time\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V1\"\n",
       "       value {\n",
       "         input_tensor_name: \"V1\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V10\"\n",
       "       value {\n",
       "         input_tensor_name: \"V10\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V11\"\n",
       "       value {\n",
       "         input_tensor_name: \"V11\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V12\"\n",
       "       value {\n",
       "         input_tensor_name: \"V12\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V13\"\n",
       "       value {\n",
       "         input_tensor_name: \"V13\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V14\"\n",
       "       value {\n",
       "         input_tensor_name: \"V14\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V15\"\n",
       "       value {\n",
       "         input_tensor_name: \"V15\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V16\"\n",
       "       value {\n",
       "         input_tensor_name: \"V16\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V17\"\n",
       "       value {\n",
       "         input_tensor_name: \"V17\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V18\"\n",
       "       value {\n",
       "         input_tensor_name: \"V18\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V19\"\n",
       "       value {\n",
       "         input_tensor_name: \"V19\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V2\"\n",
       "       value {\n",
       "         input_tensor_name: \"V2\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V20\"\n",
       "       value {\n",
       "         input_tensor_name: \"V20\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V21\"\n",
       "       value {\n",
       "         input_tensor_name: \"V21\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V22\"\n",
       "       value {\n",
       "         input_tensor_name: \"V22\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V23\"\n",
       "       value {\n",
       "         input_tensor_name: \"V23\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V24\"\n",
       "       value {\n",
       "         input_tensor_name: \"V24\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V25\"\n",
       "       value {\n",
       "         input_tensor_name: \"V25\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V26\"\n",
       "       value {\n",
       "         input_tensor_name: \"V26\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V27\"\n",
       "       value {\n",
       "         input_tensor_name: \"V27\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V28\"\n",
       "       value {\n",
       "         input_tensor_name: \"V28\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V3\"\n",
       "       value {\n",
       "         input_tensor_name: \"V3\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V4\"\n",
       "       value {\n",
       "         input_tensor_name: \"V4\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V5\"\n",
       "       value {\n",
       "         input_tensor_name: \"V5\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V6\"\n",
       "       value {\n",
       "         input_tensor_name: \"V6\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V7\"\n",
       "       value {\n",
       "         input_tensor_name: \"V7\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V8\"\n",
       "       value {\n",
       "         input_tensor_name: \"V8\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V9\"\n",
       "       value {\n",
       "         input_tensor_name: \"V9\"\n",
       "       }\n",
       "     }\n",
       "     outputs {\n",
       "       key: \"prediction_layer\"\n",
       "       value {\n",
       "         output_tensor_name: \"prediction_layer\"\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " model_version_id: \"1\"]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_models = endpoint.list_models()\n",
    "deployed_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed5350c-bb04-4b36-8afa-5b91e0baf6f3",
   "metadata": {},
   "source": [
    "### Should This Model Be Deployed?\n",
    "Is it better than the model already deployed on the endpoint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5db9b246-2b03-4313-b620-5fc8029280b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current model is ranked worse (28.0) than a currently deployed model (1.0)\n"
     ]
    }
   ],
   "source": [
    "deploy = False\n",
    "if deployed_models:\n",
    "    for deployed_model in deployed_models:\n",
    "        deployed_rank = ranks.loc[(ranks['param.model.display_name'] == deployed_model.display_name) & (ranks['param.model.version_id'] == deployed_model.model_version_id)]['series_rank'].iloc[0]\n",
    "        model_rank = current_rank['series_rank'].iloc[0]\n",
    "        if deployed_model.display_name == model.display_name and deployed_model.model_version_id == model.version_id:\n",
    "            print(f'The current model/version is already deployed.')\n",
    "            break\n",
    "        elif model_rank <= deployed_rank:\n",
    "            deploy = True\n",
    "            print(f'The current model is ranked better ({model_rank}) than a currently deployed model ({deployed_rank}).')\n",
    "            break\n",
    "    if deploy == False: print(f'The current model is ranked worse ({model_rank}) than a currently deployed model ({deployed_rank})')\n",
    "else: \n",
    "    deply = True\n",
    "    print('No models currently deployed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81269f1c-16ad-4428-aa14-d2bbfa553227",
   "metadata": {},
   "source": [
    "### Deploy Model To Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2aa50205-0f93-423e-a622-4659f81e8674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not deploying - current model is worse (28.0) than the currently deployed model (1.0)\n"
     ]
    }
   ],
   "source": [
    "if deploy:\n",
    "    print(f'Deploying model with 100% of traffic...')\n",
    "    endpoint.deploy(\n",
    "        model = model,\n",
    "        deployed_model_display_name = model.display_name,\n",
    "        traffic_percentage = 100,\n",
    "        machine_type = DEPLOY_COMPUTE,\n",
    "        min_replica_count = 1,\n",
    "        max_replica_count = 1\n",
    "    )\n",
    "else: print(f'Not deploying - current model is worse ({model_rank}) than the currently deployed model ({deployed_rank})') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b7e5a-4556-4e40-8450-a2e1eedee0f2",
   "metadata": {},
   "source": [
    "### Remove Deployed Models without Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6945f51a-0c06-4760-bbfe-f2b9d1e7d38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 05i_fraud with version 1 has traffic = 100\n"
     ]
    }
   ],
   "source": [
    "for deployed_model in endpoint.list_models():\n",
    "    if deployed_model.id in endpoint.traffic_split:\n",
    "        print(f\"Model {deployed_model.display_name} with version {deployed_model.model_version_id} has traffic = {endpoint.traffic_split[deployed_model.id]}\")\n",
    "    else:\n",
    "        endpoint.undeploy(deployed_model_id = deployed_model.id)\n",
    "        print(f\"Undeploying {deployed_model.display_name} with version {deployed_model.model_version_id} because it has no traffic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d90c6900-de81-4fcd-af0b-ba6b3925724d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5475220460650102784': 100}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14cbf4a3-9e32-4158-a9ee-0cfca92e8574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"5475220460650102784\"\n",
       " model: \"projects/1026793852137/locations/us-central1/models/model_05i_fraud\"\n",
       " display_name: \"05i_fraud\"\n",
       " create_time {\n",
       "   seconds: 1661565734\n",
       "   nanos: 379696000\n",
       " }\n",
       " dedicated_resources {\n",
       "   machine_spec {\n",
       "     machine_type: \"n1-standard-4\"\n",
       "   }\n",
       "   min_replica_count: 1\n",
       "   max_replica_count: 1\n",
       " }\n",
       " explanation_spec {\n",
       "   parameters {\n",
       "     integrated_gradients_attribution {\n",
       "       step_count: 50\n",
       "     }\n",
       "   }\n",
       "   metadata {\n",
       "     inputs {\n",
       "       key: \"Amount\"\n",
       "       value {\n",
       "         input_tensor_name: \"Amount\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"Time\"\n",
       "       value {\n",
       "         input_tensor_name: \"Time\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V1\"\n",
       "       value {\n",
       "         input_tensor_name: \"V1\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V10\"\n",
       "       value {\n",
       "         input_tensor_name: \"V10\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V11\"\n",
       "       value {\n",
       "         input_tensor_name: \"V11\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V12\"\n",
       "       value {\n",
       "         input_tensor_name: \"V12\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V13\"\n",
       "       value {\n",
       "         input_tensor_name: \"V13\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V14\"\n",
       "       value {\n",
       "         input_tensor_name: \"V14\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V15\"\n",
       "       value {\n",
       "         input_tensor_name: \"V15\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V16\"\n",
       "       value {\n",
       "         input_tensor_name: \"V16\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V17\"\n",
       "       value {\n",
       "         input_tensor_name: \"V17\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V18\"\n",
       "       value {\n",
       "         input_tensor_name: \"V18\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V19\"\n",
       "       value {\n",
       "         input_tensor_name: \"V19\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V2\"\n",
       "       value {\n",
       "         input_tensor_name: \"V2\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V20\"\n",
       "       value {\n",
       "         input_tensor_name: \"V20\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V21\"\n",
       "       value {\n",
       "         input_tensor_name: \"V21\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V22\"\n",
       "       value {\n",
       "         input_tensor_name: \"V22\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V23\"\n",
       "       value {\n",
       "         input_tensor_name: \"V23\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V24\"\n",
       "       value {\n",
       "         input_tensor_name: \"V24\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V25\"\n",
       "       value {\n",
       "         input_tensor_name: \"V25\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V26\"\n",
       "       value {\n",
       "         input_tensor_name: \"V26\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V27\"\n",
       "       value {\n",
       "         input_tensor_name: \"V27\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V28\"\n",
       "       value {\n",
       "         input_tensor_name: \"V28\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V3\"\n",
       "       value {\n",
       "         input_tensor_name: \"V3\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V4\"\n",
       "       value {\n",
       "         input_tensor_name: \"V4\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V5\"\n",
       "       value {\n",
       "         input_tensor_name: \"V5\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V6\"\n",
       "       value {\n",
       "         input_tensor_name: \"V6\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V7\"\n",
       "       value {\n",
       "         input_tensor_name: \"V7\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V8\"\n",
       "       value {\n",
       "         input_tensor_name: \"V8\"\n",
       "       }\n",
       "     }\n",
       "     inputs {\n",
       "       key: \"V9\"\n",
       "       value {\n",
       "         input_tensor_name: \"V9\"\n",
       "       }\n",
       "     }\n",
       "     outputs {\n",
       "       key: \"prediction_layer\"\n",
       "       value {\n",
       "         output_tensor_name: \"prediction_layer\"\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " model_version_id: \"1\"]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4568c3cc-863f-48d6-808d-36e9c32471bb",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction\n",
    "\n",
    "See many more details on requesting predictions in the `05tools_1 Predictions` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538a303-b8ac-4966-af80-0020477605c1",
   "metadata": {},
   "source": [
    "### Prepare a record for prediction: instance and parameters lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55c3919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bigquery.query(query = f\"SELECT * FROM {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE} WHERE splits='TEST' LIMIT 10\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "925f49d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35337</td>\n",
       "      <td>1.092844</td>\n",
       "      <td>-0.013230</td>\n",
       "      <td>1.359829</td>\n",
       "      <td>2.731537</td>\n",
       "      <td>-0.707357</td>\n",
       "      <td>0.873837</td>\n",
       "      <td>-0.796130</td>\n",
       "      <td>0.437707</td>\n",
       "      <td>0.396770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167647</td>\n",
       "      <td>0.027557</td>\n",
       "      <td>0.592115</td>\n",
       "      <td>0.219695</td>\n",
       "      <td>0.036970</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>a1b10547-d270-48c0-b902-7a0f735dadc7</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60481</td>\n",
       "      <td>1.238973</td>\n",
       "      <td>0.035226</td>\n",
       "      <td>0.063003</td>\n",
       "      <td>0.641406</td>\n",
       "      <td>-0.260893</td>\n",
       "      <td>-0.580097</td>\n",
       "      <td>0.049938</td>\n",
       "      <td>-0.034733</td>\n",
       "      <td>0.405932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057718</td>\n",
       "      <td>0.104983</td>\n",
       "      <td>0.537987</td>\n",
       "      <td>0.589563</td>\n",
       "      <td>-0.046207</td>\n",
       "      <td>-0.006212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>814c62c8-ade4-47d5-bf83-313b0aafdee5</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139587</td>\n",
       "      <td>1.870539</td>\n",
       "      <td>0.211079</td>\n",
       "      <td>0.224457</td>\n",
       "      <td>3.889486</td>\n",
       "      <td>-0.380177</td>\n",
       "      <td>0.249799</td>\n",
       "      <td>-0.577133</td>\n",
       "      <td>0.179189</td>\n",
       "      <td>-0.120462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180776</td>\n",
       "      <td>-0.060226</td>\n",
       "      <td>-0.228979</td>\n",
       "      <td>0.080827</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>-0.036997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>d08a1bfa-85c5-4f1b-9537-1c5a93e6afd0</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162908</td>\n",
       "      <td>-3.368339</td>\n",
       "      <td>-1.980442</td>\n",
       "      <td>0.153645</td>\n",
       "      <td>-0.159795</td>\n",
       "      <td>3.847169</td>\n",
       "      <td>-3.516873</td>\n",
       "      <td>-1.209398</td>\n",
       "      <td>-0.292122</td>\n",
       "      <td>0.760543</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.171627</td>\n",
       "      <td>0.214333</td>\n",
       "      <td>-0.159652</td>\n",
       "      <td>-0.060883</td>\n",
       "      <td>1.294977</td>\n",
       "      <td>0.120503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>802f3307-8e5a-4475-b795-5d5d8d7d0120</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0   35337  1.092844 -0.013230  1.359829  2.731537 -0.707357  0.873837   \n",
       "1   60481  1.238973  0.035226  0.063003  0.641406 -0.260893 -0.580097   \n",
       "2  139587  1.870539  0.211079  0.224457  3.889486 -0.380177  0.249799   \n",
       "3  162908 -3.368339 -1.980442  0.153645 -0.159795  3.847169 -3.516873   \n",
       "\n",
       "         V7        V8        V9  ...       V23       V24       V25       V26  \\\n",
       "0 -0.796130  0.437707  0.396770  ... -0.167647  0.027557  0.592115  0.219695   \n",
       "1  0.049938 -0.034733  0.405932  ... -0.057718  0.104983  0.537987  0.589563   \n",
       "2 -0.577133  0.179189 -0.120462  ...  0.180776 -0.060226 -0.228979  0.080827   \n",
       "3 -1.209398 -0.292122  0.760543  ... -1.171627  0.214333 -0.159652 -0.060883   \n",
       "\n",
       "        V27       V28  Amount  Class                        transaction_id  \\\n",
       "0  0.036970  0.010984     0.0      0  a1b10547-d270-48c0-b902-7a0f735dadc7   \n",
       "1 -0.046207 -0.006212     0.0      0  814c62c8-ade4-47d5-bf83-313b0aafdee5   \n",
       "2  0.009868 -0.036997     0.0      0  d08a1bfa-85c5-4f1b-9537-1c5a93e6afd0   \n",
       "3  1.294977  0.120503     0.0      0  802f3307-8e5a-4475-b795-5d5d8d7d0120   \n",
       "\n",
       "   splits  \n",
       "0    TEST  \n",
       "1    TEST  \n",
       "2    TEST  \n",
       "3    TEST  \n",
       "\n",
       "[4 rows x 33 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2029a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "newob = pred[pred.columns[~pred.columns.isin(VAR_OMIT.split()+[VAR_TARGET, 'splits'])]].to_dict(orient='records')[0]\n",
    "#newob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2fe2a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [json_format.ParseDict(newob, Value())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce406c3d",
   "metadata": {},
   "source": [
    "### Get Predictions: Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "310c36d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[[0.998993218, 0.00100678555]], deployed_model_id='5475220460650102784', model_version_id='1', model_resource_name='projects/1026793852137/locations/us-central1/models/model_05i_fraud', explanations=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = endpoint.predict(instances=instances)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1577b05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.998993218, 0.00100678555]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e015da78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction.predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adfb305",
   "metadata": {},
   "source": [
    "### Get Predictions: REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8404930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DIR}/request.json','w') as file:\n",
    "    file.write(json.dumps({\"instances\": [newob]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f512483f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    [\n",
      "      0.998993218,\n",
      "      0.00100678555\n",
      "    ]\n",
      "  ],\n",
      "  \"deployedModelId\": \"5475220460650102784\",\n",
      "  \"model\": \"projects/1026793852137/locations/us-central1/models/model_05i_fraud\",\n",
      "  \"modelDisplayName\": \"05i_fraud\",\n",
      "  \"modelVersionId\": \"1\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST \\\n",
    "-H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
    "-H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "-d @{DIR}/request.json \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e780e01b",
   "metadata": {},
   "source": [
    "### Get Predictions: gcloud (CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2fef4aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n",
      "[[0.998993218, 0.00100678555]]\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta ai endpoints predict {endpoint.name.rsplit('/',1)[-1]} --region={REGION} --json-request={DIR}/request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc0f5a8",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"99 - Cleanup\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
