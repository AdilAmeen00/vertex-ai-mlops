{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff39d602-2dc8-40e0-93e8-15048a655918",
   "metadata": {},
   "source": [
    "# 05Tools: Prediction - Cloud Run\n",
    "## BROKEN - Current Being Worked ON - Dependency in tensorflow/serving container\n",
    "\n",
    "Predictions from models created in the 05 series of notebooks.\n",
    "\n",
    "This notebook is part of collection of examples that showcase many ways to serve models:\n",
    "- Online:\n",
    "    - Vertex AI Endpoints: Python, REST, CLI (gcloud): [05Tools - Prediction - Online.ipynb](./05Tools%20-%20Prediction%20-%20Online.ipynb)\n",
    "    - Local with TensorFlow ModelServer: [05Tools - Prediction - Local.ipynb](./05Tools%20-%20Prediction%20-%20Local.ipynb)\n",
    "    - (**THIS NOTEBOOK**) Remote with Cloud Run with TensorFlow ModelServer: [05Tools - Prediction - Cloud Run.ipynb](./05Tools%20-%20Prediction%20-%20Cloud%20Run.ipynb)\n",
    "- Batch: [05Tools - Prediction - Batch.ipynb](./05Tools%20-%20Prediction%20-%20Batch.ipynb)\n",
    "    - BigQuery ML Model Import\n",
    "    - Vertex AI Batch Prediction Jobs\n",
    "\n",
    "### Prerequisites:\n",
    "-  At least 1 of the notebooks in this series [05, 05a-05i]5\n",
    "\n",
    "### Conceptual Flow & Workflow\n",
    "<p align=\"center\">\n",
    "  <img alt=\"Conceptual Flow\" src=\"../architectures/slides/05tools_pred_arch.png\" width=\"45%\">\n",
    "&nbsp; &nbsp; &nbsp; &nbsp;\n",
    "  <img alt=\"Workflow\" src=\"../architectures/slides/05tools_pred_console.png\" width=\"45%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c887ebb-9310-4bea-a40d-2c1c3bd92e8d",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e3409f-ce92-42cb-bfd6-026e2ffe33b1",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09efe29d-f542-46e3-a615-e0f73e92cfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f986894-0c7e-48ce-afb3-7417f8fd7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = '05_predictions'\n",
    "SERIES = '05'\n",
    "\n",
    "# source data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'fraud'\n",
    "BQ_TABLE = 'fraud_prepped'\n",
    "\n",
    "# Resources\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "DEPLOY_IMAGE='us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id' # add more variables to the string with space delimiters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b958e5fb-e042-4c46-8263-130acb8a8d13",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd739ffa-dc12-435c-ae32-0828be873a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud import bigquery\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a1e2a6-483e-459e-b54b-f6cb8510738b",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f474d80a-4ae9-438a-98f6-da2b6b49fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bq = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9282268d-08ed-42fc-a854-c0af0b32e149",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b1efd68-cb82-466b-8741-34fcac59cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = PROJECT_ID\n",
    "DIR = f\"temp/{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee36e2f-d42d-49d5-a030-35b13a0b5547",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "951463c0-2c6b-4676-90c7-551756e7fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb66c237-2e4f-4368-9feb-39a49916e769",
   "metadata": {},
   "source": [
    "---\n",
    "## Get Endpoint\n",
    "\n",
    "[Endpoint Properties and Methods](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Endpoint):\n",
    "\n",
    "```python\n",
    "endpoint\n",
    "endpoint.display_name\n",
    "endpoint.resource_name\n",
    "endpoint.traffic_split\n",
    "endpoint.list_models()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ed19980-f0dd-44e8-9637-918bb832646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = aiplatform.Endpoint.list(filter = f\"labels.series={SERIES}\")\n",
    "endpoint = endpoints[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e574baf9-25bd-4030-a6b0-be5fd6bc93f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the Endpoint in the Console:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/endpoints/1961322035766362112?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f'Review the Endpoint in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/endpoints/{endpoint.name}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d2256-3ea9-430d-85ac-9a5d75b4d7a9",
   "metadata": {},
   "source": [
    "### Model Information\n",
    "Using the model on the endpoint for the current series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1fc4613-7ef2-4db3-bc35-e39f6aee8fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7f539f277d10> \n",
       "resource name: projects/1026793852137/locations/us-central1/endpoints/1961322035766362112"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c216d9f-2728-44a2-8899-cba36608b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#endpoint.list_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5513625a-033d-4ac2-b3c3-07b61ada3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = aiplatform.Model(\n",
    "    model_name = endpoint.list_models()[0].model+f'@{endpoint.list_models()[0].model_version_id}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7aba213-e4f9-4ea8-841b-85c57874fd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05_05h'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef2e9d9f-75da-4166-8081-d1f405e19dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/1026793852137/locations/us-central1/models/model_05_05h'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b0c6cdf-12f3-4054-83fa-c589c050ff77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.version_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "311a591c-f087-4283-9116-f8afdf084b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run-20220927230247-6'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.version_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a5b8bbb-237f-45fd-aae1-000121e8fa36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/1026793852137/locations/us-central1/models/model_05_05h@1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.versioned_resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f60d31e-e291-4064-8f11-efa8f91672d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jsonl', 'bigquery', 'csv', 'tf-record', 'tf-record-gzip', 'file-list']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.supported_input_storage_formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85acf30f-7b5e-4172-9a36-5768f834b926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_05_05h'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7792362d-a55c-425e-af4e-56f241ef6672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://statmike-mlops-349915/05/05h/models/20220927230247/6/model'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06fc2f46-dd6e-44b3-9df8-a50e1bffda40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the model in the Vertex AI Model Registry:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/models/model_05_05h/versions/1/properties?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f'Review the model in the Vertex AI Model Registry:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/models/{model.name}/versions/{model.version_id}/properties?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cb37f3-a2b8-42b4-bbee-7ba2e76abb96",
   "metadata": {},
   "source": [
    "---\n",
    "## Retrieve Records For Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "387789b5-8916-4109-a604-e6f91eb1a57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "pred = bq.query(query = f\"SELECT * FROM {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE} WHERE splits='TEST' LIMIT {n}\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "deee9703-813c-45bd-a3e7-ffa2e9a3614e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35337</td>\n",
       "      <td>1.092844</td>\n",
       "      <td>-0.013230</td>\n",
       "      <td>1.359829</td>\n",
       "      <td>2.731537</td>\n",
       "      <td>-0.707357</td>\n",
       "      <td>0.873837</td>\n",
       "      <td>-0.796130</td>\n",
       "      <td>0.437707</td>\n",
       "      <td>0.396770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167647</td>\n",
       "      <td>0.027557</td>\n",
       "      <td>0.592115</td>\n",
       "      <td>0.219695</td>\n",
       "      <td>0.036970</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>a1b10547-d270-48c0-b902-7a0f735dadc7</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60481</td>\n",
       "      <td>1.238973</td>\n",
       "      <td>0.035226</td>\n",
       "      <td>0.063003</td>\n",
       "      <td>0.641406</td>\n",
       "      <td>-0.260893</td>\n",
       "      <td>-0.580097</td>\n",
       "      <td>0.049938</td>\n",
       "      <td>-0.034733</td>\n",
       "      <td>0.405932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057718</td>\n",
       "      <td>0.104983</td>\n",
       "      <td>0.537987</td>\n",
       "      <td>0.589563</td>\n",
       "      <td>-0.046207</td>\n",
       "      <td>-0.006212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>814c62c8-ade4-47d5-bf83-313b0aafdee5</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139587</td>\n",
       "      <td>1.870539</td>\n",
       "      <td>0.211079</td>\n",
       "      <td>0.224457</td>\n",
       "      <td>3.889486</td>\n",
       "      <td>-0.380177</td>\n",
       "      <td>0.249799</td>\n",
       "      <td>-0.577133</td>\n",
       "      <td>0.179189</td>\n",
       "      <td>-0.120462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180776</td>\n",
       "      <td>-0.060226</td>\n",
       "      <td>-0.228979</td>\n",
       "      <td>0.080827</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>-0.036997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>d08a1bfa-85c5-4f1b-9537-1c5a93e6afd0</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162908</td>\n",
       "      <td>-3.368339</td>\n",
       "      <td>-1.980442</td>\n",
       "      <td>0.153645</td>\n",
       "      <td>-0.159795</td>\n",
       "      <td>3.847169</td>\n",
       "      <td>-3.516873</td>\n",
       "      <td>-1.209398</td>\n",
       "      <td>-0.292122</td>\n",
       "      <td>0.760543</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.171627</td>\n",
       "      <td>0.214333</td>\n",
       "      <td>-0.159652</td>\n",
       "      <td>-0.060883</td>\n",
       "      <td>1.294977</td>\n",
       "      <td>0.120503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>802f3307-8e5a-4475-b795-5d5d8d7d0120</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0   35337  1.092844 -0.013230  1.359829  2.731537 -0.707357  0.873837   \n",
       "1   60481  1.238973  0.035226  0.063003  0.641406 -0.260893 -0.580097   \n",
       "2  139587  1.870539  0.211079  0.224457  3.889486 -0.380177  0.249799   \n",
       "3  162908 -3.368339 -1.980442  0.153645 -0.159795  3.847169 -3.516873   \n",
       "\n",
       "         V7        V8        V9  ...       V23       V24       V25       V26  \\\n",
       "0 -0.796130  0.437707  0.396770  ... -0.167647  0.027557  0.592115  0.219695   \n",
       "1  0.049938 -0.034733  0.405932  ... -0.057718  0.104983  0.537987  0.589563   \n",
       "2 -0.577133  0.179189 -0.120462  ...  0.180776 -0.060226 -0.228979  0.080827   \n",
       "3 -1.209398 -0.292122  0.760543  ... -1.171627  0.214333 -0.159652 -0.060883   \n",
       "\n",
       "        V27       V28  Amount  Class                        transaction_id  \\\n",
       "0  0.036970  0.010984     0.0      0  a1b10547-d270-48c0-b902-7a0f735dadc7   \n",
       "1 -0.046207 -0.006212     0.0      0  814c62c8-ade4-47d5-bf83-313b0aafdee5   \n",
       "2  0.009868 -0.036997     0.0      0  d08a1bfa-85c5-4f1b-9537-1c5a93e6afd0   \n",
       "3  1.294977  0.120503     0.0      0  802f3307-8e5a-4475-b795-5d5d8d7d0120   \n",
       "\n",
       "   splits  \n",
       "0    TEST  \n",
       "1    TEST  \n",
       "2    TEST  \n",
       "3    TEST  \n",
       "\n",
       "[4 rows x 33 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd3f889-38d4-47d8-9df8-72b63afa1a72",
   "metadata": {},
   "source": [
    "Remove columns not included as features in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9932f548-2c04-4150-99e0-0da87e8f216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newobs = pred[pred.columns[~pred.columns.isin(VAR_OMIT.split()+[VAR_TARGET, 'splits'])]].to_dict(orient='records')\n",
    "#newobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74109e3f-fa98-4234-9496-4eb45dbabd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af36f76-04c9-4906-a127-9eabe45c1f09",
   "metadata": {},
   "source": [
    "---\n",
    "## Serving With Cloud Run: TensorFlow ModelServer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca186767-c2c9-4048-a619-332c40d007a2",
   "metadata": {},
   "source": [
    "Review the local directory for this notebook (created above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cece6234-d80e-4554-9bd2-5a9784670165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp/05_predictions'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66641888-3844-472c-93c7-3c7cfcd60730",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928986c7-45f9-40ea-93ef-3ee42a96673f",
   "metadata": {},
   "source": [
    "Copy the model files to the local directory for this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2346f0eb-bb57-4995-a484-d97f264263e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://statmike-mlops-349915/05/05h/models/20220927230247/6/model/keras_metadata.pb...\n",
      "Copying gs://statmike-mlops-349915/05/05h/models/20220927230247/6/model/saved_model.pb...\n",
      "/ [2 files][513.3 KiB/513.3 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://statmike-mlops-349915/05/05h/models/20220927230247/6/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://statmike-mlops-349915/05/05h/models/20220927230247/6/model/variables/variables.index...\n",
      "/ [4 files][558.2 KiB/558.2 KiB]                                                \n",
      "Operation completed over 4 objects/558.2 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -R {model.uri} {DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3e3ade2-bd84-44c0-b926-a07bc371d726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n"
     ]
    }
   ],
   "source": [
    "!ls {DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00bde507-374c-44dd-a12c-49ce89d86e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras_metadata.pb  saved_model.pb  variables\n"
     ]
    }
   ],
   "source": [
    "!ls {DIR}/model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc797d40-f1ad-4a5d-bec7-2f08ff706c2a",
   "metadata": {},
   "source": [
    "### Load the Model (local) and Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea2842e7-e8e9-4cb5-95f8-e47d08b0c582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 23:46:47.911736: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2299995000 Hz\n",
      "2022-09-28 23:46:47.912646: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c77f95c580 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-09-28 23:46:47.912679: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-09-28 23:46:47.912878: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "reloaded_model = tf.saved_model.load(f'{DIR}/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd540da8-0388-4f78-8468-63bbefd08064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_SignatureMap({'serving_default': <ConcreteFunction signature_wrapper(Amount, Time, V1, V10, V11, V12, V13, V14, V15, V16, V17, V18, V19, V2, V20, V21, V22, V23, V24, V25, V26, V27, V28, V3, V4, V5, V6, V7, V8, V9) at 0x7F532ECB3150>})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_model.signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59d18f0c-6af0-4bc9-9d0b-da7f2c70f40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction signature_wrapper(Amount, Time, V1, V10, V11, V12, V13, V14, V15, V16, V17, V18, V19, V2, V20, V21, V22, V23, V24, V25, V26, V27, V28, V3, V4, V5, V6, V7, V8, V9) at 0x7F532ECB3150>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d2101bd-a8f0-45c7-aa41-84bb287e4117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((),\n",
       " {'V12': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V12'),\n",
       "  'V13': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V13'),\n",
       "  'Time': TensorSpec(shape=(None, 1), dtype=tf.float32, name='Time'),\n",
       "  'V24': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V24'),\n",
       "  'V16': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V16'),\n",
       "  'V10': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V10'),\n",
       "  'V4': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V4'),\n",
       "  'V26': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V26'),\n",
       "  'V14': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V14'),\n",
       "  'V23': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V23'),\n",
       "  'V22': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V22'),\n",
       "  'V2': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V2'),\n",
       "  'V8': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V8'),\n",
       "  'V7': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V7'),\n",
       "  'V9': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V9'),\n",
       "  'V5': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V5'),\n",
       "  'V19': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V19'),\n",
       "  'V28': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V28'),\n",
       "  'V21': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V21'),\n",
       "  'V17': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V17'),\n",
       "  'V11': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V11'),\n",
       "  'V15': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V15'),\n",
       "  'V3': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V3'),\n",
       "  'V18': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V18'),\n",
       "  'V25': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V25'),\n",
       "  'V6': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V6'),\n",
       "  'V27': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V27'),\n",
       "  'Amount': TensorSpec(shape=(None, 1), dtype=tf.float32, name='Amount'),\n",
       "  'V1': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V1'),\n",
       "  'V20': TensorSpec(shape=(None, 1), dtype=tf.float32, name='V20')})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_model.signatures['serving_default'].structured_input_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03e84068-0509-4474-84ac-6ac9c77250ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!saved_model_cli show --dir {DIR}/model --all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c42b2ad-954e-4c34-bfc4-3f9eff7573a3",
   "metadata": {},
   "source": [
    "### Build Docker Container\n",
    "This build is local to the notebook.  It could be done on a service like Cloud Build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a91f7421-89ec-4105-a5b1-41ec302c808c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dockerfile = f\"\"\"\n",
    "FROM tensorflow/serving\n",
    "#ENTRYPOINT [“/usr/bin/env”]\n",
    "ENV MODEL_NAME={SERIES}\n",
    "ENV PORT=8501\n",
    "COPY . /models/{SERIES}/1\n",
    "#RUN ls -la /models/{SERIES}\n",
    "CMD tensorflow_model_server --port8500 --rest_api_port=$PORT --model_base_path=/models/{SERIES} --model_name=$MODEL_NAME\n",
    "\"\"\"\n",
    "with open(f'{DIR}/model/Dockerfile', 'w') as f:\n",
    "    f.write(dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a5c723-da76-4be9-9957-f8b1aa5a54d2",
   "metadata": {},
   "source": [
    "Create an Image Tag for Artifact Registry - the repository name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "981682f6-22b7-466a-8b16-7413b6eb63c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/05_predictions:latest'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_URI=f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{PROJECT_ID}/{EXPERIMENT}:latest\"\n",
    "IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dccc0e9-f086-47b9-a7b6-d9f5ae9f6a64",
   "metadata": {},
   "source": [
    "Docker build - local:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00958039-3612-4aef-9711-42874dbf02e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon    577kB\n",
      "Step 1/5 : FROM tensorflow/serving\n",
      " ---> 296dbc78ab3b\n",
      "Step 2/5 : ENV MODEL_NAME=05\n",
      " ---> Running in fac71b126a3f\n",
      "Removing intermediate container fac71b126a3f\n",
      " ---> de740d578537\n",
      "Step 3/5 : ENV PORT=8501\n",
      " ---> Running in 43f2c4dbb6ef\n",
      "Removing intermediate container 43f2c4dbb6ef\n",
      " ---> 9d0b93b8887f\n",
      "Step 4/5 : COPY . /models/05/1\n",
      " ---> d1b00a6d0c16\n",
      "Step 5/5 : CMD tensorflow_model_server --port8500 --rest_api_port=$PORT --model_base_path=/models/05 --model_name=$MODEL_NAME\n",
      " ---> Running in 0e15c5979e6c\n",
      "Removing intermediate container 0e15c5979e6c\n",
      " ---> 7dad0e109de0\n",
      "Successfully built 7dad0e109de0\n",
      "Successfully tagged us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/05_predictions:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -t $IMAGE_URI {DIR}/model/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949bfe05-6098-4934-9b5d-5c67d4c9c46b",
   "metadata": {},
   "source": [
    "### Test Docker Container Locally (in a subprocess)\n",
    "Use the `-rm` flag to indicate the container should be automatically removed once stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8540732-050b-4bcc-8a4e-6a59c5298298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown argument: /bin/sh\n",
      "usage: tensorflow_model_server\n",
      "Flags:\n",
      "\t--port=8500                      \tint32\tTCP port to listen on for gRPC/HTTP API. Disabled if port set to zero.\n",
      "\t--grpc_socket_path=\"\"            \tstring\tIf non-empty, listen to a UNIX socket for gRPC API on the given path. Can be either relative or absolute path.\n",
      "\t--rest_api_port=0                \tint32\tPort to listen on for HTTP/REST API. If set to zero HTTP/REST API will not be exported. This port must be different than the one specified in --port.\n",
      "\t--rest_api_num_threads=16        \tint32\tNumber of threads for HTTP/REST API processing. If not set, will be auto set based on number of CPUs.\n",
      "\t--rest_api_timeout_in_ms=30000   \tint32\tTimeout for HTTP/REST API calls.\n",
      "\t--rest_api_enable_cors_support=false\tbool\tEnable CORS headers in response\n",
      "\t--enable_batching=false          \tbool\tenable batching\n",
      "\t--allow_version_labels_for_unavailable_models=false\tbool\tIf true, allows assigning unused version labels to models that are not available yet.\n",
      "\t--batching_parameters_file=\"\"    \tstring\tIf non-empty, read an ascii BatchingParameters protobuf from the supplied file name and use the contained values instead of the defaults.\n",
      "\t--model_config_file=\"\"           \tstring\tIf non-empty, read an ascii ModelServerConfig protobuf from the supplied file name, and serve the models in that file. This config file can be used to specify multiple models to serve and other advanced parameters including non-default version policy. (If used, --model_name, --model_base_path are ignored.)\n",
      "\t--model_config_file_poll_wait_seconds=0\tint32\tInterval in seconds between each poll of the filesystemfor model_config_file. If unset or set to zero, poll will be done exactly once and not periodically. Setting this to negative is reserved for testing purposes only.\n",
      "\t--model_name=\"default\"           \tstring\tname of model (ignored if --model_config_file flag is set)\n",
      "\t--model_base_path=\"\"             \tstring\tpath to export (ignored if --model_config_file flag is set, otherwise required)\n",
      "\t--num_load_threads=0             \tint32\tThe number of threads in the thread-pool used to load servables. If set as 0, we don't use a thread-pool, and servable loads are performed serially in the manager's main work loop, may casue the Serving request to be delayed. Default: 0\n",
      "\t--num_unload_threads=0           \tint32\tThe number of threads in the thread-pool used to unload servables. If set as 0, we don't use a thread-pool, and servable loads are performed serially in the manager's main work loop, may casue the Serving request to be delayed. Default: 0\n",
      "\t--max_num_load_retries=5         \tint32\tmaximum number of times it retries loading a model after the first failure, before giving up. If set to 0, a load is attempted only once. Default: 5\n",
      "\t--load_retry_interval_micros=60000000\tint64\tThe interval, in microseconds, between each servable load retry. If set negative, it doesn't wait. Default: 1 minute\n",
      "\t--file_system_poll_wait_seconds=1\tint32\tInterval in seconds between each poll of the filesystem for new model version. If set to zero poll will be exactly done once and not periodically. Setting this to negative value will disable polling entirely causing ModelServer to indefinitely wait for a new model at startup. Negative values are reserved for testing purposes only.\n",
      "\t--flush_filesystem_caches=true   \tbool\tIf true (the default), filesystem caches will be flushed after the initial load of all servables, and after each subsequent individual servable reload (if the number of load threads is 1). This reduces memory consumption of the model server, at the potential cost of cache misses if model files are accessed after servables are loaded.\n",
      "\t--tensorflow_session_parallelism=0\tint64\tNumber of threads to use for running a Tensorflow session. Auto-configured by default.Note that this option is ignored if --platform_config_file is non-empty.\n",
      "\t--tensorflow_session_config_file=\"\"\tstring\tIf non-empty, read an ascii TensorFlow Session ConfigProto protobuf from the supplied file name. Note, parts of the session config (threads, parallelism etc.) can be overridden if needed, via corresponding command line flags.\n",
      "\t--tensorflow_intra_op_parallelism=0\tint64\tNumber of threads to use to parallelize the executionof an individual op. Auto-configured by default.Note that this option is ignored if --platform_config_file is non-empty.\n",
      "\t--tensorflow_inter_op_parallelism=0\tint64\tControls the number of operators that can be executed simultaneously. Auto-configured by default.Note that this option is ignored if --platform_config_file is non-empty.\n",
      "\t--use_alts_credentials=false     \tbool\tUse Google ALTS credentials\n",
      "\t--ssl_config_file=\"\"             \tstring\tIf non-empty, read an ascii SSLConfig protobuf from the supplied file name and set up a secure gRPC channel\n",
      "\t--platform_config_file=\"\"        \tstring\tIf non-empty, read an ascii PlatformConfigMap protobuf from the supplied file name, and use that platform config instead of the Tensorflow platform. (If used, --enable_batching is ignored.)\n",
      "\t--per_process_gpu_memory_fraction=0.000000\tfloat\tFraction that each process occupies of the GPU memory space the value is between 0.0 and 1.0 (with 0.0 as the default) If 1.0, the server will allocate all the memory when the server starts, If 0.0, Tensorflow will automatically select a value.\n",
      "\t--saved_model_tags=\"serve\"       \tstring\tComma-separated set of tags corresponding to the meta graph def to load from SavedModel.\n",
      "\t--grpc_channel_arguments=\"\"      \tstring\tA comma separated list of arguments to be passed to the grpc server. (e.g. grpc.max_connection_age_ms=2000)\n",
      "\t--grpc_max_threads=16            \tint32\tMax grpc server threads to handle grpc messages.\n",
      "\t--enable_model_warmup=true       \tbool\tEnables model warmup, which triggers lazy initializations (such as TF optimizations) at load time, to reduce first request latency.\n",
      "\t--num_request_iterations_for_warmup=0\tint32\tNumber of times a request is iterated during warmup replay. This value is used only if > 0.\n",
      "\t--version=false                  \tbool\tDisplay version\n",
      "\t--monitoring_config_file=\"\"      \tstring\tIf non-empty, read an ascii MonitoringConfig protobuf from the supplied file name\n",
      "\t--remove_unused_fields_from_bundle_metagraph=true\tbool\tRemoves unused fields from MetaGraphDef proto message to save memory.\n",
      "\t--prefer_tflite_model=false      \tbool\tEXPERIMENTAL; CAN BE REMOVED ANYTIME! Prefer TensorFlow Lite model from `model.tflite` file in SavedModel directory, instead of the TensorFlow model from `saved_model.pb` file. If no TensorFlow Lite model found, fallback to TensorFlow model.\n",
      "\t--num_tflite_pools=4             \tint32\tEXPERIMENTAL; CAN BE REMOVED ANYTIME! Number of TFLite interpreters in an interpreter pool of TfLiteSession. Typically there is one TfLiteSession for each TF Lite model that is loaded. If not set, will be auto set based on number of CPUs.\n",
      "\t--num_tflite_interpreters_per_pool=1\tint32\tEXPERIMENTAL; CAN BE REMOVED ANYTIME! Number of TFLite interpreters in an interpreter pool of TfLiteSession. Typically there is one TfLiteSession for each TF Lite model that is loaded. If not set, will be 1.\n",
      "\t--enable_signature_method_name_check=false\tbool\tEnable method_name check for SignatureDef. Disable this if serving native TF2 regression/classification models.\n",
      "\t--xla_cpu_compilation_enabled=false\tbool\tEXPERIMENTAL; CAN BE REMOVED ANYTIME! Enable XLA:CPU JIT (default is disabled). With XLA:CPU JIT disabled, models utilizing this feature will return bad Status on first compilation request.\n",
      "\t--enable_profiler=true           \tbool\tEnable profiler service.\n",
      "\t--thread_pool_factory_config_file=\"\"\tstring\tIf non-empty, read an ascii ThreadPoolConfig protobuf from the supplied file name.\n",
      "2022-09-28 23:48:15.481554: I tensorflow_serving/model_servers/server.cc:89] Building single TensorFlow model file config:  model_name: 05 model_base_path: /models/05\n",
      "2022-09-28 23:48:15.482073: I tensorflow_serving/model_servers/server_core.cc:465] Adding/updating models.\n",
      "2022-09-28 23:48:15.482110: I tensorflow_serving/model_servers/server_core.cc:594]  (Re-)adding model: 05\n",
      "2022-09-28 23:48:15.656894: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: 05 version: 1}\n",
      "2022-09-28 23:48:15.656978: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: 05 version: 1}\n",
      "2022-09-28 23:48:15.657040: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: 05 version: 1}\n",
      "2022-09-28 23:48:15.657144: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /models/05/1\n",
      "2022-09-28 23:48:15.668871: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-09-28 23:48:15.668933: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /models/05/1\n",
      "2022-09-28 23:48:15.669106: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-28 23:48:15.740247: I external/org_tensorflow/tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2022-09-28 23:48:15.747146: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-09-28 23:48:15.851359: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /models/05/1\n",
      "2022-09-28 23:48:15.898025: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 240877 microseconds.\n",
      "2022-09-28 23:48:15.902606: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:62] No warmup data file found at /models/05/1/assets.extra/tf_serving_warmup_requests\n",
      "2022-09-28 23:48:15.969584: I tensorflow_serving/core/loader_harness.cc:95] Successfully loaded servable version {name: 05 version: 1}\n",
      "2022-09-28 23:48:15.971023: I tensorflow_serving/model_servers/server_core.cc:486] Finished adding/updating models\n",
      "2022-09-28 23:48:15.971161: I tensorflow_serving/model_servers/server.cc:133] Using InsecureServerCredentials\n",
      "2022-09-28 23:48:15.971219: I tensorflow_serving/model_servers/server.cc:395] Profiler service is enabled\n",
      "2022-09-28 23:48:15.973200: I tensorflow_serving/model_servers/server.cc:421] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
      "[warn] getaddrinfo: address family for nodename not supported\n",
      "2022-09-28 23:48:15.975134: I tensorflow_serving/model_servers/server.cc:442] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\n",
      "terminate called after throwing an instance of 'std::bad_alloc'\n",
      "  what():  std::bad_alloc\n",
      "/usr/bin/tf_serving_entrypoint.sh: line 3:     6 Aborted                 (core dumped) tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=${MODEL_NAME} --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME} \"$@\"\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def docker_runner():\n",
    "    !docker run -t --rm -i -p 8501:8501 $IMAGE_URI\n",
    "\n",
    "def main():\n",
    "    p = multiprocessing.Process(target=docker_runner)\n",
    "    p.start()\n",
    "    return p\n",
    "    \n",
    "p = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77dacc9-91cc-44e8-9561-4f9f13968f55",
   "metadata": {},
   "source": [
    "#### Get Predictions on Exposed Port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "178e8927-34a2-4528-95a5-f977b5deb4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0146dfcf-f125-4524-999f-7c10c3d95690",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteDisconnected\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;31m# sending a valid response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             raise RemoteDisconnected(\"Remote end closed connection without\"\n\u001b[0m\u001b[1;32m    289\u001b[0m                                      \" response\")\n",
      "\u001b[0;31mRemoteDisconnected\u001b[0m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    498\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m                 )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 786\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;31m# sending a valid response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             raise RemoteDisconnected(\"Remote end closed connection without\"\n\u001b[0m\u001b[1;32m    289\u001b[0m                                      \" response\")\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26798/189408287.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"content-type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjson_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'http://localhost:8501/v1/models/{SERIES}:predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"instances\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnewobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    585\u001b[0m         }\n\u001b[1;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mProtocolError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))"
     ]
    }
   ],
   "source": [
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post(f'http://localhost:8501/v1/models/{SERIES}:predict', data=json.dumps({\"instances\": [newobs[0]]}), headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ba94c248-1ae2-426b-8a98-e9ecb4681aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"predictions\": [[0.999176681, 0.000823272683]\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c8d9dc40-e2dc-408d-a93f-e7e8b40e941e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.999176681, 0.000823272683]]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = json.loads(json_response.text)['predictions']\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "de703137-b8e6-464a-9d02-8aca0eac1ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf385534-31b5-45bf-aef0-355b8de7a0df",
   "metadata": {},
   "source": [
    "#### Shutdown TensorFlow Serving Container\n",
    "There are two entities running: a subprocess called `p` and a docker container that was run by the subprocess.  It is not enough to just stop `p` but it might be enough to stop the container and then the subprocess will terminate due to completion.  The commands below stop the subprocess `p` and then stop and remove (automatic since run with `-rm` flag) the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a42d0cd-5901-4c1c-aaec-f7c6c9ff10f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb90edaf-ca8e-42bf-bb8a-bd44b0e73c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.is_alive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c61e749-d83e-48c7-86d4-c0cc651b19ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CONTAINER ID   IMAGE                          COMMAND                  CREATED       STATUS      PORTS     NAMES',\n",
       " 'cfc6fa1ae606   gcr.io/inverting-proxy/agent   \"/bin/sh -c \\'/opt/bi…\"   6 weeks ago   Up 2 days             proxy-agent']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docker = !docker ps -a\n",
    "docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f4d8b42-cea9-4442-bd90-7e085b58a12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in docker:\n",
    "    if f'{IMAGE_URI}' in d:\n",
    "        print(d.split()[-1])\n",
    "        !docker stop {d.split()[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "400160f8-8171-4992-a071-a9d2fe8556b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                          COMMAND                  CREATED       STATUS      PORTS     NAMES\n",
      "cfc6fa1ae606   gcr.io/inverting-proxy/agent   \"/bin/sh -c '/opt/bi…\"   6 weeks ago   Up 2 days             proxy-agent\n"
     ]
    }
   ],
   "source": [
    "!docker ps -a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9ef743-65d7-4f04-a91c-4891ba34d7bc",
   "metadata": {},
   "source": [
    "### Push the Docker Container to Artifact Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a2794c-f15b-4597-a846-6e17f3dfcbb8",
   "metadata": {},
   "source": [
    "#### Enable Artifact Registry API:\n",
    "Check to see if the api is enabled, if not then enable it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ed84d189-2b0e-487f-add3-e63493d97fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifact Registry is Enabled for This Project: statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "services = !gcloud services list --format=\"json\" --available --filter=name:artifactregistry.googleapis.com\n",
    "services = json.loads(\"\".join(services))\n",
    "\n",
    "if (services[0]['config']['name'] == 'artifactregistry.googleapis.com') & (services[0]['state'] == 'ENABLED'):\n",
    "    print(f\"Artifact Registry is Enabled for This Project: {PROJECT_ID}\")\n",
    "else:\n",
    "    print(f\"Enabeling Artifact Registry for this Project: {PROJECT_ID}\")\n",
    "    !gcloud services enable artifactregistry.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c8260-d4ff-45b9-835c-5840dc3f5279",
   "metadata": {},
   "source": [
    "#### Create A Repository\n",
    "Check to see if the registry is already created, if not then create it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "dfef982e-d5fc-4ed0-b7b7-342940fb4e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is already a repository named statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "check_for_repo = !gcloud artifacts repositories describe {PROJECT_ID} --location={REGION}\n",
    "\n",
    "if check_for_repo[0].startswith('ERROR'):\n",
    "    print(f'Creating a repository named {PROJECT_ID}')\n",
    "    !gcloud  artifacts repositories create {PROJECT_ID} --repository-format=docker --location={REGION} --description=\"Vertex AI Training Custom Containers\"\n",
    "else:\n",
    "    print(f'There is already a repository named {PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe01c6fb-8a0c-4f54-a0c5-ca5abd82b06b",
   "metadata": {},
   "source": [
    "#### Configure Local Docker to Use GCLOUD CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "330bea7e-c130-45b2-859b-98edcbbcaf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"us-central1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa4dc7f-ef0a-45cd-bdd9-414d850279ee",
   "metadata": {},
   "source": [
    "#### Push The Container to The Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "55bea2a4-b224-43f1-8eda-14f05b928688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/05_predictions]\n",
      "\n",
      "\u001b[1B9c0f0fb7: Preparing \n",
      "\u001b[1B23850a27: Preparing \n",
      "\u001b[1Ba33781cd: Preparing \n",
      "\u001b[1B89523b17: Preparing \n",
      "\u001b[1Bf28d5f3c: Preparing \n",
      "\u001b[1Bc6d2db45: Preparing \n",
      "\u001b[1Bbacb0351: Preparing \n",
      "\u001b[8B9c0f0fb7: Pushed lready exists 9kB\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2Klatest: digest: sha256:0cb8dacb33652b932190b7192a630742395948db07db06ee53f43042f7ff4ad5 size: 1989\n"
     ]
    }
   ],
   "source": [
    "!docker push $IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105dba0c-3285-4fde-9e90-a75c3fbaad05",
   "metadata": {},
   "source": [
    "### Deploy as Cloud Run Service\n",
    "This demonstration creates an open service allowing all traffic.  Review documentation for [Cloud Run](https://cloud.google.com/run/docs/overview/what-is-cloud-run) and the [CLOUD SKD CLI sections](https://cloud.google.com/sdk/gcloud/reference/run) for `gcloud run`.\n",
    "\n",
    "\n",
    "If you have a policy inforced for 'Domain Restricted Sharing' then it may need adjusting for the project to allow this.  This should be done with care and you may wish to only accept authenticated or internal traffic.  Review options for authentication [here](https://cloud.google.com/run/docs/authenticating/overview).\n",
    "\n",
    "Updated Org Policy:\n",
    "- Logged in as Admin\n",
    "- IAM > Organization Policies\n",
    "    - Changed to Project (not org level)\n",
    "    - Filter 'Domain Restricted Sharing'\n",
    "    - Select and Edit\n",
    "        - Applies to = Customize\n",
    "        - Policy enforcement = Replace\n",
    "        - Rules = Allow all\n",
    "    - Save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88850a2-280d-4171-9658-2265ec1c1d76",
   "metadata": {},
   "source": [
    "View the Cloud Run Console for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "47f60994-3f2b-427a-a701-c9e958f83560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://console.cloud.google.com/run?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f'https://console.cloud.google.com/run?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "5b66ade5-9be8-4b51-a18f-b624896782f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying new service...                                                       \n",
      "  . Creating Revision...                                                       \n",
      "  . Routing traffic...                                                         \n",
      "  . Setting IAM Policy...                                                      \n"
     ]
    }
   ],
   "source": [
    "!gcloud run deploy endpoint-$SERIES-$BQ_DATASET --image=$IMAGE_URI --port=8501 --region=$REGION --platform=managed --allow-unauthenticated --no-user-output-enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "bc4ab65c-b163-4e2c-8043-28516b2ace49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SERVICE            REGION       URL                                                LAST DEPLOYED BY                                     LAST DEPLOYED AT\n",
      "\u001b[32m✔\u001b[39;0m  endpoint-05-fraud  us-central1  https://endpoint-05-fraud-urlxi72dpa-uc.a.run.app  1026793852137-compute@developer.gserviceaccount.com  2022-08-26T21:08:34.408166Z\n"
     ]
    }
   ],
   "source": [
    "!gcloud run services list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "bbba529a-c073-4c6f-aefe-1c7e38680fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://endpoint-05-fraud-urlxi72dpa-uc.a.run.app'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services = !gcloud run services list --format=\"json\" --filter=SERVICE:endpoint-$SERIES-$BQ_DATASET\n",
    "services = json.loads(\"\".join(services))[0]\n",
    "services['status']['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783935d8-4566-4674-8f9b-8d8b4c6b8984",
   "metadata": {},
   "source": [
    "If you had to adjust a `Domain Restricted Sharing` policy after deployment then this command can update the service to allow all traffic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "dc2880dc-8603-4411-b8c7-672821cb16a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gcloud run services add-iam-policy-binding --region=us-central1 --member='allUsers' --role=roles/run.invoker endpoint-$SERIES-$DATANAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf2f117-064e-41c9-b73f-f8c20a440c29",
   "metadata": {},
   "source": [
    "### Get Predictions Using Cloud Run Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e231aa30-1b6f-466b-973a-ec271351e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "011a30b2-2f59-4de2-9980-581e2b44fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post(f\"{services['status']['url']}/v1/models/{SERIES}:predict\", data=json.dumps({\"instances\": [newobs[0]]}), headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "212987d2-87e4-499b-81ef-ccdce26b2b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"predictions\": [[0.999176681, 0.000823272683]\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "70a5d747-e035-4bef-9ed4-7b485dc2f620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.999176681, 0.000823272683]]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = json.loads(json_response.text)['predictions']\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1b051fe6-8c93-4a6b-8fda-0c6d99121603",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585fac3c-f900-4699-9db5-dcebe95ca7a2",
   "metadata": {},
   "source": [
    "### Remove Service\n",
    "Alternatively, you could adjust the service to not accept traffic.  Cloud Run will scale down to zero - or only charge when CPU is used (startup, shutdown, and receiving requests) unless `--no-cpu-throttling` is used ([documentation](https://cloud.google.com/run/docs/configuring/cpu-allocation#setting))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c76fd8c7-27d2-4c50-98f1-6418fc9a0c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting [endpoint-05-fraud]...done.                                           \n",
      "Deleted service [endpoint-05-fraud].\n"
     ]
    }
   ],
   "source": [
    "!gcloud run services delete --region=us-central1 --quiet endpoint-$SERIES-$BQ_DATASET"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
