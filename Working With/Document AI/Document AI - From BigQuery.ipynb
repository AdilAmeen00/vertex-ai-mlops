{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12fe5420-3565-45f0-8403-0caf9e76a444",
   "metadata": {},
   "source": [
    "![ga4](https://www.google-analytics.com/collect?v=2&tid=G-6VDTYWLKX6&cid=1&en=page_view&sid=1&dl=statmike%2Fvertex-ai-mlops%2FWorking+With%2FDocument+AI&dt=Document+AI+-+From+BigQuery.ipynb)\n",
    "\n",
    "\n",
    "# Document AI - From BigQuery\n",
    "> From the [Working With Document AI](https://github.com/statmike/vertex-ai-mlops/blob/main/Working%20With/Document%20AI/readme.md) series in the [vertex-ai-mlops](https://github.com/statmike/vertex-ai-mlops/blob/main/readme.md) repository.\n",
    "\n",
    "**NOTE: ON HOLD - IN DEVELOPMENT WHILE FEATURE IS IN PREVIEW**\n",
    "\n",
    "[Document AI](https://cloud.google.com/document-ai/docs/overview) is an API where you interact with processors to extract information from documents.  You enable the API, create an instance of a processor in your project, send in document(s), receive back JSON with the extracted information:\n",
    "\n",
    "<p align=\"center\" width=\"100%\"><center>\n",
    "    <img src=\"../../architectures/architectures/images/working with/documentai/readme/high_level.png\">\n",
    "</center></p>\n",
    "\n",
    "This workflow covers using BigQuery to do both the document processing and the response processing.  \n",
    "\n",
    "<p align=\"center\" width=\"100%\"><center>\n",
    "    <img src=\"../../architectures/architectures/images/working with/documentai/bigquery.png\">\n",
    "</center></p>\n",
    "\n",
    "> For complete details on other ways to use process documents and responses check out these other workflows:\n",
    ">- [Document AI - Process Documents](./Document%20AI%20-%20Process%20Documents.ipynb)\n",
    ">    - How to process 1 or many documents\n",
    ">    - Examples of Batch and Online Processing\n",
    ">    - Async Processing\n",
    ">    - Storing results in GCS and/or BigQuery\n",
    ">    - Recalling results from GCS and/or BigQuery\n",
    ">- [Document AI - Process Responses](./Document%20AI%20-%20Process%20Responses.ipynb)\n",
    ">    - Extracting elements from the JSON in Python or in BigQuery with SQL\n",
    ">    - Treating elements like geographies for advanced extraction techniques\n",
    "\n",
    "---\n",
    "\n",
    "**Documents**\n",
    "\n",
    "Document AI sources are documents.  There are many supported document types (file formats):\n",
    "- Supported [Document Types](https://cloud.google.com/document-ai/docs/file-types) like pdf, gif, tiff, jpeg, pn, gmp, webp\n",
    "- Additional support for [DocX files is in preview](https://cloud.google.com/document-ai/docs/enterprise-document-ocr#supported_file_formats).\n",
    "\n",
    "For BigQuery processing, document should be provided in an [object table](https://cloud.google.com/bigquery/docs/object-table-introduction).  This is essential a table with column that contains the GCS URIs of the documents.\n",
    "\n",
    "---\n",
    "\n",
    "**Processing**\n",
    "\n",
    "To launch the processessing request for the document the [ML.PROCESS_DOCUMENT](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-process-document) function is used in a SQL query statement.\n",
    "\n",
    "---\n",
    "\n",
    "**Responses**\n",
    "\n",
    "With BigQuery function [ML.PROCESS_DOCUMENT](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-process-document) the results are returned as a JSON value where SQL can be used to extract the parts of the documenta needed for an application.\n",
    "\n",
    "---\n",
    "\n",
    "**References:**\n",
    "\n",
    "- BigQuery function [ML.PROCESS_DOCUMENT](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-process-document)\n",
    "- [Document AI Overview](https://cloud.google.com/document-ai/docs/overview)\n",
    "    - [Send a processing request](https://cloud.google.com/document-ai/docs/send-request)\n",
    "    - [Handling the processing response](https://cloud.google.com/document-ai/docs/handle-response)\n",
    "    \n",
    "---\n",
    "\n",
    "**Processing Scecifics For BigQuery**\n",
    "\n",
    "- The dataset/table need to be in the same region as the remote model - this must be US or EU multi-region for Document AI.\n",
    "- (currently) there are not processing inputs, like OCR configuration and add ons\n",
    "- The service has the same limit as online processing, 15 pages per document\n",
    "- (currently) the functionality only work with [Enterprise and Enterprise Plus editions](https://cloud.google.com/bigquery/docs/editions-intro)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b95e2a-1731-4c01-9a98-3dbc1f3db288",
   "metadata": {
    "id": "od_UkDpvRmgD"
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab click [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Working%20With/Document%20AI/Document%20AI%20-%20From%20BigQuery.ipynb) and run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2c8970-102b-42f2-8a3f-2220e5c99299",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "568eb66a-cffb-4646-9cc0-9d2a3ff03767",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0468afa3-fb35-4bc8-a3ee-90cf18347c49",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs and API Enablement\n",
    "\n",
    "The clients packages may need installing in this environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e38d4-879d-4f41-b52d-19a8bdf5d846",
   "metadata": {},
   "source": [
    "### Installs (If Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e25c5e0e-7360-4443-bd83-a622385bb503",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name)\n",
    "packages = [\n",
    "    ('google.cloud.documentai', 'google-cloud-documentai'),\n",
    "    ('google.cloud.documentai', 'google-cloud-storage'),\n",
    "    ('google.cloud.documentai', 'google-cloud-bigquery'),\n",
    "    ('google.cloud.bigquery_connection_v1', 'google-cloud-bigquery-connection'),\n",
    "    ('PyPDF2', 'PyPDF2')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3697b0-818a-41a6-8ed4-20402a576a08",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "59f31e8c-e8c4-4267-bf93-4282617e596c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable documentai.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16beba12-6940-438d-9910-e8f26e63120a",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "feb5e57c-83be-4668-94bd-d2ab2c36adcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb7beef-22be-4512-b1a8-cb0f807aed24",
   "metadata": {
    "id": "appt8-yVRtJ1"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21603d73-77e9-4133-ac85-767e10c0ddc1",
   "metadata": {
    "id": "63mx2EozRxFP"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6bb26c74-1871-402a-a0d4-03cf0b1b38da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1683726390544,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "xzcoXjM5Rky5",
    "outputId": "b3bdcbc1-70d5-472e-aea2-42c74a42efde",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e99d6bc9-6fc7-44b5-a40d-cb93c09ab94b",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683726390712,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "IxWrFtqYMfku",
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'working-with-docai'\n",
    "EXPERIMENT = 'from-bigquery'\n",
    "\n",
    "# make this the gcs bucket for storing files\n",
    "GCS_BUCKET = PROJECT_ID\n",
    "\n",
    "# BigQuery Objects\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = SERIES.replace('-', '_')\n",
    "BQ_TABLE_PREFIX = EXPERIMENT\n",
    "BQ_REGION = REGION[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa8aeb5-38b9-4e08-9088-a5474daf6dca",
   "metadata": {
    "id": "LuajVwCiO6Yg"
   },
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0ad26d07-d844-48c6-8712-9c6c62f2e9b2",
   "metadata": {
    "executionInfo": {
     "elapsed": 17761,
     "status": "ok",
     "timestamp": 1683726409304,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "LVC7zzSLRk2C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, shutil, glob, json, asyncio, datetime, io\n",
    "\n",
    "import PyPDF2\n",
    "\n",
    "from google.cloud import documentai\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import bigquery_connection_v1 as bq_connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde8dea6-808c-4e8b-aed5-5753597cf775",
   "metadata": {
    "id": "EyAVFG9TO9H-"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f790abf3-91a2-48ba-a1ac-984bc15be5ab",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683726409306,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "L0RPE13LOZce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# document AI client\n",
    "LOCATION = REGION.split('-')[0]\n",
    "docai = documentai.DocumentProcessorServiceClient(\n",
    "    client_options = dict(api_endpoint = f\"{LOCATION}-documentai.googleapis.com\")\n",
    ")\n",
    "\n",
    "# gcs client: assumes bucket already exists\n",
    "gcs = storage.Client(project = PROJECT_ID)\n",
    "bucket = gcs.bucket(GCS_BUCKET)\n",
    "\n",
    "# bq client\n",
    "bq = bigquery.Client(project = PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be45606-52f9-4f29-8630-cdc831ac3c95",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Documents\n",
    "\n",
    "This section prepares documents for processing.  In this case there are documents in a local folder in the repository that are prepared for online and batch serving by either loading with directly or copying to a GCS location within the bucket defined above with parameter `GCS_BUCKET`.\n",
    "\n",
    "The files in the local folder `../shared files/docs` are printed pages (to .pdf) from the following [Wikipedia](https://www.wikipedia.org/) pages:\n",
    "\n",
    "|Document Name|Link|\n",
    "|---|---|\n",
    "|`../shared files/docs/Bayes' theorem - Wikipedia.pdf`|[https://en.wikipedia.org/wiki/Bayes%27_theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem)|\n",
    "|`../shared files/docs/sports/Baseball - Wikipedia.pdf`|[https://en.wikipedia.org/wiki/Baseball](https://en.wikipedia.org/wiki/Baseball)|\n",
    "|`../shared files/docs/sports/Football - Wikipedia.pdf`|[https://en.wikipedia.org/wiki/Football](https://en.wikipedia.org/wiki/Football)|\n",
    "|`../shared files/docs/sports/Association football - Wikipedia.pdf`|[https://en.wikipedia.org/wiki/Association_football](https://en.wikipedia.org/wiki/Association_football)|\n",
    "|`../shared files/docs/sports/American football - Wikipedia.pdf`|[https://en.wikipedia.org/wiki/American_football](https://en.wikipedia.org/wiki/American_football)|\n",
    "|`../shared files/docs/sports/Hockey - Wikipedia.pdf`|[https://en.wikipedia.org/wiki/Hockey](https://en.wikipedia.org/wiki/Hockey)|\n",
    "|`../shared files/docs/sports/Basketball - Wikipedia.pdf`|[https://en.wikipedia.org/wiki/Basketball](https://en.wikipedia.org/wiki/Basketball)|\n",
    "|`../shared files/docs/sports/Cricket - Wikipedia.pdf`|[https://en.wikipedia.org/wiki/Cricket](https://en.wikipedia.org/wiki/Cricket)|\n",
    "|`../shared files/docs/sports/Rugby football - Wikipedia.pdf`|[https://en.wikipedia.org/wiki/Rugby_football](https://en.wikipedia.org/wiki/Rugby_football)|\n",
    "|`../shared files/docs/sports/Golf - Wikipedia.pdf`|[https://en.wikipedia.org/wiki/Golf](https://en.wikipedia.org/wiki/Golf)|\n",
    "|`../shared files/docs/jam_bands/Jam band - Wikipedia.pdf`|[https://en.wikipedia.org/wiki/Jam_band](https://en.wikipedia.org/wiki/Jam_band)|\n",
    "|`../shared files/docs/jam_bands/Widespread Panic - Wikipedia.pdf`|[https://en.wikipedia.org/wiki/Widespread_Panic](https://en.wikipedia.org/wiki/Widespread_Panic)|\n",
    "|`../shared files/docs/jam_bands/Cream (band) - Wikipedia.pdf`|[https://en.wikipedia.org/wiki/Cream_(band)](https://en.wikipedia.org/wiki/Cream_(band))|\n",
    "|`../shared files/docs/jam_bands/Phish - Wikipedia.pdf`|[https://en.wikipedia.org/wiki/Phish](https://en.wikipedia.org/wiki/Phish)|\n",
    "|`../shared files/docs/jam_bands/The Allman Brothers Band - Wikipedia.pdf`|[https://en.wikipedia.org/wiki/The_Allman_Brothers_Band](https://en.wikipedia.org/wiki/The_Allman_Brothers_Band)|\n",
    "|`../shared files/docs/jam_bands/Grateful Dead - Wikipedia.pdf`|[https://en.wikipedia.org/wiki/Grateful_Dead](https://en.wikipedia.org/wiki/Grateful_Dead)|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3af1d6-f363-4463-aa73-40d6833273c3",
   "metadata": {},
   "source": [
    "### Get The Documents\n",
    "\n",
    "If you are working from a clone of this notebooks repository then the documents are already present. The following cell checks for the documents folder, `/docs`, and if it is missing gets it (`git clone`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4216823b-3df7-4e45-a90a-496f61747ad6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents Found in folder `../shared files/docs`\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('../shared files/docs'):\n",
    "    print('Retrieving documents...')\n",
    "    if not os.path.exists('temp'):\n",
    "        os.makedirs('temp')\n",
    "    !git clone https://www.github.com/statmike/vertex-ai-mlops temp/vertex-ai-mlops\n",
    "    shutil.copytree('temp/vertex-ai-mlops/Working With/Document AI/shared files/docs', '../shared files/docs')\n",
    "    shutil.rmtree('temp/vertex-ai-mlops')\n",
    "    print('Documents are now in folder `../shared files/docs`')\n",
    "else:\n",
    "    print('Documents Found in folder `../shared files/docs`')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff48e986-c122-4c97-8c4d-06c150c13f32",
   "metadata": {},
   "source": [
    "### Prepare Documents And Save To GCS\n",
    "\n",
    "The 15 page size limit means some documents might need to be split into multiple parts for complete OCR processing in this workflow.  This section detectx the number of pages and creates multi-part documents.  The parts (or full files) are then save to GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66e28d30-6d7b-4e18-9879-bb6b9542610b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../shared files/docs/jam_bands/Widespread Panic - Wikipedia.pdf',\n",
       " '../shared files/docs/jam_bands/Cream (band) - Wikipedia.pdf',\n",
       " '../shared files/docs/jam_bands/The Allman Brothers Band - Wikipedia.pdf',\n",
       " '../shared files/docs/jam_bands/Jam band - Wikipedia.pdf',\n",
       " '../shared files/docs/jam_bands/Grateful Dead - Wikipedia.pdf',\n",
       " '../shared files/docs/jam_bands/Phish - Wikipedia.pdf',\n",
       " '../shared files/docs/sports/Golf - Wikipedia.pdf',\n",
       " '../shared files/docs/sports/Cricket - Wikipedia.pdf',\n",
       " '../shared files/docs/sports/Hockey - Wikipedia.pdf',\n",
       " '../shared files/docs/sports/Association football - Wikipedia.pdf',\n",
       " '../shared files/docs/sports/American football - Wikipedia.pdf',\n",
       " '../shared files/docs/sports/Football - Wikipedia.pdf',\n",
       " '../shared files/docs/sports/Rugby football - Wikipedia.pdf',\n",
       " '../shared files/docs/sports/Baseball - Wikipedia.pdf',\n",
       " '../shared files/docs/sports/Basketball - Wikipedia.pdf']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(f'../shared files/docs/**/**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1a7ff6d-0eda-4747-971e-df0995307607",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in glob.glob('../shared files/docs/**/**'):\n",
    "    # open the full file\n",
    "    with open(file, 'rb') as pdf:\n",
    "        doc = pdf.read()\n",
    "        \n",
    "    # read file, get number of pages, calc the number of parts with up to 15 pages\n",
    "    reader = PyPDF2.PdfReader(io.BytesIO(doc))\n",
    "    num_pages = len(reader.pages)\n",
    "    num_shards = num_pages // 15 + 1 * min(1, num_pages % 15)\n",
    "    \n",
    "    # split file into parts, save all parts to GCS\n",
    "    pdfs = []\n",
    "    if num_shards > 1:\n",
    "        for shard in range(num_shards):\n",
    "            pdfs.append(PyPDF2.PdfWriter())\n",
    "        for page in range(num_pages):\n",
    "            pdfs[page // 15].add_page(reader.pages[page])\n",
    "        for p, pdf in enumerate(pdfs):\n",
    "            blob = bucket.blob(f'{SERIES}/{EXPERIMENT}/{file[3:-4]} - part {p+1} of {len(pdfs)}.pdf')\n",
    "            with blob.open(\"wb\", content_type = 'application/pdf') as f:\n",
    "                pdf.write(f)\n",
    "    else:\n",
    "        blob = bucket.blob(f'{SERIES}/{EXPERIMENT}/{file[3:]}')\n",
    "        blob.upload_from_filename(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77fad636-2807-4856-84da-4c8cf9a63428",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the bucket directly here:\n",
      "https://console.cloud.google.com/storage/browser/statmike-mlops-349915/working-with-docai/from-bigquery;tab=objects&project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f\"View the bucket directly here:\\nhttps://console.cloud.google.com/storage/browser/{GCS_BUCKET}/{SERIES}/{EXPERIMENT};tab=objects&project={PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688608f4-36b9-4489-81d2-37c95a1a623b",
   "metadata": {},
   "source": [
    "List files in bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f22f2c8-e9b9-4293-8855-be6b4446cbb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working-with-docai/from-bigquery/shared files/docs/jam_bands/Cream (band) - Wikipedia.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/jam_bands/Grateful Dead - Wikipedia - part 1 of 2.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/jam_bands/Grateful Dead - Wikipedia - part 2 of 2.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/jam_bands/Jam band - Wikipedia.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/jam_bands/Phish - Wikipedia - part 1 of 3.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/jam_bands/Phish - Wikipedia - part 2 of 3.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/jam_bands/Phish - Wikipedia - part 3 of 3.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/jam_bands/The Allman Brothers Band - Wikipedia - part 1 of 2.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/jam_bands/The Allman Brothers Band - Wikipedia - part 2 of 2.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/jam_bands/Widespread Panic - Wikipedia.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/American football - Wikipedia - part 1 of 3.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/American football - Wikipedia - part 2 of 3.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/American football - Wikipedia - part 3 of 3.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/Association football - Wikipedia - part 1 of 2.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/Association football - Wikipedia - part 2 of 2.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/Baseball - Wikipedia - part 1 of 3.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/Baseball - Wikipedia - part 2 of 3.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/Baseball - Wikipedia - part 3 of 3.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/Basketball - Wikipedia - part 1 of 2.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/Basketball - Wikipedia - part 2 of 2.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/Cricket - Wikipedia - part 1 of 2.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/Cricket - Wikipedia - part 2 of 2.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/Football - Wikipedia - part 1 of 3.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/Football - Wikipedia - part 2 of 3.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/Football - Wikipedia - part 3 of 3.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/Golf - Wikipedia - part 1 of 2.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/Golf - Wikipedia - part 2 of 2.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/Hockey - Wikipedia.pdf\n",
      "working-with-docai/from-bigquery/shared files/docs/sports/Rugby football - Wikipedia.pdf\n"
     ]
    }
   ],
   "source": [
    "for blob in list(bucket.list_blobs(prefix = f'{SERIES}/{EXPERIMENT}/shared files/docs')):\n",
    "    print(blob.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df696f76-b3c9-418b-a407-5b762993c876",
   "metadata": {},
   "source": [
    "---\n",
    "## Processors\n",
    "\n",
    "When submitting documents for processing in Document AI, the client routes the document to a processor.  There are many processors:\n",
    "- [Full processor and detail list](https://cloud.google.com/document-ai/docs/processors-list)\n",
    "- Check out the helpful table for processors in this workflows [readme file](./readme.md) \n",
    "\n",
    "When setting up a processor you can also pick versions or it will default to a version.\n",
    "\n",
    "This section shows how to:\n",
    "- list available processors in the project: console and Python Client\n",
    "    - describe processor(s)\n",
    "- get/create a processor with desired type and version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5173500-9077-4652-ac8d-ce202fa65c4a",
   "metadata": {},
   "source": [
    "### List Processors In This Project\n",
    "\n",
    "If any have already been created, list them:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6b467d-4a9d-46de-a9b1-028f474bf16c",
   "metadata": {},
   "source": [
    "What are the processors already created in this project environment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fafb836e-a33d-41fc-8c5a-e57740cfc312",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processors = list(docai.list_processors(parent = f'projects/{PROJECT_ID}/locations/{LOCATION}'))\n",
    "len(processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e60064b-499a-49aa-93f2-72a987d2ae1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the processors in the console with this link:\n",
      "https://console.cloud.google.com/ai/document-ai/processors?project=statmike-mlops-349915\n",
      "\n",
      "\n",
      "Processors 0:  working-with-docai-invoice-parser \n",
      "\tis of type =  INVOICE_PROCESSOR \n",
      "\tand version =  pretrained-invoice-v1.5-2023-09-15\n",
      "Processors 1:  working-with-docai-form-parser \n",
      "\tis of type =  FORM_PARSER_PROCESSOR \n",
      "\tand version =  pretrained-form-parser-v2.1-2023-06-26\n",
      "Processors 2:  working-with-docai-summarizer \n",
      "\tis of type =  SUMMARY_PROCESSOR \n",
      "\tand version =  pretrained-foundation-model-v1.0-2023-08-22\n",
      "Processors 3:  working-with-docai \n",
      "\tis of type =  OCR_PROCESSOR \n",
      "\tand version =  pretrained-ocr-v2.0-2023-06-02\n",
      "Processors 4:  example-dot \n",
      "\tis of type =  CUSTOM_EXTRACTION_PROCESSOR \n",
      "\tand version =  pretrained-foundation-model-v1.0-2023-08-22\n",
      "Processors 5:  my-invoice \n",
      "\tis of type =  INVOICE_PROCESSOR \n",
      "\tand version =  pretrained-invoice-v1.3-2022-07-15\n",
      "Processors 6:  my_general_processor \n",
      "\tis of type =  FORM_PARSER_PROCESSOR \n",
      "\tand version =  pretrained-form-parser-v1.0-2020-09-23\n"
     ]
    }
   ],
   "source": [
    "if processors:\n",
    "    print(f'View the processors in the console with this link:\\nhttps://console.cloud.google.com/ai/document-ai/processors?project={PROJECT_ID}\\n\\n')\n",
    "    for p, processor in enumerate(processors):\n",
    "        print(\n",
    "            f'Processors {p}: ', processor.display_name, \n",
    "            '\\n\\tis of type = ', processor.type_, \n",
    "            '\\n\\tand version = ',processor.default_processor_version.split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fb2076-980f-4602-a7d8-74655b87b8d8",
   "metadata": {},
   "source": [
    "### Create/Get A Processor\n",
    "\n",
    "For this workflow we will use the [OCR parser](https://cloud.google.com/document-ai/docs/processors-list#processor_doc-ocr). We can check for an existing processor in the project that the OCR Parser with desired version and if it is not present then create one.  The processor will be connected with Python variable `PARSER` and referred to as a parser as it is used.\n",
    "\n",
    "Get the type and version from the list of available processors: https://cloud.google.com/document-ai/docs/processors-list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a05f251-9609-415a-8f1b-e656d7a64168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TYPE = 'OCR_PROCESSOR'\n",
    "VERSION = 'pretrained-ocr-v2.0-2023-06-02'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d164e1f-7852-4c30-8b43-3a6c6648300f",
   "metadata": {},
   "source": [
    "Get an existing processor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00c3254d-ab56-4e8a-aca4-ab4403ff59de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is an existing processor with the desired type and version in PARSER = working-with-docai\n"
     ]
    }
   ],
   "source": [
    "PARSER = ''\n",
    "for processor in processors:\n",
    "    if processor.type_ == TYPE and processor.default_processor_version.split('/')[-1] == VERSION:\n",
    "        PARSER = processor\n",
    "        break\n",
    "        \n",
    "if PARSER:\n",
    "    print(f'There is an existing processor with the desired type and version in PARSER = {PARSER.display_name}')\n",
    "else:\n",
    "    print(f'Need to create a processor for the desired type and version: {TYPE}, {VERSION}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fd903f-2a52-49d5-aeb0-8438ad5ca15e",
   "metadata": {},
   "source": [
    "Create the processor if an existing one was not found to match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2fadab3a-d8ce-4d30-910f-b1e2610b7068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not PARSER:\n",
    "    PARSER = docai.create_processor(\n",
    "        parent = f'projects/{PROJECT_ID}/locations/{LOCATION}',\n",
    "        processor = documentai.Processor(\n",
    "            display_name = SERIES,\n",
    "            type_ = TYPE\n",
    "        )\n",
    "    )\n",
    "    set_default = docai.set_default_processor_version(\n",
    "        request = documentai.SetDefaultProcessorVersionRequest(\n",
    "            processor = PARSER.name,\n",
    "            default_processor_version = f'{PARSER.name}/processorVersions/{VERSION}'\n",
    "        )\n",
    "    )\n",
    "    set_default.result()\n",
    "    PARSER = docai.get_processor(\n",
    "        name = PARSER.name\n",
    "    )\n",
    "    print(f'Processor created and in PARSER variable with display name = {PARSER.display_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0eecf4ca-96b9-4a39-a93c-80146f2476c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/1026793852137/locations/us/processors/d59e19cc08278630'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARSER.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf1322d-f0cf-4553-a309-050262a590e4",
   "metadata": {},
   "source": [
    "---\n",
    "## BigQuery For Processing Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb484bc-7102-424b-964a-74029f5d79c4",
   "metadata": {},
   "source": [
    "### BigQuery Dataset - Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "94882b15-8855-45e9-8c6d-b3987dbb06ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the BigQuery Dataset:  statmike-mlops-349915:working_with_docai\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ds = bq.get_dataset(f'{BQ_PROJECT}.{BQ_DATASET}')\n",
    "    print('Found the BigQuery Dataset: ', ds.full_dataset_id)\n",
    "except:\n",
    "    ds = bigquery.DatasetReference(BQ_PROJECT, BQ_DATASET)\n",
    "    ds.location = BQ_REGION\n",
    "    ds.labels = {'series': f'{SERIES}'}\n",
    "    ds = bq.create_dataset(dataset = ds, exists_ok = True)\n",
    "    print('Created the BigQuery Dataset: ', ds.full_dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf8bcf-e856-4f26-9c6a-f79fd2da0ab7",
   "metadata": {},
   "source": [
    "### BigQuery Object Table - Link Documents In GCS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7a69d4ff-5f76-4c79-9e75-2fe1e3084695",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DONE'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Remote Model In BigQuery\n",
    "query = f\"\"\"\n",
    "CREATE OR REPLACE EXTERNAL TABLE `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE_PREFIX}_DOCUMENTS`\n",
    "    WITH CONNECTION `{BQ_PROJECT}.{BQ_REGION}.{SERIES}_{EXPERIMENT}`\n",
    "    OPTIONS(\n",
    "        object_metadata = 'SIMPLE',\n",
    "        metadata_cache_mode = 'MANUAL',\n",
    "        uris = ['gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/*']\n",
    "    )\n",
    "\"\"\"\n",
    "job = bq.query(query = query)\n",
    "job.result()\n",
    "job.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "13748560-7baf-431e-897e-1f33fff13181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/jam_bands/Cream (band) - Wikipedia.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/jam_bands/Grateful Dead - Wikipedia - part 1 of 2.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/jam_bands/Grateful Dead - Wikipedia - part 2 of 2.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/jam_bands/Jam band - Wikipedia.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/jam_bands/Phish - Wikipedia - part 1 of 3.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/jam_bands/Phish - Wikipedia - part 2 of 3.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/jam_bands/Phish - Wikipedia - part 3 of 3.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/jam_bands/The Allman Brothers Band - Wikipedia - part 1 of 2.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/jam_bands/The Allman Brothers Band - Wikipedia - part 2 of 2.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/jam_bands/Widespread Panic - Wikipedia.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/American football - Wikipedia - part 1 of 3.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/American football - Wikipedia - part 2 of 3.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/American football - Wikipedia - part 3 of 3.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/Association football - Wikipedia - part 1 of 2.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/Association football - Wikipedia - part 2 of 2.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/Baseball - Wikipedia - part 1 of 3.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/Baseball - Wikipedia - part 2 of 3.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/Baseball - Wikipedia - part 3 of 3.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/Basketball - Wikipedia - part 1 of 2.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/Basketball - Wikipedia - part 2 of 2.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/Cricket - Wikipedia - part 1 of 2.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/Cricket - Wikipedia - part 2 of 2.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/Football - Wikipedia - part 1 of 3.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/Football - Wikipedia - part 2 of 3.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/Football - Wikipedia - part 3 of 3.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/Golf - Wikipedia - part 1 of 2.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/Golf - Wikipedia - part 2 of 2.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/Hockey - Wikipedia.pdf',\n",
       " 'gs://statmike-mlops-349915/working-with-docai/from-bigquery/shared files/docs/sports/Rugby football - Wikipedia.pdf']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "SELECT uri\n",
    "FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE_PREFIX}_DOCUMENTS`\n",
    "\"\"\"\n",
    "bq.query(query = query).to_dataframe()['uri'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ccc1f5-3a01-4844-8e72-4f2c90a3a0d5",
   "metadata": {},
   "source": [
    "### BigQuery Remote Model - Document AI With BigQuery ML\n",
    "\n",
    "BigQuery ML can `Create Model`'s that are actually connections to Remote Models. [Reference](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model)\n",
    "\n",
    "Using the `REMOTE_SERVICE_TYPE = \"cloud_ai_document_v1\"` option will link to Document AI.\n",
    "- [Documentation](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-process-document)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7409e1-ee57-41e5-8ad8-f47e1d279d08",
   "metadata": {},
   "source": [
    "#### Connection Requirement\n",
    "\n",
    "To make a remote connection using BigQuery ML, BigQuery uses a CLOUD_RESOURCE connection. [Reference](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model#connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af3ea65-7d9d-4de4-89eb-42b14473a8d2",
   "metadata": {},
   "source": [
    "Create a new connection with type `CLOUD_RESOURCE`: First, check for existing connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "60726bc0-9f5e-40a4-abe3-ade0af71734f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing connection with service account: bqcx-1026793852137-te86@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = bq_connection.ConnectionServiceClient().get_connection(\n",
    "            request = bq_connection.GetConnectionRequest(\n",
    "                name = f\"projects/{BQ_PROJECT}/locations/{BQ_REGION}/connections/{SERIES}_{EXPERIMENT}\"\n",
    "            )\n",
    "    )\n",
    "    print(f'Found existing connection with service account: {response.cloud_resource.service_account_id}')\n",
    "    service_account = response.cloud_resource.service_account_id\n",
    "except Exception:\n",
    "    request = bq_connection.CreateConnectionRequest(\n",
    "        {\n",
    "            \"parent\": f\"projects/{BQ_PROJECT}/locations/{BQ_REGION}\",\n",
    "            \"connection_id\": f\"{SERIES}_{EXPERIMENT}\",\n",
    "            \"connection\": bq_connection.types.Connection(\n",
    "                {\n",
    "                    \"friendly_name\": f\"{SERIES}_{EXPERIMENT}\",\n",
    "                    \"cloud_resource\": bq_connection.CloudResourceProperties({})\n",
    "                }\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    response = bq_connection.ConnectionServiceClient().create_connection(request)\n",
    "    print(f'Created new connection with service account: {response.cloud_resource.service_account_id}')\n",
    "    service_account = response.cloud_resource.service_account_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdb2198-8c5a-4fc2-a5d4-012371375f8c",
   "metadata": {},
   "source": [
    "Assign the service account the Vertex AI User role:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a4a1e3d2-9d26-414f-a14f-c0b45c2d987a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated IAM policy for project [statmike-mlops-349915].\n",
      "bindings:\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-aiplatform-cc.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.customCodeServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-aiplatform-vm.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.notebookServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-aiplatform.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:bqcx-1026793852137-bmph@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  - serviceAccount:bqcx-1026793852137-dyw1@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  - serviceAccount:bqcx-1026793852137-pdxa@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  - serviceAccount:bqcx-1026793852137-te86@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  - serviceAccount:bqcx-1026793852137-tqpc@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  - serviceAccount:bqcx-1026793852137-zfly@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.user\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-artifactregistry.iam.gserviceaccount.com\n",
      "  role: roles/artifactregistry.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:1026793852137-compute@developer.gserviceaccount.com\n",
      "  role: roles/bigquery.admin\n",
      "- members:\n",
      "  - serviceAccount:1026793852137@cloudservices.gserviceaccount.com\n",
      "  role: roles/bigquery.dataOwner\n",
      "- members:\n",
      "  - serviceAccount:1026793852137@cloudbuild.gserviceaccount.com\n",
      "  role: roles/cloudbuild.builds.builder\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-cloudbuild.iam.gserviceaccount.com\n",
      "  role: roles/cloudbuild.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcf-admin-robot.iam.gserviceaccount.com\n",
      "  role: roles/cloudfunctions.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-cloudscheduler.iam.gserviceaccount.com\n",
      "  role: roles/cloudscheduler.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@compute-system.iam.gserviceaccount.com\n",
      "  role: roles/compute.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@containerregistry.iam.gserviceaccount.com\n",
      "  role: roles/containerregistry.ServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@dataflow-service-producer-prod.iam.gserviceaccount.com\n",
      "  role: roles/dataflow.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-dataform.iam.gserviceaccount.com\n",
      "  role: roles/dataform.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-discoveryengine.iam.gserviceaccount.com\n",
      "  role: roles/discoveryengine.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@dlp-api.iam.gserviceaccount.com\n",
      "  role: roles/dlp.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:bqcx-1026793852137-te86@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  role: roles/documentai.apiUser\n",
      "- members:\n",
      "  - serviceAccount:bqcx-1026793852137-te86@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  role: roles/documentai.viewer\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-prod-dai-core.iam.gserviceaccount.com\n",
      "  role: roles/documentaicore.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:1026793852137@cloudservices.gserviceaccount.com\n",
      "  role: roles/editor\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-networkmanagement.iam.gserviceaccount.com\n",
      "  role: roles/networkmanagement.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-notebooks.iam.gserviceaccount.com\n",
      "  role: roles/notebooks.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:1026793852137-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:1026793852137@cloudservices.gserviceaccount.com\n",
      "  - user:admin@statmike.altostrat.com\n",
      "  role: roles/owner\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-pubsub.iam.gserviceaccount.com\n",
      "  role: roles/pubsub.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:1026793852137-compute@developer.gserviceaccount.com\n",
      "  role: roles/run.admin\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@serverless-robot-prod.iam.gserviceaccount.com\n",
      "  role: roles/run.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@service-networking.iam.gserviceaccount.com\n",
      "  role: roles/servicenetworking.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-speech.iam.gserviceaccount.com\n",
      "  role: roles/speech.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:1026793852137-compute@developer.gserviceaccount.com\n",
      "  role: roles/storage.objectAdmin\n",
      "- members:\n",
      "  - serviceAccount:bqcx-1026793852137-te86@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  role: roles/storage.objectViewer\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-workstations.iam.gserviceaccount.com\n",
      "  role: roles/workstations.serviceAgent\n",
      "etag: BwYLAfOW7Ak=\n",
      "version: 1\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects add-iam-policy-binding {BQ_PROJECT} --member=serviceAccount:{service_account} --role=roles/documentai.viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ca372566-d0aa-4bdb-a41b-a4e6bf268ad8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated IAM policy for project [statmike-mlops-349915].\n",
      "bindings:\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-aiplatform-cc.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.customCodeServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-aiplatform-vm.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.notebookServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-aiplatform.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:bqcx-1026793852137-bmph@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  - serviceAccount:bqcx-1026793852137-dyw1@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  - serviceAccount:bqcx-1026793852137-pdxa@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  - serviceAccount:bqcx-1026793852137-te86@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  - serviceAccount:bqcx-1026793852137-tqpc@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  - serviceAccount:bqcx-1026793852137-zfly@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.user\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-artifactregistry.iam.gserviceaccount.com\n",
      "  role: roles/artifactregistry.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:1026793852137-compute@developer.gserviceaccount.com\n",
      "  role: roles/bigquery.admin\n",
      "- members:\n",
      "  - serviceAccount:1026793852137@cloudservices.gserviceaccount.com\n",
      "  role: roles/bigquery.dataOwner\n",
      "- members:\n",
      "  - serviceAccount:1026793852137@cloudbuild.gserviceaccount.com\n",
      "  role: roles/cloudbuild.builds.builder\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-cloudbuild.iam.gserviceaccount.com\n",
      "  role: roles/cloudbuild.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcf-admin-robot.iam.gserviceaccount.com\n",
      "  role: roles/cloudfunctions.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-cloudscheduler.iam.gserviceaccount.com\n",
      "  role: roles/cloudscheduler.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@compute-system.iam.gserviceaccount.com\n",
      "  role: roles/compute.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@containerregistry.iam.gserviceaccount.com\n",
      "  role: roles/containerregistry.ServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@dataflow-service-producer-prod.iam.gserviceaccount.com\n",
      "  role: roles/dataflow.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-dataform.iam.gserviceaccount.com\n",
      "  role: roles/dataform.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-discoveryengine.iam.gserviceaccount.com\n",
      "  role: roles/discoveryengine.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@dlp-api.iam.gserviceaccount.com\n",
      "  role: roles/dlp.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:bqcx-1026793852137-te86@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  role: roles/documentai.apiUser\n",
      "- members:\n",
      "  - serviceAccount:bqcx-1026793852137-te86@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  role: roles/documentai.viewer\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-prod-dai-core.iam.gserviceaccount.com\n",
      "  role: roles/documentaicore.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:1026793852137@cloudservices.gserviceaccount.com\n",
      "  role: roles/editor\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-networkmanagement.iam.gserviceaccount.com\n",
      "  role: roles/networkmanagement.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-notebooks.iam.gserviceaccount.com\n",
      "  role: roles/notebooks.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:1026793852137-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:1026793852137@cloudservices.gserviceaccount.com\n",
      "  - user:admin@statmike.altostrat.com\n",
      "  role: roles/owner\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-pubsub.iam.gserviceaccount.com\n",
      "  role: roles/pubsub.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:1026793852137-compute@developer.gserviceaccount.com\n",
      "  role: roles/run.admin\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@serverless-robot-prod.iam.gserviceaccount.com\n",
      "  role: roles/run.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@service-networking.iam.gserviceaccount.com\n",
      "  role: roles/servicenetworking.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-speech.iam.gserviceaccount.com\n",
      "  role: roles/speech.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:1026793852137-compute@developer.gserviceaccount.com\n",
      "  role: roles/storage.objectAdmin\n",
      "- members:\n",
      "  - serviceAccount:bqcx-1026793852137-te86@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  role: roles/storage.objectViewer\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-workstations.iam.gserviceaccount.com\n",
      "  role: roles/workstations.serviceAgent\n",
      "etag: BwYLAfOxSRU=\n",
      "version: 1\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects add-iam-policy-binding {BQ_PROJECT} --member=serviceAccount:{service_account} --role=roles/documentai.apiUser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "78d7aff3-a7ab-4b14-b301-cc05053f9874",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated IAM policy for project [statmike-mlops-349915].\n",
      "bindings:\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-aiplatform-cc.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.customCodeServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-aiplatform-vm.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.notebookServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-aiplatform.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:bqcx-1026793852137-bmph@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  - serviceAccount:bqcx-1026793852137-dyw1@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  - serviceAccount:bqcx-1026793852137-pdxa@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  - serviceAccount:bqcx-1026793852137-te86@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  - serviceAccount:bqcx-1026793852137-tqpc@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  - serviceAccount:bqcx-1026793852137-zfly@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.user\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-artifactregistry.iam.gserviceaccount.com\n",
      "  role: roles/artifactregistry.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:1026793852137-compute@developer.gserviceaccount.com\n",
      "  role: roles/bigquery.admin\n",
      "- members:\n",
      "  - serviceAccount:1026793852137@cloudservices.gserviceaccount.com\n",
      "  role: roles/bigquery.dataOwner\n",
      "- members:\n",
      "  - serviceAccount:1026793852137@cloudbuild.gserviceaccount.com\n",
      "  role: roles/cloudbuild.builds.builder\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-cloudbuild.iam.gserviceaccount.com\n",
      "  role: roles/cloudbuild.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcf-admin-robot.iam.gserviceaccount.com\n",
      "  role: roles/cloudfunctions.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-cloudscheduler.iam.gserviceaccount.com\n",
      "  role: roles/cloudscheduler.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@compute-system.iam.gserviceaccount.com\n",
      "  role: roles/compute.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@containerregistry.iam.gserviceaccount.com\n",
      "  role: roles/containerregistry.ServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@dataflow-service-producer-prod.iam.gserviceaccount.com\n",
      "  role: roles/dataflow.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-dataform.iam.gserviceaccount.com\n",
      "  role: roles/dataform.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-discoveryengine.iam.gserviceaccount.com\n",
      "  role: roles/discoveryengine.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@dlp-api.iam.gserviceaccount.com\n",
      "  role: roles/dlp.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:bqcx-1026793852137-te86@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  role: roles/documentai.apiUser\n",
      "- members:\n",
      "  - serviceAccount:bqcx-1026793852137-te86@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  role: roles/documentai.viewer\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-prod-dai-core.iam.gserviceaccount.com\n",
      "  role: roles/documentaicore.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:1026793852137@cloudservices.gserviceaccount.com\n",
      "  role: roles/editor\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-networkmanagement.iam.gserviceaccount.com\n",
      "  role: roles/networkmanagement.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-notebooks.iam.gserviceaccount.com\n",
      "  role: roles/notebooks.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:1026793852137-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:1026793852137@cloudservices.gserviceaccount.com\n",
      "  - user:admin@statmike.altostrat.com\n",
      "  role: roles/owner\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-pubsub.iam.gserviceaccount.com\n",
      "  role: roles/pubsub.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:1026793852137-compute@developer.gserviceaccount.com\n",
      "  role: roles/run.admin\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@serverless-robot-prod.iam.gserviceaccount.com\n",
      "  role: roles/run.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@service-networking.iam.gserviceaccount.com\n",
      "  role: roles/servicenetworking.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-speech.iam.gserviceaccount.com\n",
      "  role: roles/speech.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:1026793852137-compute@developer.gserviceaccount.com\n",
      "  role: roles/storage.objectAdmin\n",
      "- members:\n",
      "  - serviceAccount:bqcx-1026793852137-te86@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  role: roles/storage.objectViewer\n",
      "- members:\n",
      "  - serviceAccount:service-1026793852137@gcp-sa-workstations.iam.gserviceaccount.com\n",
      "  role: roles/workstations.serviceAgent\n",
      "etag: BwYLAfPKojQ=\n",
      "version: 1\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects add-iam-policy-binding {BQ_PROJECT} --member=serviceAccount:{service_account} --role=roles/storage.objectViewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9cf450-e1dd-4ca2-93c6-6c9c0047e523",
   "metadata": {},
   "source": [
    "### Create The Remote Model In BigQuery\n",
    "\n",
    "TEMPORARILY HARD CODING PROCESSOR.  REPLACE with `PARSER.default_processor_version`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7165c167-f93f-4a2a-b047-1b283abd472e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DONE'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Remote Model In BigQuery\n",
    "query = f\"\"\"\n",
    "CREATE OR REPLACE MODEL `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE_PREFIX}_MODEL`\n",
    "    REMOTE WITH CONNECTION `{BQ_PROJECT}.{BQ_REGION}.{SERIES}_{EXPERIMENT}`\n",
    "    OPTIONS(\n",
    "        REMOTE_SERVICE_TYPE = 'cloud_ai_document_v1',\n",
    "        DOCUMENT_PROCESSOR = \"projects/1026793852137/locations/us/processors/e64d4e675abee19a/processorVersions/pretrained-invoice-v1.3-2022-07-15\"\n",
    "    )\n",
    "\"\"\"\n",
    "job = bq.query(query = query)\n",
    "job.result()\n",
    "job.state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1a1079-b77c-4ec3-9b75-dd0d09f31d4b",
   "metadata": {},
   "source": [
    "### Process Documents with SQL Using ML.PROCESS_DOCUMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "024ea4fb-c5ce-43dd-9182-3f64ed108c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "BadRequest",
     "evalue": "400 BigQuery ML inference using imported models and object tables requires a reservation, but no reservations were assigned for job type `QUERY` to project `statmike-mlops-349915` or its parent, in location `US`.\n\nLocation: US\nJob ID: 1385c64f-79c9-4c8f-83b1-1c4a8d4d801c\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 12\u001b[0m\n\u001b[1;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mCREATE OR REPLACE TABLE `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBQ_PROJECT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBQ_DATASET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBQ_TABLE_PREFIX\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_DOCUMENTS-PROCESSED` AS\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m    SELECT *\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m    WHERE content_type = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     11\u001b[0m job \u001b[38;5;241m=\u001b[39m bq\u001b[38;5;241m.\u001b[39mquery(query \u001b[38;5;241m=\u001b[39m query)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m job\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1580\u001b[0m, in \u001b[0;36mQueryJob.result\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retry_do_query \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m job_retry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1578\u001b[0m         do_get_result \u001b[38;5;241m=\u001b[39m job_retry(do_get_result)\n\u001b[0;32m-> 1580\u001b[0m     \u001b[43mdo_get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mGoogleAPICallError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1583\u001b[0m     exc\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m=\u001b[39m _EXCEPTION_FOOTER_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1584\u001b[0m         message\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39mmessage, location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation, job_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\n\u001b[1;32m   1585\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    346\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    348\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1570\u001b[0m, in \u001b[0;36mQueryJob.result.<locals>.do_get_result\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1567\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_do_query \u001b[38;5;241m=\u001b[39m retry_do_query\n\u001b[1;32m   1568\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_job_retry \u001b[38;5;241m=\u001b[39m job_retry\n\u001b[0;32m-> 1570\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mQueryJob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;66;03m# Since the job could already be \"done\" (e.g. got a finished job\u001b[39;00m\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;66;03m# via client.get_job), the superclass call to done() might not\u001b[39;00m\n\u001b[1;32m   1574\u001b[0m \u001b[38;5;66;03m# set the self._query_results cache.\u001b[39;00m\n\u001b[1;32m   1575\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reload_query_results(retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/base.py:922\u001b[0m, in \u001b[0;36m_AsyncJob.result\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_begin(retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    921\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;129;01mis\u001b[39;00m DEFAULT_RETRY \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretry\u001b[39m\u001b[38;5;124m\"\u001b[39m: retry}\n\u001b[0;32m--> 922\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_AsyncJob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/future/polling.py:261\u001b[0m, in \u001b[0;36mPollingFuture.result\u001b[0;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking_poll(timeout\u001b[38;5;241m=\u001b[39mtimeout, retry\u001b[38;5;241m=\u001b[39mretry, polling\u001b[38;5;241m=\u001b[39mpolling)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# pylint: disable=raising-bad-type\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Pylint doesn't recognize that this is valid in this case.\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "\u001b[0;31mBadRequest\u001b[0m: 400 BigQuery ML inference using imported models and object tables requires a reservation, but no reservations were assigned for job type `QUERY` to project `statmike-mlops-349915` or its parent, in location `US`.\n\nLocation: US\nJob ID: 1385c64f-79c9-4c8f-83b1-1c4a8d4d801c\n"
     ]
    }
   ],
   "source": [
    "# CREATE table of processed documents\n",
    "query = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE_PREFIX}_DOCUMENTS-PROCESSED` AS\n",
    "    SELECT *\n",
    "    FROM ML.PROCESS_DOCUMENT(\n",
    "        MODEL `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE_PREFIX}_MODEL`,\n",
    "        TABLE `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE_PREFIX}_DOCUMENTS`\n",
    "    )\n",
    "    WHERE content_type = 'application/pdf'\n",
    "\"\"\"\n",
    "job = bq.query(query = query)\n",
    "job.result()\n",
    "job.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2da033-c52e-49da-a663-74867b18dd85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a4b087-5a14-4132-910f-4812c6f71482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
