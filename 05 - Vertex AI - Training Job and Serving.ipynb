{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "997d5c7f",
   "metadata": {},
   "source": [
    "# Vertex AI - Training Job and Serving\n",
    "\n",
    "This notebook creates a python package for a TensorFlow training project that uses the `<PROJECT_ID>.digits.digits_prepped` BigQuery table. Vertex AI clients are used to setup a Vertex AI custom training job to run the training package.  Then Vertex AI clients are used to upload the model and deploy it to an endpoint for online predictions.\n",
    "\n",
    "**Prerequisites**\n",
    "- `00 - Initial Setup`\n",
    "- `01 - BigQuery - Data`\n",
    "- `04 - Vertex AI - Notebook` (helpful to understand)\n",
    "    - the model created here is stored in a python package in this notebook\n",
    "    \n",
    "**Resources**\n",
    "- Adopted From:\n",
    "    - https://github.com/GoogleCloudPlatform/ai-platform-samples/blob/master/ai-platform-unified/notebooks/custom_job_image_classification_model_for_online_prediction.ipynb\n",
    "- Using Google Cloud Client Libraries (Python for Vertex AI):\n",
    "    - https://googleapis.dev/python/aiplatform/latest/index.html\n",
    "\n",
    "**Overview**\n",
    "\n",
    "<img src=\"architectures/statmike-mlops-05.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a16e05b",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b643505e",
   "metadata": {},
   "source": [
    "Setup the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b1d4b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13e812d",
   "metadata": {},
   "source": [
    "Define Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4562a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locations\n",
    "REGION = 'us-central1'\n",
    "PROJECT_ID='statmike-mlops'\n",
    "BUCKET_NAME='gs://{}/digits/model/05_aip_train_job'.format(PROJECT_ID)\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "JOB_NAME='05_AIP_DIGITS_'+TIMESTAMP\n",
    "MODEL_DIR = '{}/{}'.format(BUCKET_NAME, JOB_NAME)\n",
    "PARENT = \"projects/\" + PROJECT_ID + \"/locations/\" + REGION\n",
    "\n",
    "# Resources\n",
    "TRAIN_IMAGE='us-docker.pkg.dev/cloud-aiplatform/training/tf-cpu.2-4:latest'\n",
    "DEPLOY_IMAGE ='us-docker.pkg.dev/cloud-aiplatform/prediction/tf2-cpu.2-3:latest'\n",
    "TRAIN_COMPUTE='n1-standard-4'\n",
    "DEPLOY_COMPUTE='n1-standard-4'\n",
    "\n",
    "# TF Parameters to pass\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae28c04",
   "metadata": {},
   "source": [
    "Setup AI Platform Python Clients\n",
    "- https://googleapis.dev/python/aiplatform/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea6729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "client_options = {\"api_endpoint\": API_ENDPOINT}\n",
    "clients = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df1d9d5",
   "metadata": {},
   "source": [
    "---\n",
    "## Training Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5acb78a",
   "metadata": {},
   "source": [
    "Create a client for the AIP Job Service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45319a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients['job'] = aiplatform.gapic.JobServiceClient(client_options=client_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0749e2d",
   "metadata": {},
   "source": [
    "Helper functions wrappers for interacting with the client: create, list, get, cancel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e66b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_job(custom_job):\n",
    "    response = clients['job'].create_custom_job(parent=PARENT, custom_job=CUSTOM_JOB)\n",
    "    print(\"name:\", response.name)\n",
    "    print(\"display_name:\", response.display_name)\n",
    "    print(\"state:\", response.state)\n",
    "    print(\"create_time:\", response.create_time)\n",
    "    print(\"update_time:\", response.update_time)\n",
    "    return response.name\n",
    "\n",
    "def list_custom_jobs():\n",
    "    response = clients['job'].list_custom_jobs(parent=PARENT)\n",
    "    for job in response:\n",
    "        print(response)\n",
    "        \n",
    "def get_custom_job(name, silent=False):\n",
    "    response = clients['job'].get_custom_job(name=name)\n",
    "    if silent:\n",
    "        return response\n",
    "    print(\"name:\", response.name)\n",
    "    print(\"display_name:\", response.display_name)\n",
    "    print(\"state:\", response.state)\n",
    "    print(\"create_time:\", response.create_time)\n",
    "    print(\"update_time:\", response.update_time)\n",
    "    return response\n",
    "\n",
    "def cancel_job(name):\n",
    "    try:\n",
    "        response = clients['job'].cancel_custom_job(name=name)\n",
    "        print(response)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979926d",
   "metadata": {},
   "source": [
    "Define job parameters to pass to the client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15bb1170",
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_SPEC = {\n",
    "    \"machine_type\": TRAIN_COMPUTE,\n",
    "    \"accelerator_count\": 0\n",
    "}\n",
    "\n",
    "\n",
    "CMDARGS = [\n",
    "    \"--epochs=\" + str(EPOCHS),\n",
    "    \"--batch_size=\" + str(BATCH_SIZE)\n",
    "]\n",
    "\n",
    "WORKER_POOL_SPEC = [\n",
    "    {\n",
    "        \"replica_count\": 1,\n",
    "        \"machine_spec\": MACHINE_SPEC,\n",
    "        \"python_package_spec\": {\n",
    "            \"executor_image_uri\": TRAIN_IMAGE,\n",
    "            \"package_uris\": [BUCKET_NAME + \"/trainer_cifar.tar.gz\"],\n",
    "            \"python_module\": \"trainer.task\",\n",
    "            \"args\": CMDARGS\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "JOB_SPEC = {\n",
    "    \"worker_pool_specs\": WORKER_POOL_SPEC,\n",
    "    \"base_output_directory\": {\"output_uri_prefix\": MODEL_DIR}\n",
    "    \n",
    "}\n",
    "\n",
    "CUSTOM_JOB = {\n",
    "    \"display_name\": JOB_NAME,\n",
    "    \"job_spec\": JOB_SPEC\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216003d1",
   "metadata": {},
   "source": [
    "Assemble the Python training package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a89f756d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0706 14:28:39.726228003      72 backup_poller.cc:133]       Run client channel backup poller: {\"created\":\"@1625581719.726114584\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":321,\"referenced_errors\":[{\"created\":\"@1625581719.726105773\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":952,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    }
   ],
   "source": [
    "!rm -rf custom\n",
    "!mkdir custom\n",
    "\n",
    "\n",
    "setup_py = \"from setuptools import setup\\n\\\n",
    "if __name__ == '__main__':\\n\\\n",
    "    setup()\"\n",
    "\n",
    "setup_py = \"import setuptools\\n\\\n",
    "REQUIRED_PACKAGES = ['tensorflow_io']\\n\\\n",
    "setuptools.setup(\\n\\\n",
    "    name='trainer',\\n\\\n",
    "    version='0.1',\\n\\\n",
    "    #install_requires=REQUIRED_PACKAGES,\\n\\\n",
    "    packages=setuptools.find_packages(),\\n\\\n",
    "    #include_package_data=True,\\n\\\n",
    "    description='Digit Training Package')\"\n",
    "\n",
    "!echo \"$setup_py\" > custom/setup.py\n",
    "\n",
    "!mkdir custom/trainer\n",
    "!touch custom/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e199128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing custom/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile custom/trainer/task.py\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "from tensorflow_io.bigquery import BigQueryReadSession\n",
    "import tensorflow as tf\n",
    "from google.cloud import bigquery\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "# the passed param, dest: a name for the param, default: if absent fetch this param from the OS, type: type to convert to, help: description of argument\n",
    "parser.add_argument('--model-dir', dest='model_dir', default=os.getenv(\"AIP_MODEL_DIR\"), type=str, help='Model dir.')\n",
    "parser.add_argument('--epochs',dest='epochs', default=10, type=int, help='Number of Epochs')\n",
    "parser.add_argument('--batch_size',dest='batch_size', default=32, type=int, help='Batch Size')\n",
    "#parser.add_argument('',dest='', default=, type=, help='')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# built in parameters for data source:\n",
    "PROJECT_ID='statmike-mlops'\n",
    "BQDATASET_ID='digits'\n",
    "BQTABLE_ID='digits_prepped'\n",
    "\n",
    "selected_fields = ['p0', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19', 'p20', 'p21', 'p22', 'p23', 'p24', 'p25', 'p26', 'p27', 'p28', 'p29', 'p30', 'p31', 'p32', 'p33', 'p34', 'p35', 'p36', 'p37', 'p38', 'p39', 'p40', 'p41', 'p42', 'p43', 'p44', 'p45', 'p46', 'p47', 'p48', 'p49', 'p50', 'p51', 'p52', 'p53', 'p54', 'p55', 'p56', 'p57', 'p58', 'p59', 'p60', 'p61', 'p62', 'p63', 'target']\n",
    "output_types = ['FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'INT64']\n",
    "\n",
    "feature_columns = []\n",
    "feature_layer_inputs = {}\n",
    "for header in selected_fields:\n",
    "    if header != 'target':\n",
    "        feature_columns.append(tf.feature_column.numeric_column(header))\n",
    "        feature_layer_inputs[header] = tf.keras.Input(shape=(1,),name=header)\n",
    "\n",
    "from tensorflow.python.framework import dtypes\n",
    "output_types = [dtypes.float64 if x=='FLOAT64' else dtypes.int64 for x in output_types]\n",
    "\n",
    "def transTable(row_dict):\n",
    "    target=row_dict.pop('target')\n",
    "    target = tf.one_hot(tf.cast(target,tf.int64),10)\n",
    "    target = tf.cast(target,tf.float32)\n",
    "    return(row_dict,target)\n",
    "\n",
    "client = BigQueryClient()\n",
    "session = client.read_session(\"projects/\"+PROJECT_ID,PROJECT_ID,BQTABLE_ID,BQDATASET_ID,selected_fields,output_types,row_restriction=\"SPLITS='TRAIN'\",requested_streams=3)\n",
    "table = session.parallel_read_rows()\n",
    "table = table.map(transTable)\n",
    "train = table.shuffle(100000).batch(args.batch_size)\n",
    "\n",
    "client = BigQueryClient()\n",
    "session = client.read_session(\"projects/\"+PROJECT_ID,PROJECT_ID,BQTABLE_ID,BQDATASET_ID,selected_fields,output_types,row_restriction=\"SPLITS='TEST'\",requested_streams=3)\n",
    "table = session.parallel_read_rows()\n",
    "table = table.map(transTable)\n",
    "test = table.batch(args.batch_size)\n",
    "\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "model = tf.keras.Model(inputs=[v for v in feature_layer_inputs.values()],outputs=tf.keras.layers.Dense(10,activation=tf.nn.softmax)(feature_layer_outputs))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "tf.keras.utils.plot_model(model,show_shapes=True, show_dtype=True)\n",
    "\n",
    "history = model.fit(train,epochs=args.epochs)\n",
    "\n",
    "model.save(args.model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f352b4d",
   "metadata": {},
   "source": [
    "Store the training package in a Cloud Storage Bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23146f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0706 14:29:09.726237545      88 backup_poller.cc:133]       Run client channel backup poller: {\"created\":\"@1625581749.726085150\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":321,\"referenced_errors\":[{\"created\":\"@1625581749.726074808\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":952,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "custom/\n",
      "custom/setup.py\n",
      "custom/trainer/\n",
      "custom/trainer/task.py\n",
      "custom/trainer/__init__.py\n",
      "Copying file://custom.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  1.6 KiB/  1.6 KiB]                                                \n",
      "Operation completed over 1 objects/1.6 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!rm -f custom.tar custom.tar.gz\n",
    "!tar cvf custom.tar custom\n",
    "!gzip custom.tar\n",
    "!gsutil cp custom.tar.gz $BUCKET_NAME/trainer_cifar.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfe5ea3",
   "metadata": {},
   "source": [
    "Submit the training job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59e6ba5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: projects/691911073727/locations/us-central1/customJobs/4009386742871228416\n",
      "display_name: 05_AIP_DIGITS_20210706142708\n",
      "state: JobState.JOB_STATE_PENDING\n",
      "create_time: 2021-07-06 14:29:19.069452+00:00\n",
      "update_time: 2021-07-06 14:29:19.069452+00:00\n"
     ]
    }
   ],
   "source": [
    "JOB_ID = create_custom_job(CUSTOM_JOB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff2de3d",
   "metadata": {},
   "source": [
    "Get information as the job runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d09a3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: projects/691911073727/locations/us-central1/customJobs/4009386742871228416\n",
      "display_name: 05_AIP_DIGITS_20210706142708\n",
      "state: JobState.JOB_STATE_SUCCEEDED\n",
      "create_time: 2021-07-06 14:29:19.069452+00:00\n",
      "update_time: 2021-07-06 14:40:37.872504+00:00\n"
     ]
    }
   ],
   "source": [
    "trainjob_response = get_custom_job(JOB_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d20232",
   "metadata": {},
   "source": [
    "---\n",
    "## Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2dcc92",
   "metadata": {},
   "source": [
    "---\n",
    "### Upload the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd00d1",
   "metadata": {},
   "source": [
    "Check that model training was successful (and update the path to the model store):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5e0e8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://statmike-mlops/digits/model/05_aip_train_job/05_AIP_DIGITS_20210706142708/model\n"
     ]
    }
   ],
   "source": [
    "if trainjob_response.state == aiplatform.gapic.JobState.JOB_STATE_SUCCEEDED:\n",
    "    MODEL_DIR = MODEL_DIR + \"/model\"\n",
    "    \n",
    "print(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dff5e7",
   "metadata": {},
   "source": [
    "Create a client to the Model Service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b20d45b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients['model'] = aiplatform.gapic.ModelServiceClient(client_options=client_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c27cf",
   "metadata": {},
   "source": [
    "Upload the model using the client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88aa5d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = {\n",
    "    \"display_name\": trainjob_response.display_name,\n",
    "    \"metadata_schema_uri\": \"\",\n",
    "    \"artifact_uri\": MODEL_DIR,\n",
    "    \"container_spec\": {\n",
    "        \"image_uri\": DEPLOY_IMAGE,\n",
    "        \"command\": [],\n",
    "        \"args\": [],\n",
    "        \"env\": [{\"name\": \"env_name\", \"value\": \"env_value\"}],\n",
    "        \"ports\": [{\"container_port\": 8080}],\n",
    "        \"predict_route\": \"\",\n",
    "        \"health_route\": \"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "uploaded_model = clients['model'].upload_model(parent=PARENT, model=MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21b5985",
   "metadata": {},
   "source": [
    "Review the uploaded models information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9223cbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/691911073727/locations/us-central1/models/4339649249529561088'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info = clients['model'].get_model(name=uploaded_model.result(timeout=180).model)\n",
    "model_info.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86fb8d8",
   "metadata": {},
   "source": [
    "---\n",
    "### Endpoint Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c013478a",
   "metadata": {},
   "source": [
    "Create a client to the endpoint service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58e1afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients['endpoint'] = aiplatform.gapic.EndpointServiceClient(client_options=client_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063081b7",
   "metadata": {},
   "source": [
    "Create the endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1196803",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT_NAME = 'ENDPOINT_'+JOB_NAME\n",
    "endpoint = clients['endpoint'].create_endpoint(parent=PARENT, endpoint={\"display_name\": ENDPOINT_NAME})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96ed5563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/691911073727/locations/us-central1/endpoints/5819970132516012032'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_info = clients['endpoint'].get_endpoint(name=endpoint.result(timeout=180).name)\n",
    "endpoint_info.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3842d532",
   "metadata": {},
   "source": [
    "---\n",
    "### Deploy Model to Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68683ceb",
   "metadata": {},
   "source": [
    "Setup Deployment Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bce31aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_SPEC = {\n",
    "    \"machine_type\": DEPLOY_COMPUTE,\n",
    "    \"accelerator_count\": 0,\n",
    "}\n",
    "DMODEL = {\n",
    "        \"model\": model_info.name,\n",
    "        \"display_name\": 'DEPLOYED_'+JOB_NAME,\n",
    "        \"dedicated_resources\": {\n",
    "            \"min_replica_count\": 1,\n",
    "            \"max_replica_count\": 2,\n",
    "            \"machine_spec\": MACHINE_SPEC\n",
    "        }   \n",
    "}\n",
    "TRAFFIC = {\n",
    "    '0' : 100\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77908ae",
   "metadata": {},
   "source": [
    "Deploy the Model to the Endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "777e81d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmodel = clients['endpoint'].deploy_model(endpoint=endpoint_info.name, deployed_model=DMODEL, traffic_split=TRAFFIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b951f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4618986775635820544'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmodel_info = dmodel.result().deployed_model\n",
    "dmodel_info.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91510ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/691911073727/locations/us-central1/endpoints/5819970132516012032\"\n",
       "display_name: \"ENDPOINT_05_AIP_DIGITS_20210706142708\"\n",
       "deployed_models {\n",
       "  id: \"4618986775635820544\"\n",
       "  model: \"projects/691911073727/locations/us-central1/models/4339649249529561088\"\n",
       "  display_name: \"DEPLOYED_05_AIP_DIGITS_20210706142708\"\n",
       "  create_time {\n",
       "    seconds: 1625582511\n",
       "    nanos: 621968000\n",
       "  }\n",
       "  dedicated_resources {\n",
       "    machine_spec {\n",
       "      machine_type: \"n1-standard-4\"\n",
       "    }\n",
       "    min_replica_count: 1\n",
       "    max_replica_count: 2\n",
       "  }\n",
       "}\n",
       "traffic_split {\n",
       "  key: \"4618986775635820544\"\n",
       "  value: 100\n",
       "}\n",
       "etag: \"AMEw9yMuZH3v75SbvDkHR6qYOQHqA-yUrDB7JIqh86a-hL52Hc1PhLSNzu3waoutyJb0\"\n",
       "create_time {\n",
       "  seconds: 1625582503\n",
       "  nanos: 740357000\n",
       "}\n",
       "update_time {\n",
       "  seconds: 1625582817\n",
       "  nanos: 907513000\n",
       "}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients['endpoint'].get_endpoint(name=endpoint_info.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c120c0",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b464ca5",
   "metadata": {},
   "source": [
    "Create a client to the prediction service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abeb164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients['prediction'] = aiplatform.gapic.PredictionServiceClient(client_options=client_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b81f42",
   "metadata": {},
   "source": [
    "Setup an observation for prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af4706ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 694.54query/s] \n",
      "Downloading: 100%|██████████| 366/366 [00:01<00:00, 326.91rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery pred\n",
    "SELECT *\n",
    "FROM `digits.digits_prepped`\n",
    "WHERE splits='TEST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d04a8dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>p9</th>\n",
       "      <th>...</th>\n",
       "      <th>p57</th>\n",
       "      <th>p58</th>\n",
       "      <th>p59</th>\n",
       "      <th>p60</th>\n",
       "      <th>p61</th>\n",
       "      <th>p62</th>\n",
       "      <th>p63</th>\n",
       "      <th>target</th>\n",
       "      <th>target_OE</th>\n",
       "      <th>SPLITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Even</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    p0   p1   p2   p3   p4   p5   p6   p7   p8   p9  ...  p57  p58  p59   p60  \\\n",
       "0  0.0  0.0  0.0  9.0  8.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  7.0  14.0   \n",
       "\n",
       "   p61  p62  p63  target  target_OE  SPLITS  \n",
       "0  9.0  0.0  0.0       0       Even    TEST  \n",
       "\n",
       "[1 rows x 67 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4fd6b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "newob = pred.loc[:0,'p0':'p63'].to_dict(orient='records')[0]\n",
    "#newob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e16871b",
   "metadata": {},
   "source": [
    "Request prediction from prediction service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3aa29a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "\n",
    "response = clients['prediction'].predict(endpoint=endpoint_info.name, instances=[json_format.ParseDict(newob, Value())], parameters=json_format.ParseDict({}, Value()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea007208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.872015238, 0.000258201791, 3.30423244e-09, 5.97235109e-12, 0.0258183852, 3.31672226e-07, 0.101762742, 1.96920397e-10, 0.000144183723, 8.55353562e-07]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3b753f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmax(response.predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e829a87",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62154c",
   "metadata": {},
   "source": [
    "## Remove Resources\n",
    "- undeploy model\n",
    "- delete endpoint\n",
    "- remove model\n",
    "- delete training > custom job\n",
    "- delete python training application:\n",
    "    - these could be used by later notebooks in this project:\n",
    "    - delete custom and custom.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ce3f05",
   "metadata": {},
   "source": [
    "Undeploy Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfbc2013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.api_core.operation.Operation at 0x7fd29f70be90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmodel = clients['endpoint'].get_endpoint(name=endpoint_info.name).deployed_models[0].id\n",
    "clients['endpoint'].undeploy_model(endpoint=endpoint_info.name, deployed_model_id=dmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3bbc99",
   "metadata": {},
   "source": [
    "Delete Endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c5a0b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.api_core.operation.Operation at 0x7fd29f7e84d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients['endpoint'].delete_endpoint(name=endpoint_info.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cf4088",
   "metadata": {},
   "source": [
    "Remove Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28ba55e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.api_core.operation.Operation at 0x7fd29effb150>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients['model'].delete_model(name=model_info.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9acc2fe",
   "metadata": {},
   "source": [
    "Delete Training > Custom Job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d806f082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.api_core.operation.Operation at 0x7fd29f70e550>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients['job'].delete_custom_job(name=trainjob_response.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7094cf6f",
   "metadata": {},
   "source": [
    "Delete Model Files: \n",
    "- This includes the training package and the saved model\n",
    "- These could be useful for other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b22b21ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Blob: statmike-mlops, digits/aip_train_job/AIP_DIGITS_20210413130018/, 1618319425187771>\n",
      "<Blob: statmike-mlops, digits/aip_train_job/AIP_DIGITS_20210413130018/model/, 1618319425350552>\n",
      "<Blob: statmike-mlops, digits/aip_train_job/AIP_DIGITS_20210413130018/model/assets/, 1618319427738045>\n",
      "<Blob: statmike-mlops, digits/aip_train_job/AIP_DIGITS_20210413130018/model/saved_model.pb, 1618319428158820>\n",
      "<Blob: statmike-mlops, digits/aip_train_job/AIP_DIGITS_20210413130018/model/variables/, 1618319425484405>\n",
      "<Blob: statmike-mlops, digits/aip_train_job/AIP_DIGITS_20210413130018/model/variables/variables.data-00000-of-00001, 1618319426990754>\n",
      "<Blob: statmike-mlops, digits/aip_train_job/AIP_DIGITS_20210413130018/model/variables/variables.index, 1618319427197772>\n",
      "<Blob: statmike-mlops, digits/aip_train_job/trainer_cifar.tar.gz, 1618318849607448>\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "gcs = storage.Client()\n",
    "\n",
    "path = gcs.bucket(PROJECT_ID)\n",
    "blobs = path.list_blobs(prefix='digits/aip_train_job')\n",
    "for blob in blobs:\n",
    "    print(blob)\n",
    "    blob.delete()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "managed-notebooks.m70",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/managed-notebooks:m70"
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
