{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08b4010a",
   "metadata": {},
   "source": [
    "![ga4](https://www.google-analytics.com/collect?v=2&tid=G-6VDTYWLKX6&cid=1&en=page_view&sid=1&dl=statmike%2Fvertex-ai-mlops%2F04+-+scikit-learn&dt=04g+-+Vertex+AI+Custom+Model+-+scikit-learn+-+Hyperparameter+Tuning+Job+With+Python+file.ipynb)\n",
    "\n",
    "# 04g - Vertex AI > Training > Hyperparameter Tuning Jobs\n",
    "\n",
    "**04 Series Overview**\n",
    "\n",
    "Where a model gets trained is where it consumes computing resources.  With Vertex AI, you have choices for configuring the computing resources available at training.  This notebook is an example of an execution environment.  When it was set up there were choices for machine type and accelerators (GPUs).  \n",
    "\n",
    "In the [04 - Vertex AI Custom Model - scikit-learn - in Notebook](./04%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20in%20Notebook.ipynb) notebook, the model training happened directly in the notebook.  The model was then imported to Vertex AI and deployed to an endpoint for online predictions. \n",
    "\n",
    "In this `04a-04i` series of demonstrations, the same model is trained using managed computing resources in Vertex AI Training as managed jobs.  These jobs will be demonstrated as:\n",
    "\n",
    "-  Custom Job that trains and saves (to GCS) a model from a python script (`04a`), python source distribution (`04b`), and custom container (`04c`)\n",
    "-  Training Pipeline that trains and registers a model from a python script (`04d`), python source distribution (`04e`), and custom container (`04f`)\n",
    "-  Hyperparameter Tuning Jobs from a python script (`04g`), python source distribution (`04h`), and custom container (`04i`)\n",
    "\n",
    "**This Notebook (`04g`): An extension of `04a` with Hyperparameter Tuning - And Tensorboard HParams**\n",
    "\n",
    "This notebook trains the same scikit-learn Keras model from [04 - Vertex AI Custom Model - scikit-learn - in Notebook](./04%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20in%20Notebook.ipynb) by first modifying and saving the training code to a Python script as shown in [04 - Vertex AI Custom Model - scikit-learn - Notebook to Script](./04%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20Notebook%20to%20Script.ipynb). \n",
    "\n",
    "The script is then used as an input for a Vertex AI > Training > Custom Job that is also assigned compute resources and a [pre-built container for custom training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers) for executing the training in a managed service. \n",
    "\n",
    "The Custom Job is then used as the input for a Vertex AI > Training > Hyperparameter Tuning Job.  This runs and manages the tuning loops for the number of trials in each loop, collects the metric(s) and manages the parameters with the selected search algorithm for parameter modification.\n",
    "\n",
    "This job is launched using the Vertex AI client library:\n",
    "- [Python Cloud Client Libraries](https://cloud.google.com/python/docs/reference)\n",
    "    - [google-cloud-aiplatform](https://cloud.google.com/python/docs/reference/aiplatform/latest)\n",
    "        - [`aiplatform` package](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform)\n",
    "            - Custom Job:\n",
    "                - [`aiplatform.CustomJob.from_local_script()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob#google_cloud_aiplatform_CustomJob_from_local_script)\n",
    "            - Hyperparameter Tuning Job:\n",
    "                - [`aiplatform.HyperparameterTuningJob()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.HyperparameterTuningJob#google_cloud_aiplatform_HyperparameterTuningJob)\n",
    "\n",
    "**Vertex AI Training**\n",
    "\n",
    "In Vertex AI Training you can run your training code as a job where you specify the compute resources to use. For tips on preparing code, running training jobs, and workflows for building custom containers with software and training code combined please visit these [tips notebooks](../Tips/readme.md) in this repository:\n",
    "- [Python Packages](../Tips/Python%20Packages.ipynb)\n",
    "- [Python Custom Containers](../Tips/Python%20Custom%20Containers.ipynb)\n",
    "- [Python Training](../Tips/Python%20Training.ipynb)\n",
    "\n",
    "<p align=\"center\" width=\"100%\">\n",
    "    <img src=\"../architectures/overview/training.png\" width=\"45%\">\n",
    "    &nbsp; &nbsp; &nbsp; &nbsp;\n",
    "    <img src=\"../architectures/overview/training2.png\" width=\"45%\">\n",
    "</p>\n",
    "\n",
    "**Prerequisites:**\n",
    "-  [01 - BigQuery - Table Data Source](../01%20-%20Data%20Sources/01%20-%20BigQuery%20-%20Table%20Data%20Source.ipynb)\n",
    "-  Understanding:\n",
    "    -  Model overview in [04 - Vertex AI Custom Model - scikit-learn - in Notebook](./04%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20in%20Notebook.ipynb)\n",
    "    -  Convert notebook code to Python Script in [04 - Vertex AI Custom Model - scikit-learn - Notebook to Script](./04%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20Notebook%20to%20Script.ipynb)\n",
    "\n",
    "**Resources:**\n",
    "-  [sklearn](https://scikit-learn.org/stable/)\n",
    "-  [Python Client For Google BigQuery](https://googleapis.dev/python/bigquery/latest/index.html)\n",
    "-  [Python Client for Vertex AI](https://googleapis.dev/python/aiplatform/latest/aiplatform.html)\n",
    "-  Containers for training (Pre-Built)\n",
    "   -  [Overview](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container)\n",
    "   -  [List](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers)\n",
    "-  Vertex AI Hyperparameter Tuning\n",
    "   -  [Overview of Hyperparameter Tuning](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview)\n",
    "   -  [Using Hyperparameter Tuning](https://cloud.google.com/vertex-ai/docs/training/using-hyperparameter-tuning)\n",
    "\n",
    "**Conceptual Flow & Workflow**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img alt=\"Conceptual Flow\" src=\"../architectures/slides/05g_arch.png\" width=\"45%\">\n",
    "&nbsp; &nbsp; &nbsp; &nbsp;\n",
    "  <img alt=\"Workflow\" src=\"../architectures/slides/05g_console.png\" width=\"45%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aa954d",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05565fc",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c0d813b-0c5f-4ade-85b0-e8b3d12c0d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mg-ce-demos'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cbb3331",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = '04g'\n",
    "SERIES = '04'\n",
    "\n",
    "# source data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'fraud'\n",
    "BQ_TABLE = 'fraud_prepped'\n",
    "\n",
    "# Resources\n",
    "DEPLOY_IMAGE = 'us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-23:latest'\n",
    "TRAIN_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/scikit-learn-cpu.0-23:latest'\n",
    "TRAIN_COMPUTE = 'n1-standard-4'\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id-splits' + '-' + VAR_TARGET # add more variables to the string with space delimiters\n",
    "SOLVER = 'newton-cg'\n",
    "PENALTY = 'l2'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9328f759",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b9e6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "import pkg_resources\n",
    "from IPython.display import Markdown as md\n",
    "from google.cloud import bigquery\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca8d5b7",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7f7b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bq = bigquery.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ed844",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2c63af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = PROJECT_ID\n",
    "URI = f\"gs://{BUCKET}/{SERIES}/{EXPERIMENT}\"\n",
    "DIR = f\"temp/{EXPERIMENT}\"\n",
    "BLOB = f\"{SERIES}/{EXPERIMENT}/models/{TIMESTAMP}/model/model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a3b448f-564f-445e-9658-2fdd9323026e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mg-ce-demos-main@mg-ce-demos.iam.gserviceaccount.com'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a39b16-d043-4342-9002-449d6844b354",
   "metadata": {},
   "source": [
    "List the service accounts current roles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31ce5756-da2b-4be5-9994-403e3c67fc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE\n",
      "roles/aiplatform.admin\n",
      "roles/bigquery.admin\n",
      "roles/editor\n",
      "roles/storage.objectAdmin\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects get-iam-policy $PROJECT_ID --filter=\"bindings.members:$SERVICE_ACCOUNT\" --format='table(bindings.role)' --flatten=\"bindings[].members\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95c8103-7656-4903-af1c-cb4ba80ce7be",
   "metadata": {},
   "source": [
    ">Note: If the resulting list is missing [roles/storage.objectAdmin](https://cloud.google.com/storage/docs/access-control/iam-roles) then [revisit the setup notebook](../00%20-%20Setup/00%20-%20Environment%20Setup.ipynb#permissions) and add this permission to the service account with the provided instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476af43c",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "194cf496",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600913c-5696-44dd-9789-c06a2434eaae",
   "metadata": {},
   "source": [
    "Experiment Tracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "904180b8-9685-4d4a-82f7-7bfacdce1edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMEWORK = 'sklearn'\n",
    "TASK = 'classification'\n",
    "MODEL_TYPE = 'logistric-regression'\n",
    "EXPERIMENT_NAME = f'experiment-{SERIES}-{EXPERIMENT}-{FRAMEWORK}-{TASK}-{MODEL_TYPE}'\n",
    "RUN_NAME = f'run-{TIMESTAMP}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b71cfa9-24fb-41e0-9c02-85cb9107a6bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Setup Vertex AI Experiments\n",
    "\n",
    "The code in this section initializes the experiment and starts a run that represents this notebook.  Throughout the notebook sections for model training and evaluation information will be logged to the experiment using:\n",
    "- [.log_params](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_params)\n",
    "- [.log_metrics](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_metrics)\n",
    "- [.log_time_series_metrics](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_time_series_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b50688f8-8c11-462a-9a37-6f503a7cd85d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.init(experiment = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06880307",
   "metadata": {},
   "source": [
    "---\n",
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9fd5db-d08f-4449-8902-965ff0d2a448",
   "metadata": {},
   "source": [
    "### Python File for Training\n",
    "\n",
    "This notebook trains the same scikit-learn Keras model from [04 - Vertex AI Custom Model - scikit-learn - in Notebook](./04%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20in%20Notebook.ipynb) by first modifying and saving the training code to a python script as shown in [04 - Vertex AI Custom Model - scikit-learn - Notebook to Hyperparameter Tuning Script.ipynb](./04%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20Notebook%20to%20Hyperparameter%20Tuning%20Script.ipynb) which stores the script in [`./code/hp_train.py`](./code/hp_train.py).\n",
    "\n",
    "**Review the script:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b59ef69-fb65-4f4a-ad00-d0ea4e1572d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "\n",
       "\n",
       "# package import\n",
       "import sklearn\n",
       "from sklearn.preprocessing import StandardScaler\n",
       "from sklearn.linear_model import LogisticRegression\n",
       "from sklearn.pipeline import Pipeline\n",
       "from sklearn import metrics\n",
       "\n",
       "import pickle\n",
       "import pandas as pd \n",
       "import numpy as np \n",
       "\n",
       "from google.cloud import bigquery\n",
       "from google.cloud import aiplatform\n",
       "from google.cloud import storage\n",
       "import argparse\n",
       "import os\n",
       "import sys\n",
       "import hypertune\n",
       "#from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
       "\n",
       "# import argument to local variables\n",
       "parser = argparse.ArgumentParser()\n",
       "# the passed param, dest: a name for the param, default: if absent fetch this param from the OS, type: type to convert to, help: description of argument\n",
       "parser.add_argument('--penalty', dest = 'penalty', default = 'l2', type = str, help = 'Penalty term')\n",
       "parser.add_argument('--solver', dest = 'solver', default = 'newton-cg', type = str, help = 'Logistic regression solver')\n",
       "parser.add_argument('--var_target', dest = 'var_target', type=str)\n",
       "parser.add_argument('--var_omit', dest = 'var_omit', type=str)\n",
       "parser.add_argument('--project_id', dest = 'project_id', type=str)\n",
       "parser.add_argument('--bq_project', dest = 'bq_project', type=str)\n",
       "parser.add_argument('--bq_dataset', dest = 'bq_dataset', type=str)\n",
       "parser.add_argument('--bq_table', dest = 'bq_table', type=str)\n",
       "parser.add_argument('--region', dest = 'region', type=str)\n",
       "parser.add_argument('--experiment', dest = 'experiment', type=str)\n",
       "parser.add_argument('--series', dest = 'series', type=str)\n",
       "parser.add_argument('--experiment_name', dest = 'experiment_name', type=str)\n",
       "parser.add_argument('--run_name', dest = 'run_name', type=str)\n",
       "parser.add_argument('--bucket', dest = 'bucket', type=str)\n",
       "parser.add_argument('--uri', dest = 'uri', type=str)\n",
       "parser.add_argument('--blob', dest = 'blob', type=str)\n",
       "parser.add_argument('--timestamp', dest = 'timestamp', type=str)\n",
       "\n",
       "# hyperparameters\n",
       "parser.add_argument('--C', dest = 'C', type=str)\n",
       "args = parser.parse_args()\n",
       "\n",
       "# Model Training\n",
       "VAR_TARGET = str(args.var_target)\n",
       "VAR_OMIT = str(args.var_omit).split('-')\n",
       "\n",
       "# clients\n",
       "bq = bigquery.Client(project = args.project_id)\n",
       "aiplatform.init(project = args.project_id, location = args.region)\n",
       "hpt = hypertune.HyperTune()\n",
       "args.run_name = f'{args.run_name}-{hpt.trial_id}'\n",
       "\n",
       "# Vertex AI Experiment\n",
       "if args.run_name in [run.name for run in aiplatform.ExperimentRun.list(experiment = args.experiment_name)]:\n",
       "    expRun = aiplatform.ExperimentRun(run_name = args.run_name, experiment = args.experiment_name)\n",
       "else:\n",
       "    expRun = aiplatform.ExperimentRun.create(run_name = args.run_name, experiment = args.experiment_name)\n",
       "expRun.log_params({'experiment': args.experiment, 'series': args.series, 'project_id': args.project_id})\n",
       "expRun.log_params({'hyperparameter.C': args.C})\n",
       "\n",
       "# get schema from bigquery source\n",
       "query = f\"SELECT * FROM {args.bq_project}.{args.bq_dataset}.INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{args.bq_table}'\"\n",
       "schema = bq.query(query).to_dataframe()\n",
       "\n",
       "# get number of classes from bigquery source\n",
       "nclasses = bq.query(query = f'SELECT DISTINCT {VAR_TARGET} FROM {args.bq_project}.{args.bq_dataset}.{args.bq_table} WHERE {VAR_TARGET} is not null').to_dataframe()\n",
       "nclasses = nclasses.shape[0]\n",
       "expRun.log_params({'data_source': f'bq://{args.bq_project}.{args.bq_dataset}.{args.bq_table}', 'nclasses': nclasses, 'var_split': 'splits', 'var_target': VAR_TARGET})\n",
       "\n",
       "train_query = f\"SELECT * FROM {args.bq_project}.{args.bq_dataset}.{args.bq_table} WHERE splits = 'TRAIN'\"\n",
       "train = bq.query(train_query).to_dataframe()\n",
       "X_train = train.loc[:, ~train.columns.isin(VAR_OMIT)]\n",
       "y_train = train[VAR_TARGET].astype('int')\n",
       "\n",
       "val_query = f\"SELECT * FROM {args.bq_project}.{args.bq_dataset}.{args.bq_table} WHERE splits = 'VALIDATE'\"\n",
       "val = bq.query(val_query).to_dataframe()\n",
       "X_val = val.loc[:, ~val.columns.isin(VAR_OMIT)]\n",
       "y_val = val[VAR_TARGET].astype('int')\n",
       "\n",
       "test_query = f\"SELECT * FROM {args.bq_project}.{args.bq_dataset}.{args.bq_table} WHERE splits = 'TEST'\"\n",
       "test = bq.query(test_query).to_dataframe()\n",
       "X_test = test.loc[:, ~test.columns.isin(VAR_OMIT)]\n",
       "y_test = test[VAR_TARGET].astype('int')\n",
       "\n",
       "# Logistic Regression\n",
       "# instantiate the model \n",
       "logistic = LogisticRegression(solver=args.solver, penalty=args.penalty, C=args.C)\n",
       "\n",
       "# Define a Standard Scaler to normalize inputs\n",
       "scaler = StandardScaler()\n",
       "\n",
       "expRun.log_params({'solver': args.solver, 'penalty': args.penalty, 'C':args.C})\n",
       "\n",
       "# define pipeline\n",
       "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"logistic\", logistic)])\n",
       "\n",
       "# define grid search model\n",
       "model = pipe.fit(X_train, y_train)\n",
       "\n",
       "# test evaluations:\n",
       "y_pred = model.predict(X_test)\n",
       "test_acc = metrics.accuracy_score(y_test, y_pred) \n",
       "test_prec = metrics.precision_score(y_test, y_pred)\n",
       "test_rec = metrics.recall_score(y_test, y_pred)\n",
       "test_rocauc = metrics.roc_auc_score(y_test, y_pred)\n",
       "expRun.log_metrics({'test_accuracy': test_acc, 'test_precision': test_prec, 'test_recall': test_rec, 'test_roc_auc': test_rocauc})\n",
       "\n",
       "# val evaluations:\n",
       "y_pred_val = model.predict(X_val)\n",
       "val_acc = metrics.accuracy_score(y_val, y_pred_val) \n",
       "val_prec = metrics.precision_score(y_val, y_pred_val)\n",
       "val_rec = metrics.recall_score(y_val, y_pred_val)\n",
       "val_rocauc = metrics.roc_auc_score(y_val, y_pred_val)\n",
       "expRun.log_metrics({'validation_accuracy': val_acc, 'validation_precision': val_prec, 'validation_recall': val_rec, 'validation_roc_auc': val_rocauc})\n",
       "\n",
       "# training evaluations:\n",
       "y_pred_training = model.predict(X_train)\n",
       "training_acc = metrics.accuracy_score(y_train, y_pred_training) \n",
       "training_prec = metrics.precision_score(y_train, y_pred_training)\n",
       "training_rec = metrics.recall_score(y_train, y_pred_training)\n",
       "training_rocauc = metrics.roc_auc_score(y_train, y_pred_training)\n",
       "expRun.log_metrics({'training_accuracy': training_acc, 'training_precision':training_prec, 'training_recall': training_rec, 'training_roc_auc': training_rocauc})\n",
       "\n",
       "# report hypertune info back to Vertex AI Training > Hyperparamter Tuning Job\n",
       "hpt.report_hyperparameter_tuning_metric(\n",
       "    hyperparameter_metric_tag = 'roc_auc',\n",
       "    metric_value = test_rocauc)\n",
       "\n",
       "# output the model save files\n",
       "with open('model.pkl','wb') as f:\n",
       "    pickle.dump(model,f)\n",
       "    \n",
       "# Upload the model to GCS\n",
       "bucket = storage.Client().bucket(args.bucket)\n",
       "blob = bucket.blob(args.blob)\n",
       "blob.upload_from_filename('model.pkl')\n",
       "\n",
       "expRun.log_params({'model.save': f'{args.uri}/models/{args.timestamp}/model'})\n",
       "expRun.end_run()\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCRIPT_PATH = './code/hp_train.py'\n",
    "\n",
    "with open(SCRIPT_PATH, 'r') as file:\n",
    "    data = file.read()\n",
    "md(f\"```python\\n\\n{data}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ea9334",
   "metadata": {},
   "source": [
    "### Setup Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f99fcc8-7eaf-4086-b214-04b3159d5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMDARGS = [\n",
    "    \"--penalty=\" + PENALTY,\n",
    "    \"--solver=\" + SOLVER,\n",
    "    \"--var_target=\" + VAR_TARGET,\n",
    "    \"--var_omit=\" + VAR_OMIT,\n",
    "    \"--project_id=\" + PROJECT_ID,\n",
    "    \"--bq_project=\" + BQ_PROJECT,\n",
    "    \"--bq_dataset=\" + BQ_DATASET,\n",
    "    \"--bq_table=\" + BQ_TABLE,\n",
    "    \"--region=\" + REGION,\n",
    "    \"--experiment=\" + EXPERIMENT,\n",
    "    \"--series=\" + SERIES,\n",
    "    \"--experiment_name=\" + EXPERIMENT_NAME,\n",
    "    \"--run_name=\" + RUN_NAME,\n",
    "    \"--bucket=\" + BUCKET,\n",
    "    \"--uri=\" + URI,\n",
    "    \"--blob=\" + BLOB,\n",
    "    \"--timestamp=\" + TIMESTAMP\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a2b628d-f699-467e-9ca6-2e1d1080f191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training script copied to:\n",
      "gs://mg-ce-demos/04/04g/models/20230221091933/aiplatform-2023-02-21-09:19:47.840-aiplatform_custom_trainer_script-0.1.tar.gz.\n"
     ]
    }
   ],
   "source": [
    "customJob = aiplatform.CustomJob.from_local_script(\n",
    "    display_name = f'{SERIES}_{EXPERIMENT}_{TIMESTAMP}',\n",
    "    script_path = SCRIPT_PATH,\n",
    "    container_uri = TRAIN_IMAGE,\n",
    "    args = CMDARGS,\n",
    "    requirements = ['google-cloud-aiplatform', 'protobuf',  'db-dtypes>=1.0.0', 'google-auth>=2.6.0', 'google-cloud-bigquery>=3.0.1'],\n",
    "    replica_count = 1,\n",
    "    machine_type = TRAIN_COMPUTE,\n",
    "    accelerator_count = 0,\n",
    "    base_output_dir = f\"{URI}/models/{TIMESTAMP}\",\n",
    "    staging_bucket = f\"{URI}/models/{TIMESTAMP}\",\n",
    "    labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04b2e81",
   "metadata": {},
   "source": [
    "### Setup Hyperparameter Tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aea9f388-7bb8-4691-a9ef-1a46257e5d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_SPEC = {\n",
    "    \"auc_roc\": \"maximize\"\n",
    "}\n",
    "\n",
    "PARAMETER_SPEC = {\n",
    "    \"C\": aiplatform.hyperparameter_tuning.DiscreteParameterSpec(values=[0.1, 1.0, 10.0], scale='linear')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4e0035e-67fc-44e2-a8e3-0ec9da50f7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuningJob = aiplatform.HyperparameterTuningJob(\n",
    "    display_name = f'{SERIES}_{EXPERIMENT}_{TIMESTAMP}',\n",
    "    custom_job = customJob,\n",
    "    metric_spec = METRIC_SPEC,\n",
    "    parameter_spec = PARAMETER_SPEC,\n",
    "    max_trial_count = 10,\n",
    "    parallel_trial_count = 3,\n",
    "    search_algorithm = None,\n",
    "    labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6249099",
   "metadata": {},
   "source": [
    "### Run Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cc277b5-dfbf-4081-9610-86801aa55631",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating HyperparameterTuningJob\n",
      "HyperparameterTuningJob created. Resource name: projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672\n",
      "To use this HyperparameterTuningJob in another session:\n",
      "hpt_job = aiplatform.HyperparameterTuningJob.get('projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672')\n",
      "View HyperparameterTuningJob:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/2905748235639324672?project=633472233130\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/633472233130/locations/us-central1/hyperparameterTuningJobs/2905748235639324672 current state:\n",
      "JobState.JOB_STATE_FAILED\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Job failed with:\ncode: 3\nmessage: \"Hyperparameter Tuning Trial #1 Failed before any other successful trials were completed. The failed trial had parameters: C=1.0000000000000002, .  The trial\\'s error message was: The replica workerpool0-0 exited with a non-zero status of 1. \\nTraceback (most recent call last):\\n  File \\\"/usr/lib/python3.7/runpy.py\\\", line 193, in _run_module_as_main\\n    \\\"__main__\\\", mod_spec)\\n  File \\\"/usr/lib/python3.7/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \\\"/root/.local/lib/python3.7/site-packages/aiplatform_custom_trainer_script/task.py\\\", line 102, in <module>\\n    model = pipe.fit(X_train, y_train)\\n  File \\\"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\\\", line 335, in fit\\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\\n  File \\\"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\\\", line 1308, in fit\\n    % self.C)\\nValueError: Penalty term must be positive; got (C=\\'1.0000000000000002\\')\\n\\nTo find out more about why your job exited please check the logs: https://console.cloud.google.com/logs/viewer?project=633472233130&resource=ml_job%2Fjob_id%2F2905748235639324672&advancedFilter=resource.type%3D%22ml_job%22%0Aresource.labels.job_id%3D%222905748235639324672%22\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q8/1gf829m141157nbz7kc4_19h00tb0q/T/ipykernel_68671/3641136950.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m tuningJob.run(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mservice_account\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSERVICE_ACCOUNT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m~/Documents/developer/venv37/lib/python3.7/site-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, service_account, network, timeout, restart_job_on_worker_restart, enable_web_access, tensorboard, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m   2103\u001b[0m             \u001b[0mtensorboard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m             \u001b[0msync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2105\u001b[0;31m             \u001b[0mcreate_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_request_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2106\u001b[0m         )\n\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv37/lib/python3.7/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv37/lib/python3.7/site-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, service_account, network, timeout, restart_job_on_worker_restart, enable_web_access, tensorboard, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m   2203\u001b[0m             )\n\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2205\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2207\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/developer/venv37/lib/python3.7/site-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;31m# JOB_STATE_FAILED or JOB_STATE_CANCELLED.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_JOB_ERROR_STATES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job failed with:\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m             \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_action_completed_against_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Job failed with:\ncode: 3\nmessage: \"Hyperparameter Tuning Trial #1 Failed before any other successful trials were completed. The failed trial had parameters: C=1.0000000000000002, .  The trial\\'s error message was: The replica workerpool0-0 exited with a non-zero status of 1. \\nTraceback (most recent call last):\\n  File \\\"/usr/lib/python3.7/runpy.py\\\", line 193, in _run_module_as_main\\n    \\\"__main__\\\", mod_spec)\\n  File \\\"/usr/lib/python3.7/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \\\"/root/.local/lib/python3.7/site-packages/aiplatform_custom_trainer_script/task.py\\\", line 102, in <module>\\n    model = pipe.fit(X_train, y_train)\\n  File \\\"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\\\", line 335, in fit\\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\\n  File \\\"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\\\", line 1308, in fit\\n    % self.C)\\nValueError: Penalty term must be positive; got (C=\\'1.0000000000000002\\')\\n\\nTo find out more about why your job exited please check the logs: https://console.cloud.google.com/logs/viewer?project=633472233130&resource=ml_job%2Fjob_id%2F2905748235639324672&advancedFilter=resource.type%3D%22ml_job%22%0Aresource.labels.job_id%3D%222905748235639324672%22\"\n"
     ]
    }
   ],
   "source": [
    "tuningJob.run(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fdc0eb-77d9-4760-896d-53b1c018dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuningJob.resource_name, tuningJob.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16e26e7-2cd1-4e55-af42-11563d0cdbc6",
   "metadata": {},
   "source": [
    "Create hyperlinks to job and tensorboard here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2895cc0-88f2-46bc-ba91-0851e5ce0426",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_link = f\"https://console.cloud.google.com/ai/platform/locations/{REGION}/training/{tuningJob.resource_name.split('/')[-1]}?project={PROJECT_ID}\"\n",
    "\n",
    "print(f'Review the Job here:\\n{job_link}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8acff2-6daf-49e4-b6a0-c80df5d8058c",
   "metadata": {},
   "source": [
    "### Get Best Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faed179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if trial.state.name == 'SUCCEEDED'\n",
    "auc_roc = [trial.final_measurement.metrics[0].value if trial.state.name == 'SUCCEEDED' else 1 for trial in tuningJob.trials]\n",
    "auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e699294",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = tuningJob.trials[auc_roc.index(max(auc_roc))]\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471aa31a-122f-4147-aa4c-9776c12fa443",
   "metadata": {},
   "outputs": [],
   "source": [
    "best.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4bf665",
   "metadata": {},
   "source": [
    "---\n",
    "## Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bda4198",
   "metadata": {},
   "source": [
    "### Upload The Model\n",
    "Only upload the best model from the hyperparmeter tuning job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af63fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelmatch = aiplatform.Model.list(filter = f'display_name={SERIES}_{EXPERIMENT} AND labels.series={SERIES} AND labels.experiment={EXPERIMENT}')\n",
    "\n",
    "upload_model = True\n",
    "if modelmatch:\n",
    "    print(\"Model Already in Registry:\")\n",
    "    if f'{RUN_NAME}-{best.id}' in modelmatch[0].version_aliases:\n",
    "        print(\"This version already loaded, no action taken.\")\n",
    "        upload_model = False\n",
    "        model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n",
    "    else:\n",
    "        print('Loading model as new default version.')\n",
    "        parent_model = modelmatch[0].resource_name\n",
    "\n",
    "else:\n",
    "    print('This is a new model, creating in model registry')\n",
    "    parent_model = ''\n",
    "\n",
    "if upload_model:\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name = f'{SERIES}_{EXPERIMENT}',\n",
    "        model_id = f'model_{SERIES}_{EXPERIMENT}',\n",
    "        parent_model =  parent_model,\n",
    "        serving_container_image_uri = DEPLOY_IMAGE,\n",
    "        artifact_uri = f\"{URI}/models/{TIMESTAMP}/{best.id}/model\",\n",
    "        is_default_version = True,\n",
    "        version_aliases = [f'{RUN_NAME}-{best.id}'],\n",
    "        version_description = f'{RUN_NAME}-{best.id}',\n",
    "        labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}-{best.id}'}        \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae670bf1-ba26-4e7f-ae65-8e24c047b9f3",
   "metadata": {},
   "source": [
    ">**Note** on Version Aliases:\n",
    ">Expectation is a name starting with `a-z` that can include `[a-zA-Z0-9-]`\n",
    ">\n",
    ">**Retrieve a Model Resource**\n",
    ">[aiplatform.Model()](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Model)\n",
    ">```Python\n",
    "model = aiplatform.Model(model_name = f'model_{SERIES}_{EXPERIMENT}') # retrieves default version\n",
    "model = aiplatform.Model(model_name = f'model_{SERIES}_{EXPERIMENT}@time-{TIMESTAMP}') # retrieves specific version\n",
    "model = aiplatform.Model(model_name = f'model_{SERIES}_{EXPERIMENT}', version = f'time-{TIMESTAMP}') # retrieves specific version\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d16c9a1-030f-409a-b455-a42e84a964cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Review the model in the Vertex AI Model Registry:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/models/{model.name}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa43d924-491d-4257-aa58-ca0777877ef8",
   "metadata": {},
   "source": [
    "### Vertex AI Experiment Update and Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a85b24-9bcb-4d11-8818-f3e4f9a89f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun = aiplatform.ExperimentRun(run_name = f'{RUN_NAME}-{best.id}', experiment = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dbe229-564d-49fb-bbb2-280bfa07fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun.log_params({\n",
    "    'model.uri': model.uri,\n",
    "    'model.display_name': model.display_name,\n",
    "    'model.name': model.name,\n",
    "    'model.resource_name': model.resource_name,\n",
    "    'model.version_id': model.version_id,\n",
    "    'model.versioned_resource_name': model.versioned_resource_name,\n",
    "    'hyperparameterTuningJobs.display_name': tuningJob.display_name,\n",
    "    'hyperparameterTuning.resource_name': tuningJob.resource_name,\n",
    "    'hyperparameterTuning.link': job_link,\n",
    "    'hyperparameterTuning.tensorboard': board_link\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d46fbf9-b9dc-4ced-8c9d-8fbec99dcb79",
   "metadata": {},
   "source": [
    "Complete the experiment run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a1dcfe-1b4a-434d-85e9-acd9e5e557be",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun.update_state(state = aiplatform.gapic.Execution.State.COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab34bc6-53fa-45d5-880e-f1af9d2bd685",
   "metadata": {},
   "source": [
    "Need to add the `hyperparameterTuning` job information to each run of the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23da03c9-0b38-41c8-b1e3-1d35ab7943fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in tuningJob.trials:\n",
    "    expRun = aiplatform.ExperimentRun(run_name = f'{RUN_NAME}-{trial.id}', experiment = EXPERIMENT_NAME)\n",
    "    expRun.log_params({\n",
    "        'hyperparameterTuningJobs.display_name': tuningJob.display_name,\n",
    "        'hyperparameterTuning.resource_name': tuningJob.resource_name,\n",
    "        'hyperparameterTuning.link': job_link,\n",
    "        'hyperparameterTuning.tensorboard': board_link\n",
    "    })\n",
    "    expRun.update_state(state = aiplatform.gapic.Execution.State.COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa576c7-1cc7-45b7-a533-8c40baa611ce",
   "metadata": {},
   "source": [
    "Retrieve the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b4e1d3-9836-4aac-9286-c0a07d4ccdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = aiplatform.Experiment(experiment_name = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d603e1-b034-4469-a245-de9ab1334d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.get_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc69ae6-e0e3-4763-8471-bc2837d0675b",
   "metadata": {},
   "source": [
    "Review the Experiments TensorBoard to compare runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce18389-8484-4d5d-a30e-c4841eb52e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The Experiment TensorBoard Link:\\nhttps://{REGION}.tensorboard.googleusercontent.com/experiment/{tb.resource_name.replace('/', '+')}+experiments+{exp.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec7151d-9a4a-4907-b481-7faa89e0af42",
   "metadata": {},
   "source": [
    "### Review Experiment and Run in Console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b3eeaa-5cec-45e4-b764-576d6a0f2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Review The Experiment in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/experiments/{EXPERIMENT_NAME}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631226fd-c3d1-4b6b-9d3a-0bc129cca0fb",
   "metadata": {},
   "source": [
    "### Compare This Run Using Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc77160-5019-4f32-bd59-b8a5fc47be37",
   "metadata": {
    "tags": []
   },
   "source": [
    "Get a list of all experiments in this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb42949a-a4ab-4ef0-b163-ce89d2b58c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = aiplatform.Experiment.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf94d8e-3906-48f1-a2c7-d737a92bf1e6",
   "metadata": {},
   "source": [
    "Remove experiments not in the SERIES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd9424-3b50-4921-868e-e08eb6e2c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [e for e in experiments if e.name.split('-')[0:2] == ['experiment', SERIES]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69cbd44-d1aa-4b57-93e6-3fd8672a6f23",
   "metadata": {},
   "source": [
    "Combine the runs from all experiments in SERIES into a single dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7352f4-d50a-43c1-a342-a15ba06b1ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for experiment in experiments:\n",
    "        results.append(experiment.get_data_frame())\n",
    "        print(experiment.name)\n",
    "results = pd.concat(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad3c0bf-5a65-4219-be82-17cbc11c31f0",
   "metadata": {},
   "source": [
    "Create ranks for models within experiment and across the entire SERIES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd876a4-7984-4687-b42b-c829952c2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranker(metric = 'metric.test_auprc'):\n",
    "    ranks = results[['experiment_name', 'run_name', 'param.model.display_name', 'param.model.version_id', metric]].copy().reset_index(drop = True)\n",
    "    ranks = ranks[~ranks['param.model.display_name'].isnull()]\n",
    "    ranks['series_rank'] = ranks[metric].rank(method = 'dense', ascending = False)\n",
    "    ranks['experiment_rank'] = ranks.groupby('experiment_name')[metric].rank(method = 'dense', ascending = False)\n",
    "    return ranks.sort_values(by = ['experiment_name', 'run_name'])\n",
    "    \n",
    "ranks = ranker('metric.test_auprc')\n",
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae6903c-1986-47f8-b1e7-f05777ca6fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_rank = ranks.loc[(ranks['param.model.display_name'] == model.display_name) & (ranks['param.model.version_id'] == model.version_id)]\n",
    "current_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e45ccb7-8f93-4c12-9b7d-666fd8fa238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The current model is ranked {current_rank['experiment_rank'].iloc[0]} within this experiment and {current_rank['series_rank'].iloc[0]} across this series.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2851fff7-a7d3-4910-a20b-c72828f4da1d",
   "metadata": {},
   "source": [
    "### Create/Retrieve The Endpoint For This Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc28d98-b525-4385-9b95-489bf574f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = aiplatform.Endpoint.list(filter = f\"labels.series={SERIES}\")\n",
    "if endpoints:\n",
    "    endpoint = endpoints[0]\n",
    "    print(f\"Endpoint Exists: {endpoints[0].resource_name}\")\n",
    "else:\n",
    "    endpoint = aiplatform.Endpoint.create(\n",
    "        display_name = f\"{SERIES}\",\n",
    "        labels = {'series' : f\"{SERIES}\"}    \n",
    "    )\n",
    "    print(f\"Endpoint Created: {endpoint.resource_name}\")\n",
    "    \n",
    "print(f'Review the Endpoint in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/endpoints/{endpoint.name}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a538bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0029bd-9744-4449-91f0-56ef7ca5e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d06eba-82dc-4d50-8405-800d756e3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_models = endpoint.list_models()\n",
    "#deployed_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99cd8db-6b0b-4b8d-b147-769577037abc",
   "metadata": {},
   "source": [
    "### Should This Model Be Deployed?\n",
    "Is it better than the model already deployed on the endpoint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db9b246-2b03-4313-b620-5fc8029280b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy = False\n",
    "if deployed_models:\n",
    "    for deployed_model in deployed_models:\n",
    "        deployed_rank = ranks.loc[(ranks['param.model.display_name'] == deployed_model.display_name) & (ranks['param.model.version_id'] == deployed_model.model_version_id)]['series_rank'].iloc[0]\n",
    "        model_rank = current_rank['series_rank'].iloc[0]\n",
    "        if deployed_model.display_name == model.display_name and deployed_model.model_version_id == model.version_id:\n",
    "            print(f'The current model/version is already deployed.')\n",
    "            break\n",
    "        elif model_rank <= deployed_rank:\n",
    "            deploy = True\n",
    "            print(f'The current model is ranked better ({model_rank}) than a currently deployed model ({deployed_rank}).')\n",
    "            break\n",
    "    if deploy == False: print(f'The current model is ranked worse ({model_rank}) than a currently deployed model ({deployed_rank})')\n",
    "else: \n",
    "    deploy = True\n",
    "    print('No models currently deployed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647eebe7-b87f-4911-b101-1a8c2c8980da",
   "metadata": {},
   "source": [
    "### Deploy Model To Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa50205-0f93-423e-a622-4659f81e8674",
   "metadata": {},
   "outputs": [],
   "source": [
    "if deploy:\n",
    "    print(f'Deploying model with 100% of traffic...')\n",
    "    endpoint.deploy(\n",
    "        model = model,\n",
    "        deployed_model_display_name = model.display_name,\n",
    "        traffic_percentage = 100,\n",
    "        machine_type = DEPLOY_COMPUTE,\n",
    "        min_replica_count = 1,\n",
    "        max_replica_count = 1\n",
    "    )\n",
    "else: print(f'Not deploying - current model is worse ({model_rank}) than the currently deployed model ({deployed_rank})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c0af25-2b22-47b1-bf45-4c6227d5d991",
   "metadata": {},
   "source": [
    "### Remove Deployed Models without Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6945f51a-0c06-4760-bbfe-f2b9d1e7d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for deployed_model in endpoint.list_models():\n",
    "    if deployed_model.id in endpoint.traffic_split:\n",
    "        print(f\"Model {deployed_model.display_name} with version {deployed_model.model_version_id} has traffic = {endpoint.traffic_split[deployed_model.id]}\")\n",
    "    else:\n",
    "        endpoint.undeploy(deployed_model_id = deployed_model.id)\n",
    "        print(f\"Undeploying {deployed_model.display_name} with version {deployed_model.model_version_id} because it has no traffic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90c6900-de81-4fcd-af0b-ba6b3925724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cbf4a3-9e32-4158-a9ee-0cfca92e8574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#endpoint.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6466c127-a948-41ec-bbe9-422d1fd3a5e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Prediction\n",
    "\n",
    "See many more details on requesting predictions in the [04Tools - Prediction](./04Tools%20-%20Prediction.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc6c69e-429b-4590-97e2-77d06da10ac4",
   "metadata": {},
   "source": [
    "### Prepare a record for prediction: instance and parameters lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68911df0-5bee-44fb-9bb8-5aa363ae1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "pred = bq.query(\n",
    "    query = f\"\"\"\n",
    "        SELECT * EXCEPT({VAR_TARGET}, {VAR_OMIT}, splits)\n",
    "        FROM {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}\n",
    "        WHERE splits='TEST'\n",
    "        LIMIT {n}\n",
    "        \"\"\"\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bae334-4223-4680-a2d0-d350f6a7ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5640e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "newobs = pred.to_dict(orient = 'records')\n",
    "#newobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce631c5e-b200-43c8-9577-b77f957bb63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "newobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617e1e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instances = [json_format.ParseDict(newobs[0], Value())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc18b1b-90a4-47ba-b781-3a036d321757",
   "metadata": {},
   "source": [
    "### Get Predictions: Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec05c59-dc93-4a69-90bf-5f3f96f4d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = endpoint.predict(instances = newobs[0:1])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cb59fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = endpoint.predict(instances = newobs)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b22b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64e3283",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(prediction.predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4ef516-9d05-41d1-bcf4-8ca79d27da1e",
   "metadata": {},
   "source": [
    "### Get Predictions: REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f97f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DIR}/request.json','w') as file:\n",
    "    file.write(json.dumps({\"instances\": newobs[0:1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362dd5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST \\\n",
    "-H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
    "-H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "-d @{DIR}/request.json \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72f4031-6c30-4cf7-ae14-742d9d4b41fa",
   "metadata": {},
   "source": [
    "### Get Predictions: gcloud (CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e56e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud beta ai endpoints predict {endpoint.name.rsplit('/',1)[-1]} --region={REGION} --json-request={DIR}/request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e56322-afcb-4bfe-ae65-da9a3aeb9187",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"99 - Cleanup\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m94"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
