{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "838945b4",
   "metadata": {},
   "source": [
    "# 04a - Vertex AI > Notebooks - Models Built in Notebooks with Tensorflow\n",
    "\n",
    "Where a model gets trained is where it consumes computing resources.  With Vertex AI, you have choices for configuring the computing resources available at training.  This notebook is an example of an execution environment.  When it was set up there were choices for machine type and accelerators (GPUs).  \n",
    "\n",
    "This notebook shows training a model directly within the runtime of the notebook environment.  Then the model is saved and moved to GCS for deployment to a Vertex AI Endpoint for online predictions.  The model training is done with [Tensorflow](https://www.tensorflow.org/), specifically [Keras](https://keras.io/), and was designed to show a neural network approach to logistic regression.  The training data batches are read from BigQuery using [Tensorflow I/O](https://www.tensorflow.org/io).\n",
    "\n",
    "**Prerequisites:**\n",
    "\n",
    "-  01 - BigQuery - Table Data Source\n",
    "\n",
    "**Overview:**\n",
    "\n",
    "-  Use Python Client for BigQuery\n",
    "   -  Read the tables schema from BigQuery INFORMATION_SCHEMA\n",
    "   -  Prepare the feature information for Tensorflow\n",
    "-  Define a function that remaps the input data into features and target variables where target is one-hot encoded (classification model with 10 classes)\n",
    "-  Set Tensorflow I/O read session\n",
    "-  Demonstrate reading a single batch\n",
    "-  Train a Tensorflow model\n",
    "   -  Define the model layers\n",
    "   -  Compile the model\n",
    "   -  Fit the model\n",
    "   -  Evaluate the model (loss, accuracy)\n",
    "   -  Create prediction with the model\n",
    "-  Use Python Client google.cloud.aiplatform for Vertex AI\n",
    "   -  Upload Model\n",
    "      -  Model - aiplatform.Model.upoad\n",
    "   -  Create Endpoint\n",
    "      -  Endpoint - aiplatform.Endpoint.create\n",
    "   -  Deploy to Endpoint\n",
    "      -  Endpoint.deploy(model=Model)\n",
    "   -  Online Predictions\n",
    "      -  Endpoint.predict\n",
    "-  Online Predictions with:\n",
    "   -  REST call\n",
    "   -  gcloud CLI\n",
    "\n",
    "**Resources:**\n",
    "\n",
    "-  [BigQuery Tensorflow Reader](https://www.tensorflow.org/io/tutorials/bigquery)\n",
    "-  [Keras Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)\n",
    "   -  [Keras API](https://www.tensorflow.org/api_docs/python/tf/keras)\n",
    "-  [Python Client For Google BigQuery](https://googleapis.dev/python/bigquery/latest/index.html)\n",
    "-  [Tensorflow Python Client](https://www.tensorflow.org/api_docs/python/tf)\n",
    "-  [Tensorflow I/O Python Client](https://www.tensorflow.org/io/api_docs/python/tfio/bigquery)\n",
    "-  [Python Client for Vertex AI](https://googleapis.dev/python/aiplatform/latest/aiplatform.html)\n",
    "\n",
    "**Related Training:**\n",
    "\n",
    "-  todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf40777",
   "metadata": {},
   "source": [
    "---\n",
    "## Conceptual Architecture\n",
    "\n",
    "<img src=\"architectures/statmike-mlops-04.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc485502",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9acab9",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6774445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "PROJECT_ID='statmike-mlops'\n",
    "DATANAME = 'digits'\n",
    "NOTEBOOK = '04a'\n",
    "\n",
    "# Resources\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "DEPLOY_IMAGE='us-docker.pkg.dev/cloud-aiplatform/prediction/tf2-cpu.2-2:latest'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'target'\n",
    "VAR_OMIT = 'target_OE' # add more variables to the string with space delimiters\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220e356e",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2881f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62231558",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a938b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bigquery = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d91586b",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31a42699",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = PROJECT_ID\n",
    "URI = f\"gs://{BUCKET}/{DATANAME}/models/{NOTEBOOK}\"\n",
    "DIR = f\"temp/{NOTEBOOK}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb88f9a1",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fd2db0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc1868",
   "metadata": {},
   "source": [
    "---\n",
    "## Get The Schema of The Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d22e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM {DATANAME}.INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{DATANAME}_prepped'\"\n",
    "schema = bigquery.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e60e1625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_catalog</th>\n",
       "      <th>table_schema</th>\n",
       "      <th>table_name</th>\n",
       "      <th>column_name</th>\n",
       "      <th>ordinal_position</th>\n",
       "      <th>is_nullable</th>\n",
       "      <th>data_type</th>\n",
       "      <th>is_generated</th>\n",
       "      <th>generation_expression</th>\n",
       "      <th>is_stored</th>\n",
       "      <th>is_hidden</th>\n",
       "      <th>is_updatable</th>\n",
       "      <th>is_system_defined</th>\n",
       "      <th>is_partitioning_column</th>\n",
       "      <th>clustering_ordinal_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>statmike-mlops</td>\n",
       "      <td>digits</td>\n",
       "      <td>digits_prepped</td>\n",
       "      <td>p0</td>\n",
       "      <td>1</td>\n",
       "      <td>YES</td>\n",
       "      <td>FLOAT64</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>statmike-mlops</td>\n",
       "      <td>digits</td>\n",
       "      <td>digits_prepped</td>\n",
       "      <td>p1</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>FLOAT64</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>statmike-mlops</td>\n",
       "      <td>digits</td>\n",
       "      <td>digits_prepped</td>\n",
       "      <td>p2</td>\n",
       "      <td>3</td>\n",
       "      <td>YES</td>\n",
       "      <td>FLOAT64</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>statmike-mlops</td>\n",
       "      <td>digits</td>\n",
       "      <td>digits_prepped</td>\n",
       "      <td>p3</td>\n",
       "      <td>4</td>\n",
       "      <td>YES</td>\n",
       "      <td>FLOAT64</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>statmike-mlops</td>\n",
       "      <td>digits</td>\n",
       "      <td>digits_prepped</td>\n",
       "      <td>p4</td>\n",
       "      <td>5</td>\n",
       "      <td>YES</td>\n",
       "      <td>FLOAT64</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>statmike-mlops</td>\n",
       "      <td>digits</td>\n",
       "      <td>digits_prepped</td>\n",
       "      <td>p62</td>\n",
       "      <td>63</td>\n",
       "      <td>YES</td>\n",
       "      <td>FLOAT64</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>statmike-mlops</td>\n",
       "      <td>digits</td>\n",
       "      <td>digits_prepped</td>\n",
       "      <td>p63</td>\n",
       "      <td>64</td>\n",
       "      <td>YES</td>\n",
       "      <td>FLOAT64</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>statmike-mlops</td>\n",
       "      <td>digits</td>\n",
       "      <td>digits_prepped</td>\n",
       "      <td>target</td>\n",
       "      <td>65</td>\n",
       "      <td>YES</td>\n",
       "      <td>INT64</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>statmike-mlops</td>\n",
       "      <td>digits</td>\n",
       "      <td>digits_prepped</td>\n",
       "      <td>target_OE</td>\n",
       "      <td>66</td>\n",
       "      <td>YES</td>\n",
       "      <td>STRING</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>statmike-mlops</td>\n",
       "      <td>digits</td>\n",
       "      <td>digits_prepped</td>\n",
       "      <td>splits</td>\n",
       "      <td>67</td>\n",
       "      <td>YES</td>\n",
       "      <td>STRING</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     table_catalog table_schema      table_name column_name  ordinal_position  \\\n",
       "0   statmike-mlops       digits  digits_prepped          p0                 1   \n",
       "1   statmike-mlops       digits  digits_prepped          p1                 2   \n",
       "2   statmike-mlops       digits  digits_prepped          p2                 3   \n",
       "3   statmike-mlops       digits  digits_prepped          p3                 4   \n",
       "4   statmike-mlops       digits  digits_prepped          p4                 5   \n",
       "..             ...          ...             ...         ...               ...   \n",
       "62  statmike-mlops       digits  digits_prepped         p62                63   \n",
       "63  statmike-mlops       digits  digits_prepped         p63                64   \n",
       "64  statmike-mlops       digits  digits_prepped      target                65   \n",
       "65  statmike-mlops       digits  digits_prepped   target_OE                66   \n",
       "66  statmike-mlops       digits  digits_prepped      splits                67   \n",
       "\n",
       "   is_nullable data_type is_generated generation_expression is_stored  \\\n",
       "0          YES   FLOAT64        NEVER                  None      None   \n",
       "1          YES   FLOAT64        NEVER                  None      None   \n",
       "2          YES   FLOAT64        NEVER                  None      None   \n",
       "3          YES   FLOAT64        NEVER                  None      None   \n",
       "4          YES   FLOAT64        NEVER                  None      None   \n",
       "..         ...       ...          ...                   ...       ...   \n",
       "62         YES   FLOAT64        NEVER                  None      None   \n",
       "63         YES   FLOAT64        NEVER                  None      None   \n",
       "64         YES     INT64        NEVER                  None      None   \n",
       "65         YES    STRING        NEVER                  None      None   \n",
       "66         YES    STRING        NEVER                  None      None   \n",
       "\n",
       "   is_hidden is_updatable is_system_defined is_partitioning_column  \\\n",
       "0         NO         None                NO                     NO   \n",
       "1         NO         None                NO                     NO   \n",
       "2         NO         None                NO                     NO   \n",
       "3         NO         None                NO                     NO   \n",
       "4         NO         None                NO                     NO   \n",
       "..       ...          ...               ...                    ...   \n",
       "62        NO         None                NO                     NO   \n",
       "63        NO         None                NO                     NO   \n",
       "64        NO         None                NO                     NO   \n",
       "65        NO         None                NO                     NO   \n",
       "66        NO         None                NO                     NO   \n",
       "\n",
       "    clustering_ordinal_position  \n",
       "0                           NaN  \n",
       "1                           NaN  \n",
       "2                           NaN  \n",
       "3                           NaN  \n",
       "4                           NaN  \n",
       "..                          ...  \n",
       "62                          NaN  \n",
       "63                          NaN  \n",
       "64                          NaN  \n",
       "65                          NaN  \n",
       "66                          NaN  \n",
       "\n",
       "[67 rows x 15 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b15e3b",
   "metadata": {},
   "source": [
    "## Prepare Inputs For Tensorflow Training\n",
    "\n",
    "Use the the table schema to prepare the TensorFlow Model:\n",
    "- Omit unused columns\n",
    "- Create `feature_columns` for the model\n",
    "- Define the `dtypes` for TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81f2c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "OMIT = VAR_OMIT.split() + ['splits']\n",
    "\n",
    "selected_fields = schema[~schema.column_name.isin(OMIT)].column_name.tolist()\n",
    "\n",
    "feature_columns = []\n",
    "feature_layer_inputs = {}\n",
    "for header in selected_fields:\n",
    "    if header != VAR_TARGET:\n",
    "        feature_columns.append(tf.feature_column.numeric_column(header))\n",
    "        feature_layer_inputs[header] = tf.keras.Input(shape=(1,),name=header)\n",
    "\n",
    "# all the columns in this data source are either float64 or int64\n",
    "output_types = schema[~schema.column_name.isin(OMIT)].data_type.tolist()\n",
    "output_types = [dtypes.float64 if x=='FLOAT64' else dtypes.int64 for x in output_types]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85774dc4",
   "metadata": {},
   "source": [
    "Define a function that remaps the input data for TensorFlow into:\n",
    "- features\n",
    "- `target` - and one_hot encoded for multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b9b50af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transTable(row_dict):\n",
    "    target=row_dict.pop(VAR_TARGET)\n",
    "    target = tf.one_hot(tf.cast(target,tf.int64),10)\n",
    "    target = tf.cast(target,tf.float32)\n",
    "    return(row_dict,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db48a495",
   "metadata": {},
   "source": [
    "## Use Tensorflow I/O to Read Batches from BigQuery\n",
    "\n",
    "Setup TensorFlow_IO client > session > table + table.map\n",
    "- https://www.tensorflow.org/io/api_docs/python/tfio/bigquery/BigQueryClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5981248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bq_reader(split):\n",
    "    reader = BigQueryClient()\n",
    "\n",
    "    training = reader.read_session(\n",
    "        parent = f\"projects/{PROJECT_ID}\",\n",
    "        project_id = PROJECT_ID,\n",
    "        table_id = f\"{DATANAME}_prepped\",\n",
    "        dataset_id = DATANAME,\n",
    "        selected_fields = selected_fields,\n",
    "        output_types = output_types,\n",
    "        row_restriction = f\"splits='{split}'\",\n",
    "        requested_streams = 3\n",
    "    )\n",
    "    \n",
    "    return training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f85f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = bq_reader('TRAIN').parallel_read_rows().map(transTable).shuffle(BATCH_SIZE*3).batch(BATCH_SIZE)\n",
    "validate = bq_reader('VALIDATE').parallel_read_rows().map(transTable).batch(BATCH_SIZE)\n",
    "test = bq_reader('TEST').parallel_read_rows().map(transTable).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a03d70",
   "metadata": {},
   "source": [
    "Review a single batch of the train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eae7417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns:\n",
      " ['p0', 'p1', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19', 'p2', 'p20', 'p21', 'p22', 'p23', 'p24', 'p25', 'p26', 'p27', 'p28', 'p29', 'p3', 'p30', 'p31', 'p32', 'p33', 'p34', 'p35', 'p36', 'p37', 'p38', 'p39', 'p4', 'p40', 'p41', 'p42', 'p43', 'p44', 'p45', 'p46', 'p47', 'p48', 'p49', 'p5', 'p50', 'p51', 'p52', 'p53', 'p54', 'p55', 'p56', 'p57', 'p58', 'p59', 'p6', 'p60', 'p61', 'p62', 'p63', 'p7', 'p8', 'p9']\n",
      "\n",
      "target:\n",
      " tf.Tensor(\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(30, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for a, b in train.take(1):\n",
    "    columns=list(a.keys())\n",
    "    print('columns:\\n',columns)\n",
    "    print('\\ntarget:\\n',b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49333631",
   "metadata": {},
   "source": [
    "---\n",
    "## Train the Model In The Notebook\n",
    "\n",
    "Define the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cd88c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "model = tf.keras.Model(\n",
    "    inputs = [v for v in feature_layer_inputs.values()],\n",
    "    outputs = tf.keras.layers.Dense(10, activation = tf.nn.softmax)(feature_layer_outputs)\n",
    ")\n",
    "model.compile(\n",
    "    optimizer = 'sgd',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "#tf.keras.utils.plot_model(model, show_shapes = True, show_dtype = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2690c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f46f80",
   "metadata": {},
   "source": [
    "Fit the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fe920d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "49/49 [==============================] - 3s 53ms/step - loss: 2.8710 - accuracy: 0.5503 - val_loss: 1.7381 - val_accuracy: 0.6556\n",
      "Epoch 2/25\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.6488 - accuracy: 0.8340 - val_loss: 0.7009 - val_accuracy: 0.8222\n",
      "Epoch 3/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.4617 - accuracy: 0.8809 - val_loss: 0.6590 - val_accuracy: 0.8222\n",
      "Epoch 4/25\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.3504 - accuracy: 0.9070 - val_loss: 0.4153 - val_accuracy: 0.8833\n",
      "Epoch 5/25\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 0.3131 - accuracy: 0.9146 - val_loss: 0.4358 - val_accuracy: 0.8611\n",
      "Epoch 6/25\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.2312 - accuracy: 0.9311 - val_loss: 0.3779 - val_accuracy: 0.9000\n",
      "Epoch 7/25\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.2152 - accuracy: 0.9366 - val_loss: 0.3035 - val_accuracy: 0.9111\n",
      "Epoch 8/25\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 0.2007 - accuracy: 0.9394 - val_loss: 0.2724 - val_accuracy: 0.9167\n",
      "Epoch 9/25\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.1745 - accuracy: 0.9463 - val_loss: 0.2890 - val_accuracy: 0.9056\n",
      "Epoch 10/25\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.1582 - accuracy: 0.9504 - val_loss: 0.2660 - val_accuracy: 0.9167\n",
      "Epoch 11/25\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.1529 - accuracy: 0.9552 - val_loss: 0.2772 - val_accuracy: 0.9000\n",
      "Epoch 12/25\n",
      "49/49 [==============================] - 4s 83ms/step - loss: 0.1424 - accuracy: 0.9587 - val_loss: 0.2622 - val_accuracy: 0.9111\n",
      "Epoch 13/25\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.1334 - accuracy: 0.9607 - val_loss: 0.2290 - val_accuracy: 0.9167\n",
      "Epoch 14/25\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.1233 - accuracy: 0.9614 - val_loss: 0.2515 - val_accuracy: 0.9056\n",
      "Epoch 15/25\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 0.1181 - accuracy: 0.9649 - val_loss: 0.3236 - val_accuracy: 0.8944\n",
      "Epoch 16/25\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 0.1108 - accuracy: 0.9690 - val_loss: 0.2325 - val_accuracy: 0.9222\n",
      "Epoch 17/25\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.1021 - accuracy: 0.9690 - val_loss: 0.2386 - val_accuracy: 0.9056\n",
      "Epoch 18/25\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.0930 - accuracy: 0.9697 - val_loss: 0.2136 - val_accuracy: 0.9167\n",
      "Epoch 19/25\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 0.0882 - accuracy: 0.9690 - val_loss: 0.2086 - val_accuracy: 0.9278\n",
      "Epoch 20/25\n",
      "49/49 [==============================] - 2s 36ms/step - loss: 0.0836 - accuracy: 0.9766 - val_loss: 0.2738 - val_accuracy: 0.9000\n",
      "Epoch 21/25\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 0.0823 - accuracy: 0.9773 - val_loss: 0.2127 - val_accuracy: 0.9222\n",
      "Epoch 22/25\n",
      "49/49 [==============================] - 2s 36ms/step - loss: 0.0764 - accuracy: 0.9745 - val_loss: 0.2218 - val_accuracy: 0.9111\n",
      "Epoch 23/25\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.0801 - accuracy: 0.9752 - val_loss: 0.2161 - val_accuracy: 0.9111\n",
      "Epoch 24/25\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 0.0749 - accuracy: 0.9793 - val_loss: 0.2026 - val_accuracy: 0.9389\n",
      "Epoch 25/25\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 0.0724 - accuracy: 0.9773 - val_loss: 0.2034 - val_accuracy: 0.9278\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, epochs = 25, validation_data = validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4dc4bbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07243506610393524"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['loss'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442fa473",
   "metadata": {},
   "source": [
    "Evaluate the model with the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fb275ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1042 - accuracy: 0.9636\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13d8c2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2034 - accuracy: 0.9278\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75025bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 1s 24ms/step - loss: 0.0633 - accuracy: 0.9828\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be92263",
   "metadata": {},
   "source": [
    "Create Prediction from a batch of the test data and review first row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "049251b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9956220e-01, 2.7984512e-07, 2.6025486e-06, 5.3722726e-10,\n",
       "       2.1185444e-04, 1.6432656e-08, 2.2245137e-04, 2.4398972e-10,\n",
       "       3.1432586e-07, 2.2100301e-07], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test.take(1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f1db0c",
   "metadata": {},
   "source": [
    "---\n",
    "## Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2060e3f8",
   "metadata": {},
   "source": [
    "### Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f03227f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-19 12:30:22.503001: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://statmike-mlops/digits/models/04a/assets\n",
      "INFO:tensorflow:Assets written to: gs://statmike-mlops/digits/models/04a/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4c9cec",
   "metadata": {},
   "source": [
    "### Upload The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8e51298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Model\n",
      "INFO:google.cloud.aiplatform.models:Create Model backing LRO: projects/691911073727/locations/us-central1/models/8309625097614786560/operations/3000425120322813952\n",
      "INFO:google.cloud.aiplatform.models:Model created. Resource name: projects/691911073727/locations/us-central1/models/8309625097614786560\n",
      "INFO:google.cloud.aiplatform.models:To use this Model in another session:\n",
      "INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/691911073727/locations/us-central1/models/8309625097614786560')\n"
     ]
    }
   ],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name = f'{NOTEBOOK}_{DATANAME}_{TIMESTAMP}',\n",
    "    serving_container_image_uri = DEPLOY_IMAGE,\n",
    "    artifact_uri = URI,\n",
    "    labels = {'notebook':f'{NOTEBOOK}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d849aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'04a_digits_20210919122627'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf04ef5",
   "metadata": {},
   "source": [
    "### Create An Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b921a66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Endpoint\n",
      "INFO:google.cloud.aiplatform.models:Create Endpoint backing LRO: projects/691911073727/locations/us-central1/endpoints/1552879854326644736/operations/1568280438818996224\n",
      "INFO:google.cloud.aiplatform.models:Endpoint created. Resource name: projects/691911073727/locations/us-central1/endpoints/1552879854326644736\n",
      "INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n",
      "INFO:google.cloud.aiplatform.models:endpoint = aiplatform.Endpoint('projects/691911073727/locations/us-central1/endpoints/1552879854326644736')\n"
     ]
    }
   ],
   "source": [
    "endpoint = aiplatform.Endpoint.create(\n",
    "    display_name = f'{NOTEBOOK}_{DATANAME}_{TIMESTAMP}',\n",
    "    labels = {'notebook':f'{NOTEBOOK}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0fa0922b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'04a_digits_20210919122627'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad82e62",
   "metadata": {},
   "source": [
    "### Deploy Model To Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b17f1cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Deploying Model projects/691911073727/locations/us-central1/models/8309625097614786560 to Endpoint : projects/691911073727/locations/us-central1/endpoints/1552879854326644736\n",
      "INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/691911073727/locations/us-central1/endpoints/1552879854326644736/operations/8814572239258124288\n",
      "INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/691911073727/locations/us-central1/endpoints/1552879854326644736\n"
     ]
    }
   ],
   "source": [
    "endpoint.deploy(\n",
    "    model = model,\n",
    "    deployed_model_display_name = f'{NOTEBOOK}_{DATANAME}_{TIMESTAMP}',\n",
    "    traffic_percentage = 100,\n",
    "    machine_type = DEPLOY_COMPUTE,\n",
    "    min_replica_count = 1,\n",
    "    max_replica_count = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ea8a7c",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12809aff",
   "metadata": {},
   "source": [
    "### Prepare a record for prediction: instance and parameters lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d61ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bigquery.query(query = f\"SELECT * FROM {DATANAME}.{DATANAME} LIMIT 10\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1522eaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>p9</th>\n",
       "      <th>...</th>\n",
       "      <th>p56</th>\n",
       "      <th>p57</th>\n",
       "      <th>p58</th>\n",
       "      <th>p59</th>\n",
       "      <th>p60</th>\n",
       "      <th>p61</th>\n",
       "      <th>p62</th>\n",
       "      <th>p63</th>\n",
       "      <th>target</th>\n",
       "      <th>target_OE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Even</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    p0   p1    p2    p3   p4   p5   p6   p7   p8    p9  ...  p56  p57   p58  \\\n",
       "0  0.0  5.0  16.0  15.0  5.0  0.0  0.0  0.0  0.0   2.0  ...  0.0  6.0  16.0   \n",
       "1  0.0  5.0  16.0  12.0  1.0  0.0  0.0  0.0  0.0   5.0  ...  0.0  8.0  16.0   \n",
       "2  0.0  5.0  15.0  16.0  6.0  0.0  0.0  0.0  0.0  11.0  ...  0.0  6.0  16.0   \n",
       "3  0.0  4.0  15.0  15.0  8.0  0.0  0.0  0.0  0.0   8.0  ...  0.0  7.0  14.0   \n",
       "\n",
       "    p59   p60   p61  p62  p63  target  target_OE  \n",
       "0  16.0  16.0  16.0  7.0  0.0       2       Even  \n",
       "1  16.0  16.0  16.0  4.0  0.0       2       Even  \n",
       "2  16.0  16.0  13.0  3.0  0.0       2       Even  \n",
       "3  11.0   0.0   0.0  0.0  0.0       2       Even  \n",
       "\n",
       "[4 rows x 66 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf8df2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "newob = pred[pred.columns[~pred.columns.isin(VAR_OMIT.split()+[VAR_TARGET])]].to_dict(orient='records')[0]\n",
    "#newob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36bd9e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [json_format.ParseDict(newob, Value())]\n",
    "parameters = json_format.ParseDict({}, Value())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96758f87",
   "metadata": {},
   "source": [
    "### Get Predictions: Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f01e494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[[2.46273196e-10, 0.00158410147, 0.997878194, 1.5257192e-06, 2.3139702e-12, 1.76742205e-07, 7.47057638e-05, 2.49122e-10, 0.000460077048, 1.18600212e-06]], deployed_model_id='2499014008074403840', explanations=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = endpoint.predict(instances=instances, parameters=parameters)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5c738172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.46273196e-10,\n",
       " 0.00158410147,\n",
       " 0.997878194,\n",
       " 1.5257192e-06,\n",
       " 2.3139702e-12,\n",
       " 1.76742205e-07,\n",
       " 7.47057638e-05,\n",
       " 2.49122e-10,\n",
       " 0.000460077048,\n",
       " 1.18600212e-06]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0510677b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction.predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e494b3",
   "metadata": {},
   "source": [
    "### Get Predictions: REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09da7bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DIR}/request.json','w') as file:\n",
    "    file.write(json.dumps({\"instances\": [newob]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "791f933d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    [\n",
      "      2.46273196e-10,\n",
      "      0.00158410147,\n",
      "      0.997878194,\n",
      "      1.5257192e-06,\n",
      "      2.3139702e-12,\n",
      "      1.76742205e-07,\n",
      "      7.47057638e-05,\n",
      "      2.49122e-10,\n",
      "      0.000460077048,\n",
      "      1.18600212e-06\n",
      "    ]\n",
      "  ],\n",
      "  \"deployedModelId\": \"2499014008074403840\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST \\\n",
    "-H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
    "-H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "-d @{DIR}/request.json \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb7eb2a",
   "metadata": {},
   "source": [
    "### Get Predictions: gcloud (CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "14a2504b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n",
      "[[2.46273196e-10, 0.00158410147, 0.997878194, 1.5257192e-06, 2.3139702e-12, 1.76742205e-07, 7.47057638e-05, 2.49122e-10, 0.000460077048, 1.18600212e-06]]\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta ai endpoints predict {endpoint.name.rsplit('/',1)[-1]} --region={REGION} --json-request={DIR}/request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bbe7cb",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"XX - Cleanup\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m79"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
