{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a6bca4-0162-4841-9b77-00c611ff98a6",
   "metadata": {},
   "source": [
    "![ga4](https://www.google-analytics.com/collect?v=2&tid=G-6VDTYWLKX6&cid=1&en=page_view&sid=1&dl=statmike%2Fvertex-ai-mlops%2FWorking+With+Document+AI&dt=Document+AI+-+Process+Responses.ipynb)\n",
    "\n",
    "# Document AI - Process Responses\n",
    "> From the [Working With Document AI](https://github.com/statmike/vertex-ai-mlops/blob/main/Working%20With%20Document%20AI/readme.md) series in the [vertex-ai-mlops](https://github.com/statmike/vertex-ai-mlops/blob/main/readme.md) repository.\n",
    "\n",
    "Document AI is an API where you interact with processors to extract information from documents.  You enable the API, create an instance of a processor in your project, send in document(s), receive back JSON with the extracted information:\n",
    "\n",
    "<p align=\"center\" width=\"100%\"><center>\n",
    "    <img src=\"../architectures/architectures/images/working with/documentai/readme/high_level.png\">\n",
    "</center></p>\n",
    "\n",
    "---\n",
    "\n",
    "**Processing**\n",
    "\n",
    "This workflow covers techniques to extract elements from the responses.  A prior workflow covered all the ways to process a document, or many documents, using Python as the client: [Document AI - Process Documents](./Document%20AI%20-%20Process%20Documents.ipynb). It also shows how to store and retrieve responses from GCS and BigQuery.\n",
    "\n",
    "---\n",
    "\n",
    "more here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff83a40-ea39-4b3e-b460-59128b38e067",
   "metadata": {
    "id": "od_UkDpvRmgD"
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab click [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Working%20With%20Document%20AI/Document%20AI%20-%20Process%20Responses.ipynb) and run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4795a0f1-20ce-4611-bf29-a57af709def1",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7465d4e4-1995-470f-a661-0cac80526598",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bf85c5-1ada-4c69-997d-887c793ca3e1",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs and API Enablement\n",
    "\n",
    "The clients packages may need installing in this environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e86b85-6810-4627-9084-ccee091179e2",
   "metadata": {},
   "source": [
    "### Installs (If Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2fe898e-20a1-4fed-a2ae-292bdacfe1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuples of (import name, install name)\n",
    "packages = [\n",
    "    ('google.cloud.documentai', 'google-cloud-documentai'),\n",
    "    ('google.cloud.documentai_toolbox', 'google-cloud-documentai-toolbox'),\n",
    "    ('google.cloud.documentai', 'google-cloud-storage'),\n",
    "    ('google.cloud.documentai', 'google-cloud-bigquery'),\n",
    "    ('PyPDF2', 'PyPDF2')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc968b-5760-41fe-9561-0c89625485e1",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0943ffe-ebb0-4257-b683-595fdde91e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud services enable documentai.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77e23e3-98c4-47f9-9d4c-75b911f53478",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f3e509e-da5e-4e94-9e89-4a23a51f14b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e8a845-dce4-49c0-b9c2-9bbedcb4b5a7",
   "metadata": {
    "id": "appt8-yVRtJ1"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2238cf-48e7-476d-bfd1-5085b21a2333",
   "metadata": {
    "id": "63mx2EozRxFP"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3cd9f1b-b38b-4c4b-aab0-df6414cbc5cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1683726390544,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "xzcoXjM5Rky5",
    "outputId": "b3bdcbc1-70d5-472e-aea2-42c74a42efde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "298afaa9-2744-4ab9-b7d3-bd915adb411e",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683726390712,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "IxWrFtqYMfku"
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'working-with-docai'\n",
    "EXPERIMENT = 'process-responses'\n",
    "\n",
    "# make this the gcs bucket for storing files\n",
    "GCS_BUCKET = PROJECT_ID\n",
    "\n",
    "# BigQuery Objects\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = SERIES.replace('-', '_')\n",
    "BQ_TABLE_PREFIX = EXPERIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09edf5c-16eb-4a7f-aa23-dd27a59035f7",
   "metadata": {
    "id": "LuajVwCiO6Yg"
   },
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b9c168d-ba67-4b04-b37d-183c631854bd",
   "metadata": {
    "executionInfo": {
     "elapsed": 17761,
     "status": "ok",
     "timestamp": 1683726409304,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "LVC7zzSLRk2C"
   },
   "outputs": [],
   "source": [
    "import os, shutil, glob, json, asyncio, datetime\n",
    "\n",
    "import PyPDF2\n",
    "\n",
    "from google.cloud import documentai\n",
    "from google.cloud import documentai_toolbox\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07253108-e8a3-4d79-b101-411c54acf745",
   "metadata": {
    "id": "EyAVFG9TO9H-"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44caf6c9-1549-4da3-be9a-a87b36ff6f25",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683726409306,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "L0RPE13LOZce"
   },
   "outputs": [],
   "source": [
    "# document AI client\n",
    "LOCATION = REGION.split('-')[0]\n",
    "docai = documentai.DocumentProcessorServiceClient(\n",
    "    client_options = dict(api_endpoint = f\"{LOCATION}-documentai.googleapis.com\")\n",
    ")\n",
    "\n",
    "# gcs client: assumes bucket already exists\n",
    "gcs = storage.Client(project = PROJECT_ID)\n",
    "bucket = gcs.bucket(GCS_BUCKET)\n",
    "\n",
    "# bq client\n",
    "bq = bigquery.Client(project = PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e882861f-6669-41ed-8d99-3cc1bf28756c",
   "metadata": {},
   "source": [
    "---\n",
    "## Get The Document\n",
    "\n",
    "This section prepares a document for processing with online processing.\n",
    "\n",
    "|Document Name|Link|\n",
    "|---|---|\n",
    "|`docs/sports/Baseball - Wikipedia.pdf`|[https://en.wikipedia.org/wiki/Baseball](https://en.wikipedia.org/wiki/Baseball)|\n",
    "\n",
    "If you are working from a clone of this notebooks repository then the document is already present. The following cell checks for the documents folder, `/docs`, and if it is missing gets the document used in this workflow (`wget`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d736e81-afda-4c6f-9646-6e2ad2b77065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Found at `docs/sports/Baseball - Wikipedia.pdf`\n"
     ]
    }
   ],
   "source": [
    "file = 'docs/sports/Baseball - Wikipedia.pdf'\n",
    "if not os.path.exists(file):\n",
    "    print('Retrieving document...')\n",
    "    if not os.path.exists(os.path.dirname(file)):\n",
    "      os.makedirs(os.path.dirname(file))\n",
    "    import requests, urllib.parse\n",
    "    r = requests.get(f'https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Working%20With%20Document%20AI/{urllib.parse.quote(file)}')\n",
    "    open(file, 'wb').write(r.content)\n",
    "    print(f'Document now at `{file}`')\n",
    "else:\n",
    "    print(f'Document Found at `{file}`')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcf87bb-a5af-4788-80f5-e96dbf3d43c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Create/Get A Processor\n",
    "\n",
    "For this workflow we will use the [OCR parser](https://cloud.google.com/document-ai/docs/processors-list#processor_doc-ocr). We can check for an existing processor in the project that the OCR Parser with desired version and if it is not present then create one.  The processor will be connected with Python variable `PARSER` and referred to as a parser as it is used.\n",
    "\n",
    "Get the type and version from the list of available processors: https://cloud.google.com/document-ai/docs/processors-list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64931792-72a8-4451-9a97-24d89cf4e9ef",
   "metadata": {},
   "source": [
    "What are the processors already created in this project environment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3a4526e-9d57-48bd-bbe2-a0522a427570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processors = list(docai.list_processors(parent = f'projects/{PROJECT_ID}/locations/{LOCATION}'))\n",
    "len(processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7a59ff03-3c3b-447c-9771-5e913713dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE = 'OCR_PROCESSOR'\n",
    "VERSION = 'pretrained-ocr-v2.0-2023-06-02'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2206b1a-c7ad-4ff2-8ab3-cc116af2276c",
   "metadata": {},
   "source": [
    "Get an existing processor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "00c401c5-ebb4-4171-877c-d1fd5298e573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is an existing processor with the desire type and version in PARSER = working-with-docai\n"
     ]
    }
   ],
   "source": [
    "PARSER = ''\n",
    "for processor in processors:\n",
    "    if processor.type_ == TYPE and processor.default_processor_version.split('/')[-1] == VERSION:\n",
    "        PARSER = processor\n",
    "        break\n",
    "        \n",
    "if PARSER:\n",
    "    print(f'There is an existing processor with the desire type and version in PARSER = {PARSER.display_name}')\n",
    "else:\n",
    "    print(f'Need to create a processor for the desired type and version: {TYPE}, {VERSION}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a195f3d5-ee3d-4cf9-81ea-0ad1b3ebfcf8",
   "metadata": {},
   "source": [
    "Create the processor if an existing one was not found to match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5020d2be-76ec-4099-b77a-af0938aa77e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not PARSER:\n",
    "    PARSER = docai.create_processor(\n",
    "        parent = f'projects/{PROJECT_ID}/locations/{LOCATION}',\n",
    "        processor = documentai.Processor(\n",
    "            display_name = SERIES,\n",
    "            type_ = TYPE\n",
    "        )\n",
    "    )\n",
    "    set_default = docai.set_default_processor_version(\n",
    "        request = documentai.SetDefaultProcessorVersionRequest(\n",
    "            processor = PARSER.name,\n",
    "            default_processor_version = f'{PARSER.name}/processorVersions/{VERSION}'\n",
    "        )\n",
    "    )\n",
    "    set_default.result()\n",
    "    PARSER = docai.get_processor(\n",
    "        name = PARSER.name\n",
    "    )\n",
    "    print(f'Processor created and in PARSER variable with display name = {PARSER.display_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbcf03d-1049-49d3-97f5-68bfb6cb5de0",
   "metadata": {},
   "source": [
    "---\n",
    "## Online Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c0bf35-def1-4489-8468-697f77136ec0",
   "metadata": {},
   "source": [
    "---\n",
    "## Batch Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b34280-355b-4b22-819f-7fc0b64d6ef2",
   "metadata": {},
   "source": [
    "---\n",
    "## Extraction: Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb4aad-cffe-4c31-81d4-7d50b5d2c9d2",
   "metadata": {},
   "source": [
    "---\n",
    "## Extraction: BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0849c3b-56d7-4864-8b4e-d7a5fca3cdc3",
   "metadata": {},
   "source": [
    "---\n",
    "## Extraction: Document AI Toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7300349-8b2b-45df-bc2e-319ed8568919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b4dac8-81c2-4723-8c0c-50db45b8065a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
