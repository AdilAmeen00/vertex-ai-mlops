{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26932d9e-d190-47a8-86e1-3e2063a2a0e1",
   "metadata": {},
   "source": [
    "![ga4](https://www.google-analytics.com/collect?v=2&tid=G-6VDTYWLKX6&cid=1&en=page_view&sid=1&dl=statmike%2Fvertex-ai-mlops%2FWorking+With+Document+AI&dt=Document+AI+-+Process+Documents.ipynb)\n",
    "\n",
    "# Document AI - Process Documents\n",
    "\n",
    "Document AI is an API where you interact with processors to extract information from documents.  You enable the API, create an instance of a processor in your project, send in document(s), receive back JSON with the extracted information:\n",
    "\n",
    "<p align=\"center\" width=\"100%\"><center>\n",
    "    <img src=\"../architectures/architectures/images/working with/documentai/readme/high_level.png\">\n",
    "</center></p>\n",
    "\n",
    "This workflow covers all the ways to process a document, or many documents, using Python as the client. For details on how to extract elements from the responses see the next workflow: [Document AI - Process Responses](./Document%20AI%20-%20Process%20Responses.ipynb)\n",
    "\n",
    "---\n",
    "**Documents**\n",
    "\n",
    "Document AI sources are documents.  There are many supported document types (file formats):\n",
    "- Supported [Document Types](https://cloud.google.com/document-ai/docs/file-types) like pdf, gif, tiff, jpeg, pn, gmp, webp\n",
    "- Additional support for [DocX files is in preview](https://cloud.google.com/document-ai/docs/enterprise-document-ocr#supported_file_formats).\n",
    "\n",
    "---\n",
    "**Processing**\n",
    "\n",
    "Processing can be orchestrated with one of the [client libraries](https://cloud.google.com/document-ai/docs/libraries), [REST](https://cloud.google.com/document-ai/docs/reference/rest), or [RPC](https://cloud.google.com/document-ai/docs/reference/rpc).  This workflow will use the [Python Client for Document AI](https://cloud.google.com/python/docs/reference/documentai/latest).\n",
    "\n",
    "```\n",
    "from google.cloud import documentai\n",
    "\n",
    "doc_ai_async = documentai.DocumentProcessorServiceClient()\n",
    "```\n",
    "\n",
    "> There is also an async client that can be used.  The methods have the same names and can be awaited with the `await`:\n",
    "> `doc_ai = documentai.DocumentProcessorServiceAsyncClient()`\n",
    "\n",
    "Processing can be be done online (one document) or in batch (multiple documents):\n",
    "- online: `doc_ai.process_document()`\n",
    "- batch: `doc_ai.batch_process_documents()`\n",
    "\n",
    "---\n",
    "**Inputs & Outputs**\n",
    "\n",
    "File Locations:\n",
    "- inputs:\n",
    "    - online processing\n",
    "        - `documentai.ProcessRequest()`: includes one of these parameters:\n",
    "            - `inline_document` = `documentai.types.Document()`\n",
    "                - source is specified with: `uri` = GCS URI as string\n",
    "            - `raw_document` = `documentai.types.RawDocument()`\n",
    "                - source is specified with: `content` = bytes\n",
    "            - `gcs_document` = `documentai.types.GcsDocument()`\n",
    "                - source is specified with: `gcs_uri` = GCS URI as string\n",
    "    - batch processing\n",
    "        - `documentai.BatchDocumentsInputConfig()`: includes one of these parameters:\n",
    "            - `gcs_prefix` = `documentai.types.GcsPrefix()`\n",
    "                - sources are specified with: `gcs_uri_prefix` = GCS URI (prefix) as string\n",
    "            - `gcs_documents` = `documentai.types.GcsDocuments()`\n",
    "                - sources are specified with: documents = [list of `documentai.types.GcsDocument()`]\n",
    "                    - each source has parameter: `gcs_uri` = GCS URI as string\n",
    "- outputs:\n",
    "    - online processing\n",
    "        - response returned to client as `documentai.types.ProcessResponse()`\n",
    "            - `document` = `documentai.types.Document()`\n",
    "                - parameters:\n",
    "                    - `text` =\n",
    "                    - `pages` =\n",
    "                    - `entities` = \n",
    "                    - ...\n",
    "                - methods:\n",
    "                    - `.to_dict()` for dictionary\n",
    "                    - `.to_json()` for JSON\n",
    "    - batch processing\n",
    "        - the `doc_ai.batch_process_document()` requests has parameter 'document_output_config` = `documentai.DocumentOutputConfig()`:\n",
    "            - `gcs_output_config` = `documentai.types.DocumentOutputConfig.GcsOutputConfig()`\n",
    "                - `gcs_uri` = GCS URI as string\n",
    "                - `field_mask` (optional): which field to include in output\n",
    "                - `sharding_config` (optional): pages per shard\n",
    "            - results are stored at the GCS URI specified in `gcs_uri` as JSON files\n",
    "\n",
    "---\n",
    "**Processing Specifics**\n",
    "\n",
    "There are limits to processing requests:\n",
    "- the number of request that can be made over a period of time: [Quotas](https://cloud.google.com/document-ai/quotas#quotas)\n",
    "- the amount and size of content (documents, pages): [Content Limits](https://cloud.google.com/document-ai/quotas#content_limits)\n",
    "- the processing request for each processor (parser) also has limits: [Processor Specific Limits](https://cloud.google.com/document-ai/quotas#processor_limits)\n",
    "\n",
    "What does this actually mean?  Let's pick a single processor and walk through it, the OCR Parser. [This page](https://cloud.google.com/document-ai/docs/processors-list) has all the specifics for each parser.\n",
    "- Parser Limits: The OCR parser\n",
    "    - limit of 15 pages for an online requests and 500 for a batch requests\n",
    "- Content Limits:\n",
    "    - file size: 20MB online, and 1GB batch\n",
    "    - files: 1 for online, 5000 for batch\n",
    "        - but the OCR parser has a 500 page limit for batch\n",
    "    - If the file type is an image (not PDF) then each page can be a max of 40 megapixels\n",
    "- Requests (Qoutas):\n",
    "    - overall\n",
    "        - 10,000 active pages per project\n",
    "    - users:\n",
    "        - 1800 requests per minute\n",
    "    - online (per minute):\n",
    "        - 600 per project\n",
    "        - 120 per project/processor/multi-region (US, EU)\n",
    "        - 6 per project/processor/single-region\n",
    "    - batch (concurrent jobs):\n",
    "        - 10 per project\n",
    "        - 5 per project/multi-region\n",
    "        - 5 per project/single-region\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e135a9-a292-4e2d-9123-39ddf676a376",
   "metadata": {},
   "source": [
    "---\n",
    "## TODO\n",
    "- add copy of files form github to local for the Colab\n",
    "- may need more file examples\n",
    "- use folder for type of demo: ocr, ocr_math, ocr_font, ocr_checkbox, form, invoice, summarizer\n",
    "    - some of these are actually for other workflow notebooks so dont copy all\n",
    "- save online to local for use in the process request notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6a6334-acdd-4d3b-ae3a-f70534973c89",
   "metadata": {
    "id": "od_UkDpvRmgD"
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab click [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Working%20With%20Document%20AI/Document%20AI%20-%20Process%20Documents.ipynb) and run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e795c7-1190-4f8b-a1a6-b07dd45864ae",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace3c8bd-e9f6-4ab1-9f39-5ce4c1ca40b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb438cf-7535-40ea-8642-c15d62b2588f",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs and API Enablement\n",
    "\n",
    "The clients packages may need installing in this environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c696d7-d04b-45b5-b1da-01bba96f031e",
   "metadata": {},
   "source": [
    "### Installs (If Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed80185a-2e33-4cff-bbce-53712ef38e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuples of (import name, install name)\n",
    "packages = [\n",
    "    ('google.cloud.documentai', 'google-cloud-documentai'),\n",
    "    ('google.cloud.documentai', 'google-cloud-storage'),\n",
    "    ('google.cloud.documentai', 'google-cloud-bigquery'),\n",
    "    ('PIL', 'Pillow'),\n",
    "    ('PyPDF2', 'PyPDF2'), \n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62380d65-d60d-4611-82e8-493fda40b433",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c2ed9b3-05f3-44aa-bd01-7da9b1b43462",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud services enable documentai.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece0930a-c857-4a01-a46e-2ccba0e06b50",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d38de82-e046-4ef0-a046-cae0ae2a44ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b965df-d97e-42df-8bde-511e05eec6a0",
   "metadata": {
    "id": "appt8-yVRtJ1"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d436ad0d-ebb3-4f54-80fe-ba78450e8c16",
   "metadata": {
    "id": "63mx2EozRxFP"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e46ed995-fa8f-442d-87f6-8bec6b4e366e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1683726390544,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "xzcoXjM5Rky5",
    "outputId": "b3bdcbc1-70d5-472e-aea2-42c74a42efde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d1b4370-fe3e-4a3c-969a-3a4f054271fd",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683726390712,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "IxWrFtqYMfku"
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'working-with-docai'\n",
    "EXPERIMENT = 'process-documents'\n",
    "\n",
    "# make this the gcs bucket for storing files\n",
    "GCS_BUCKET = PROJECT_ID\n",
    "\n",
    "# make this the BQ Project / Dataset / Table prefix to store responses\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = SERIES.replace('-', '_')\n",
    "BQ_TABLE = EXPERIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815116ff-ef1a-4a27-bc2a-5d30b7001f85",
   "metadata": {
    "id": "LuajVwCiO6Yg"
   },
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d56c9fe-1533-46f4-a6a5-3a565f76d3c0",
   "metadata": {
    "executionInfo": {
     "elapsed": 17761,
     "status": "ok",
     "timestamp": 1683726409304,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "LVC7zzSLRk2C"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-26 20:53:50.533237: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import IPython\n",
    "import PIL\n",
    "import PIL.ImageFont, PIL.Image, PIL.ImageDraw\n",
    "\n",
    "from google.cloud import documentai\n",
    "from google.cloud.documentai_v1 import Document\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3c0982-13dc-401f-b316-3a5c0d1b1a4a",
   "metadata": {
    "id": "EyAVFG9TO9H-"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a0aaead-df67-4741-8d59-706319c1d757",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683726409306,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "L0RPE13LOZce"
   },
   "outputs": [],
   "source": [
    "# document AI client\n",
    "LOCATION = REGION.split('-')[0]\n",
    "docai_client = documentai.DocumentProcessorServiceClient(\n",
    "    client_options = dict(api_endpoint = f\"{LOCATION}-documentai.googleapis.com\")\n",
    ")\n",
    "\n",
    "# bigquery client\n",
    "bq = bigquery.Client(project = PROJECT_ID)\n",
    "\n",
    "# gcs client: assumes bucket already exists\n",
    "gcs = storage.Client(project = PROJECT_ID)\n",
    "bucket = gcs.bucket(GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574382da-f227-42b5-8274-a1d988485798",
   "metadata": {},
   "source": [
    "---\n",
    "## Documents\n",
    "\n",
    "Local\n",
    "GCS - create structure from local documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7f8fc3-64ff-41c1-be17-042f5ea6c1e0",
   "metadata": {},
   "source": [
    "---\n",
    "## Processors\n",
    "\n",
    "describe\n",
    "\n",
    "list\n",
    "\n",
    "get/create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fb7995-99b9-4643-be00-48feb822a8f9",
   "metadata": {},
   "source": [
    "---\n",
    "## Online Processing (single document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2622ff7-bbf1-4745-812c-e78929e1d9b3",
   "metadata": {},
   "source": [
    "---\n",
    "## Batch Processing (multiple documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8765dcf3-ef13-4c52-8efa-05f28691651b",
   "metadata": {},
   "source": [
    "---\n",
    "## Async Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee97baeb-ce01-44da-bba8-4d8c417efe2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82e24af-50ab-4991-9b1d-f49b8c789e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f49041-a261-469a-b241-bbc917b6ae86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b30ac8-90cf-4db5-898d-ab90f570b9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923a8d3e-8eaa-4595-9b32-f2111046e248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc02138-683f-4127-bc31-6681fffcadc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f7b12-f90f-442f-95f5-84fb795c7d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae449f56-bccc-4973-b2a1-8fa6d2ec7de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4871e8-6133-413d-a61e-aa52f36386d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a0984-2489-4c8b-8c1c-ef664374abef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae2f11-7706-40ad-9238-a11004e0c5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babac35c-480b-425b-82bb-676f6c5f0466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91110eea-09db-4d1b-a698-5d95d0010b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8a504e-4091-424f-92e9-21ca0326f139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f319ff-95e4-4338-b5a6-0c467e8393a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f6f928-bd0c-43fe-b4d1-36bd274aeccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a2759c-b693-497f-8535-e4a60fec0acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
