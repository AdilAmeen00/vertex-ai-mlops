{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "signed-allergy",
   "metadata": {},
   "source": [
    "# TFX on AI Platform - Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adjusted-conclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.3.2\n",
      "TFX version: 0.28.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "import tfx\n",
    "print('TFX version: {}'.format(tfx.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-ministry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "careful-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO)  # Set default logging level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "quiet-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = 'my-pipeline'\n",
    "\n",
    "# Make the Directory Structure for the Pipeline\n",
    "LOCAL_DIR = PIPELINE_NAME\n",
    "DATA_PATH = 'gs://statmike-mlops/digits/data'\n",
    "TRAINER_PATH = '{}/trainer'.format(LOCAL_DIR)\n",
    "PIPELINE_PATH = '{}/pipeline'.format(LOCAL_DIR)\n",
    "METADATA_PATH = '{}/metadata/metadata.db'.format(LOCAL_DIR)\n",
    "MODEL_PATH = '{}/model'.format(LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "institutional-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {LOCAL_DIR}\n",
    "!mkdir {LOCAL_DIR}\n",
    "!mkdir {TRAINER_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "moving-commonwealth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing my-pipeline/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRAINER_PATH}/task.py\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "from tensorflow_io.bigquery import BigQueryReadSession\n",
    "import tensorflow as tf\n",
    "from google.cloud import bigquery\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "# the passed param, dest: a name for the param, default: if absent fetch this param from the OS, type: type to convert to, help: description of argument\n",
    "parser.add_argument('--model-dir', dest='model_dir', default=os.getenv(\"AIP_MODEL_DIR\"), type=str, help='Model dir.')\n",
    "parser.add_argument('--epochs',dest='epochs', default=10, type=int, help='Number of Epochs')\n",
    "parser.add_argument('--batch_size',dest='batch_size', default=32, type=int, help='Batch Size')\n",
    "#parser.add_argument('',dest='', default=, type=, help='')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# built in parameters for data source:\n",
    "#PROJECT_ID='statmike-mlops'\n",
    "#BQDATASET_ID='digits'\n",
    "#BQTABLE_ID='digits_prepped'\n",
    "\n",
    "selected_fields = ['p0', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19', 'p20', 'p21', 'p22', 'p23', 'p24', 'p25', 'p26', 'p27', 'p28', 'p29', 'p30', 'p31', 'p32', 'p33', 'p34', 'p35', 'p36', 'p37', 'p38', 'p39', 'p40', 'p41', 'p42', 'p43', 'p44', 'p45', 'p46', 'p47', 'p48', 'p49', 'p50', 'p51', 'p52', 'p53', 'p54', 'p55', 'p56', 'p57', 'p58', 'p59', 'p60', 'p61', 'p62', 'p63', 'target']\n",
    "output_types = ['FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'FLOAT64', 'INT64']\n",
    "\n",
    "feature_columns = []\n",
    "feature_layer_inputs = {}\n",
    "for header in selected_fields:\n",
    "    if header != 'target':\n",
    "        feature_columns.append(tf.feature_column.numeric_column(header))\n",
    "        feature_layer_inputs[header] = tf.keras.Input(shape=(1,),name=header)\n",
    "\n",
    "from tensorflow.python.framework import dtypes\n",
    "output_types = [dtypes.float64 if x=='FLOAT64' else dtypes.int64 for x in output_types]\n",
    "\n",
    "def transTable(row_dict):\n",
    "    target=row_dict.pop('target')\n",
    "    target = tf.one_hot(tf.cast(target,tf.int64),10)\n",
    "    target = tf.cast(target,tf.float32)\n",
    "    return(row_dict,target)\n",
    "\n",
    "#client = BigQueryClient()\n",
    "#session = client.read_session(\"projects/\"+PROJECT_ID,PROJECT_ID,BQTABLE_ID,BQDATASET_ID,selected_fields,output_types,row_restriction=\"SPLITS='TRAIN'\",requested_streams=3)\n",
    "#table = session.parallel_read_rows()\n",
    "table = table.map(transTable)\n",
    "train = table.shuffle(100000).batch(args.batch_size)\n",
    "\n",
    "#client = BigQueryClient()\n",
    "#session = client.read_session(\"projects/\"+PROJECT_ID,PROJECT_ID,BQTABLE_ID,BQDATASET_ID,selected_fields,output_types,row_restriction=\"SPLITS='TEST'\",requested_streams=3)\n",
    "#table = session.parallel_read_rows()\n",
    "table = table.map(transTable)\n",
    "test = table.batch(args.batch_size)\n",
    "\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "model = tf.keras.Model(inputs=[v for v in feature_layer_inputs.values()],outputs=tf.keras.layers.Dense(10,activation=tf.nn.softmax)(feature_layer_outputs))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#tf.keras.utils.plot_model(model,show_shapes=True, show_dtype=True)\n",
    "\n",
    "history = model.fit(train,epochs=args.epochs)\n",
    "\n",
    "model.save(args.model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "speaking-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.components import CsvExampleGen\n",
    "from tfx.extensions.google_cloud_big_query.example_gen import component as big_query_example_gen_component\n",
    "from tfx.components import Pusher\n",
    "from tfx.components import Trainer\n",
    "from tfx.components import SchemaGen\n",
    "from tfx.components import StatisticsGen\n",
    "from tfx.components.trainer.executor import GenericExecutor\n",
    "from tfx.dsl.components.base import executor_spec\n",
    "from tfx.orchestration import metadata\n",
    "from tfx.orchestration import pipeline\n",
    "from tfx.proto import pusher_pb2\n",
    "from tfx.proto import trainer_pb2\n",
    "from tfx.proto import example_gen_pb2\n",
    "from tfx.orchestration.local import local_dag_runner\n",
    "\n",
    "\n",
    "from typing import Optional, List, Text\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "organized-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_CLOUD_REGION = 'us-central1'\n",
    "GOOGLE_CLOUD_PROJECT='statmike-mlops'\n",
    "GCS_BUCKET_NAME=GOOGLE_CLOUD_PROJECT\n",
    "BIG_QUERY_WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS = [\n",
    "    '--project=' + GOOGLE_CLOUD_PROJECT,\n",
    "    '--temp_location=' + os.path.join('gs://', GCS_BUCKET_NAME, 'tmp'),\n",
    "    ]\n",
    "BIG_QUERY_QUERY = \"\"\"\n",
    "      SELECT * FROM `statmike-mlops.digits.digits_prepped`\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "technical-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mypipeline(pipeline_name: str, pipeline_path: str, data_path: str, query: str,\n",
    "                     train_file: str, model_path: str,\n",
    "                     metadata_path: str, beam_pipeline_args: Optional[List[Text]] = None) -> pipeline.Pipeline:\n",
    "\n",
    "  # Brings data into the pipeline.\n",
    "  #example_gen = CsvExampleGen(input_base=data_path)\n",
    "  #example_gen = big_query_example_gen_component.BigQueryExampleGen(query=query)\n",
    "\n",
    "  query_train = \"\"\"\n",
    "      SELECT * FROM `statmike-mlops.digits.digits_prepped` WHERE SPLITS='TRAIN'\n",
    "  \"\"\"\n",
    "  query_test = \"\"\"\n",
    "      SELECT * FROM `statmike-mlops.digits.digits_prepped` WHERE SPLITS='TEST'\n",
    "  \"\"\"\n",
    "    \n",
    "  input_pb2 = example_gen_pb2.Input(splits=[\n",
    "      example_gen_pb2.Input.Split(name='train', pattern=query_train),\n",
    "      example_gen_pb2.Input.Split(name='test', pattern=query_test)\n",
    "  ])\n",
    "  example_gen = big_query_example_gen_component.BigQueryExampleGen(input_config=input_pb2)\n",
    "\n",
    "\n",
    "  # Computes statistics over data for visualization and example validation.\n",
    "  statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])\n",
    "\n",
    "  # Generates schema based on statistics files.\n",
    "  schema_gen = SchemaGen(statistics=statistics_gen.outputs['statistics'],infer_feature_shape=True)\n",
    "\n",
    "  # Uses user-provided Python function that trains a model.\n",
    "  trainer = Trainer(\n",
    "      module_file=train_file,\n",
    "      custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),\n",
    "      examples=example_gen.outputs['examples'],\n",
    "      train_args=trainer_pb2.TrainArgs(num_steps=100),\n",
    "      eval_args=trainer_pb2.EvalArgs(num_steps=5))\n",
    "\n",
    "  # Pushes the model to a filesystem destination.\n",
    "  pusher = Pusher(\n",
    "      model=trainer.outputs['model'],\n",
    "      push_destination=pusher_pb2.PushDestination(\n",
    "          filesystem=pusher_pb2.PushDestination.Filesystem(\n",
    "              base_directory=model_path)))\n",
    "\n",
    "  # Following three components will be included in the pipeline.\n",
    "  components = [\n",
    "      example_gen,\n",
    "      statistics_gen,\n",
    "      schema_gen,\n",
    "      #trainer,\n",
    "      #pusher,\n",
    "  ]\n",
    "\n",
    "  return pipeline.Pipeline(\n",
    "      pipeline_name=pipeline_name,\n",
    "      pipeline_root=pipeline_path,\n",
    "      metadata_connection_config=metadata.sqlite_metadata_connection_config(metadata_path),\n",
    "      components=components,\n",
    "      beam_pipeline_args=beam_pipeline_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "immune-layer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Running pipeline:\n",
      " pipeline_info {\n",
      "  id: \"my-pipeline\"\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.extensions.google_cloud_big_query.example_gen.component.BigQueryExampleGen\"\n",
      "      }\n",
      "      id: \"BigQueryExampleGen\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my-pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"2021-04-15T18:44:21.599611\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my-pipeline.BigQueryExampleGen\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Examples\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "              properties {\n",
      "                key: \"version\"\n",
      "                value: INT\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"input_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"train\\\",\\n      \\\"pattern\\\": \\\"\\\\n      SELECT * FROM `statmike-mlops.digits.digits_prepped` WHERE SPLITS=\\'TRAIN\\'\\\\n  \\\"\\n    },\\n    {\\n      \\\"name\\\": \\\"test\\\",\\n      \\\"pattern\\\": \\\"\\\\n      SELECT * FROM `statmike-mlops.digits.digits_prepped` WHERE SPLITS=\\'TEST\\'\\\\n  \\\"\\n    }\\n  ]\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"output_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"output_data_format\"\n",
      "        value {\n",
      "          field_value {\n",
      "            int_value: 6\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    downstream_nodes: \"StatisticsGen\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "      }\n",
      "      id: \"StatisticsGen\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my-pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"2021-04-15T18:44:21.599611\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my-pipeline.StatisticsGen\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"BigQueryExampleGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my-pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"2021-04-15T18:44:21.599611\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my-pipeline.BigQueryExampleGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Examples\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"examples\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"statistics\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleStatistics\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"exclude_splits\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"[]\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"BigQueryExampleGen\"\n",
      "    downstream_nodes: \"SchemaGen\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
      "      }\n",
      "      id: \"SchemaGen\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my-pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"2021-04-15T18:44:21.599611\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my-pipeline.SchemaGen\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"statistics\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"StatisticsGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my-pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"2021-04-15T18:44:21.599611\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my-pipeline.StatisticsGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"ExampleStatistics\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"statistics\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"exclude_splits\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"[]\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"infer_feature_shape\"\n",
      "        value {\n",
      "          field_value {\n",
      "            int_value: 1\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"StatisticsGen\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "runtime_spec {\n",
      "  pipeline_root {\n",
      "    field_value {\n",
      "      string_value: \"my-pipeline/pipeline\"\n",
      "    }\n",
      "  }\n",
      "  pipeline_run_id {\n",
      "    field_value {\n",
      "      string_value: \"2021-04-15T18:44:21.599611\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "execution_mode: SYNC\n",
      "deployment_config {\n",
      "  type_url: \"type.googleapis.com/tfx.orchestration.IntermediateDeploymentConfig\"\n",
      "  value: \"\\n\\331\\001\\n\\rStatisticsGen\\022\\307\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\022t\\n/tfx.components.statistics_gen.executor.Executor\\022\\030--project=statmike-mlops\\022\\'--temp_location=gs://statmike-mlops/tmp\\n\\321\\001\\n\\tSchemaGen\\022\\303\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\022p\\n+tfx.components.schema_gen.executor.Executor\\022\\030--project=statmike-mlops\\022\\'--temp_location=gs://statmike-mlops/tmp\\n\\363\\001\\n\\022BigQueryExampleGen\\022\\334\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\022\\210\\001\\nCtfx.extensions.google_cloud_big_query.example_gen.executor.Executor\\022\\030--project=statmike-mlops\\022\\'--temp_location=gs://statmike-mlops/tmp*Z\\n0type.googleapis.com/ml_metadata.ConnectionConfig\\022&\\032$\\n my-pipeline/metadata/metadata.db\\020\\003\"\n",
      "}\n",
      "\n",
      "INFO:absl:Using deployment config:\n",
      " executor_specs {\n",
      "  key: \"BigQueryExampleGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.extensions.google_cloud_big_query.example_gen.executor.Executor\"\n",
      "      extra_flags: \"--project=statmike-mlops\"\n",
      "      extra_flags: \"--temp_location=gs://statmike-mlops/tmp\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"SchemaGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.schema_gen.executor.Executor\"\n",
      "      extra_flags: \"--project=statmike-mlops\"\n",
      "      extra_flags: \"--temp_location=gs://statmike-mlops/tmp\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"StatisticsGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.statistics_gen.executor.Executor\"\n",
      "      extra_flags: \"--project=statmike-mlops\"\n",
      "      extra_flags: \"--temp_location=gs://statmike-mlops/tmp\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "metadata_connection_config {\n",
      "  sqlite {\n",
      "    filename_uri: \"my-pipeline/metadata/metadata.db\"\n",
      "    connection_mode: READWRITE_OPENCREATE\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Using connection config:\n",
      " sqlite {\n",
      "  filename_uri: \"my-pipeline/metadata/metadata.db\"\n",
      "  connection_mode: READWRITE_OPENCREATE\n",
      "}\n",
      "\n",
      "INFO:absl:Component BigQueryExampleGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.extensions.google_cloud_big_query.example_gen.component.BigQueryExampleGen\"\n",
      "  }\n",
      "  id: \"BigQueryExampleGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"my-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-04-15T18:44:21.599611\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"my-pipeline.BigQueryExampleGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"train\\\",\\n      \\\"pattern\\\": \\\"\\\\n      SELECT * FROM `statmike-mlops.digits.digits_prepped` WHERE SPLITS=\\'TRAIN\\'\\\\n  \\\"\\n    },\\n    {\\n      \\\"name\\\": \\\"test\\\",\\n      \\\"pattern\\\": \\\"\\\\n      SELECT * FROM `statmike-mlops.digits.digits_prepped` WHERE SPLITS=\\'TEST\\'\\\\n  \\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 11\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=11, input_dict={}, output_dict=defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"my-pipeline/pipeline/BigQueryExampleGen/examples/11\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"my-pipeline:2021-04-15T18:44:21.599611:BigQueryExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      ")]}), exec_properties={'output_config': '{}', 'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"train\",\\n      \"pattern\": \"\\\\n      SELECT * FROM `statmike-mlops.digits.digits_prepped` WHERE SPLITS=\\'TRAIN\\'\\\\n  \"\\n    },\\n    {\\n      \"name\": \"test\",\\n      \"pattern\": \"\\\\n      SELECT * FROM `statmike-mlops.digits.digits_prepped` WHERE SPLITS=\\'TEST\\'\\\\n  \"\\n    }\\n  ]\\n}', 'output_data_format': 6}, execution_output_uri='my-pipeline/pipeline/BigQueryExampleGen/.system/executor_execution/11/executor_output.pb', stateful_working_dir='my-pipeline/pipeline/BigQueryExampleGen/.system/stateful_working_dir/2021-04-15T18:44:21.599611', tmp_dir='my-pipeline/pipeline/BigQueryExampleGen/.system/executor_execution/11/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.extensions.google_cloud_big_query.example_gen.component.BigQueryExampleGen\"\n",
      "  }\n",
      "  id: \"BigQueryExampleGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"my-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-04-15T18:44:21.599611\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"my-pipeline.BigQueryExampleGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"train\\\",\\n      \\\"pattern\\\": \\\"\\\\n      SELECT * FROM `statmike-mlops.digits.digits_prepped` WHERE SPLITS=\\'TRAIN\\'\\\\n  \\\"\\n    },\\n    {\\n      \\\"name\\\": \\\"test\\\",\\n      \\\"pattern\\\": \\\"\\\\n      SELECT * FROM `statmike-mlops.digits.digits_prepped` WHERE SPLITS=\\'TEST\\'\\\\n  \\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"my-pipeline\"\n",
      ", pipeline_run_id='2021-04-15T18:44:21.599611')\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/home/jupyter/.local/share/jupyter/runtime/kernel-8e2424ea-5ef1-4a2a-885e-bec76182bb80.json']\n",
      "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
      "INFO:absl:Copying all content from install dir /opt/conda/lib/python3.7/site-packages/tfx to temp dir /tmp/tmpkadm7uu8/build/tfx\n",
      "INFO:absl:Generating a temp setup file at /tmp/tmpkadm7uu8/build/tfx/setup.py\n",
      "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpkadm7uu8/build/tfx/setup.log\n",
      "INFO:absl:Added --extra_package=/tmp/tmpkadm7uu8/build/tfx/dist/tfx_ephemeral-0.28.0.tar.gz to beam args\n",
      "INFO:absl:Generating examples.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/home/jupyter/.local/share/jupyter/runtime/kernel-8e2424ea-5ef1-4a2a-885e-bec76182bb80.json']\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset statmike-mlops:temp_dataset_9c29296e6bbf4cf8bfb193d304f3f4a1 does not exist so we will create it as temporary with location=US\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset statmike-mlops:temp_dataset_f436e2f5edae4cb3ba83aa93ef3e17ef does not exist so we will create it as temporary with location=US\n",
      "INFO:absl:Examples generated.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 11 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"my-pipeline/pipeline/BigQueryExampleGen/examples/11\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"test\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"my-pipeline:2021-04-15T18:44:21.599611:BigQueryExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      ")]}) for exeuction 11\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component BigQueryExampleGen is finished.\n",
      "INFO:absl:Component StatisticsGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "  }\n",
      "  id: \"StatisticsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"my-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-04-15T18:44:21.599611\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"my-pipeline.StatisticsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"BigQueryExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"my-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-04-15T18:44:21.599611\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"my-pipeline.BigQueryExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"BigQueryExampleGen\"\n",
      "downstream_nodes: \"SchemaGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 12\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=12, input_dict={'examples': [Artifact(artifact: id: 11\n",
      "type_id: 6\n",
      "uri: \"my-pipeline/pipeline/BigQueryExampleGen/examples/11\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"test\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"my-pipeline:2021-04-15T18:44:21.599611:BigQueryExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1618512294656\n",
      "last_update_time_since_epoch: 1618512294656\n",
      ", artifact_type: id: 6\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"my-pipeline/pipeline/StatisticsGen/statistics/12\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"my-pipeline:2021-04-15T18:44:21.599611:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='my-pipeline/pipeline/StatisticsGen/.system/executor_execution/12/executor_output.pb', stateful_working_dir='my-pipeline/pipeline/StatisticsGen/.system/stateful_working_dir/2021-04-15T18:44:21.599611', tmp_dir='my-pipeline/pipeline/StatisticsGen/.system/executor_execution/12/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "  }\n",
      "  id: \"StatisticsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"my-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-04-15T18:44:21.599611\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"my-pipeline.StatisticsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"BigQueryExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"my-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-04-15T18:44:21.599611\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"my-pipeline.BigQueryExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"BigQueryExampleGen\"\n",
      "downstream_nodes: \"SchemaGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"my-pipeline\"\n",
      ", pipeline_run_id='2021-04-15T18:44:21.599611')\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/home/jupyter/.local/share/jupyter/runtime/kernel-8e2424ea-5ef1-4a2a-885e-bec76182bb80.json']\n",
      "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
      "INFO:absl:Copying all content from install dir /opt/conda/lib/python3.7/site-packages/tfx to temp dir /tmp/tmp11956j_g/build/tfx\n",
      "INFO:absl:Generating a temp setup file at /tmp/tmp11956j_g/build/tfx/setup.py\n",
      "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmp11956j_g/build/tfx/setup.log\n",
      "INFO:absl:Added --extra_package=/tmp/tmp11956j_g/build/tfx/dist/tfx_ephemeral-0.28.0.tar.gz to beam args\n",
      "INFO:absl:Generating statistics for split train.\n",
      "INFO:absl:Statistics for split train written to my-pipeline/pipeline/StatisticsGen/statistics/12/train.\n",
      "INFO:absl:Generating statistics for split test.\n",
      "INFO:absl:Statistics for split test written to my-pipeline/pipeline/StatisticsGen/statistics/12/test.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/home/jupyter/.local/share/jupyter/runtime/kernel-8e2424ea-5ef1-4a2a-885e-bec76182bb80.json']\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 12 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"my-pipeline/pipeline/StatisticsGen/statistics/12\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"test\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"my-pipeline:2021-04-15T18:44:21.599611:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}) for exeuction 12\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component StatisticsGen is finished.\n",
      "INFO:absl:Component SchemaGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
      "  }\n",
      "  id: \"SchemaGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"my-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-04-15T18:44:21.599611\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"my-pipeline.SchemaGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"my-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-04-15T18:44:21.599611\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"my-pipeline.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"infer_feature_shape\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 13\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=13, input_dict={'statistics': [Artifact(artifact: id: 12\n",
      "type_id: 8\n",
      "uri: \"my-pipeline/pipeline/StatisticsGen/statistics/12\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"test\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"my-pipeline:2021-04-15T18:44:21.599611:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1618512299126\n",
      "last_update_time_since_epoch: 1618512299126\n",
      ", artifact_type: id: 8\n",
      "name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"my-pipeline/pipeline/SchemaGen/schema/13\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"my-pipeline:2021-04-15T18:44:21.599611:SchemaGen:schema:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Schema\"\n",
      ")]}), exec_properties={'infer_feature_shape': 1, 'exclude_splits': '[]'}, execution_output_uri='my-pipeline/pipeline/SchemaGen/.system/executor_execution/13/executor_output.pb', stateful_working_dir='my-pipeline/pipeline/SchemaGen/.system/stateful_working_dir/2021-04-15T18:44:21.599611', tmp_dir='my-pipeline/pipeline/SchemaGen/.system/executor_execution/13/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
      "  }\n",
      "  id: \"SchemaGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"my-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-04-15T18:44:21.599611\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"my-pipeline.SchemaGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"my-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-04-15T18:44:21.599611\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"my-pipeline.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"infer_feature_shape\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"my-pipeline\"\n",
      ", pipeline_run_id='2021-04-15T18:44:21.599611')\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/home/jupyter/.local/share/jupyter/runtime/kernel-8e2424ea-5ef1-4a2a-885e-bec76182bb80.json']\n",
      "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
      "INFO:absl:Copying all content from install dir /opt/conda/lib/python3.7/site-packages/tfx to temp dir /tmp/tmp7jz297vo/build/tfx\n",
      "INFO:absl:Generating a temp setup file at /tmp/tmp7jz297vo/build/tfx/setup.py\n",
      "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmp7jz297vo/build/tfx/setup.log\n",
      "INFO:absl:Added --extra_package=/tmp/tmp7jz297vo/build/tfx/dist/tfx_ephemeral-0.28.0.tar.gz to beam args\n",
      "INFO:absl:Processing schema from statistics for split train.\n",
      "INFO:absl:Processing schema from statistics for split test.\n",
      "INFO:absl:Schema written to my-pipeline/pipeline/SchemaGen/schema/13/schema.pbtxt.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 13 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"my-pipeline/pipeline/SchemaGen/schema/13\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"my-pipeline:2021-04-15T18:44:21.599611:SchemaGen:schema:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Schema\"\n",
      ")]}) for exeuction 13\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component SchemaGen is finished.\n"
     ]
    }
   ],
   "source": [
    "local_dag_runner.LocalDagRunner().run(mypipeline(\n",
    "    pipeline_name=PIPELINE_NAME,\n",
    "    pipeline_path=PIPELINE_PATH,\n",
    "    data_path=DATA_PATH,\n",
    "    query = BIG_QUERY_QUERY,\n",
    "    train_file=TRAINER_PATH+'/task.py',\n",
    "    model_path=MODEL_PATH,\n",
    "    beam_pipeline_args=BIG_QUERY_WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS,\n",
    "    metadata_path=METADATA_PATH\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "married-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "formal-scanner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:InteractiveContext pipeline_root argument not provided: using temporary directory /tmp/tfx-interactive-2021-04-15T18_45_10.376606-jlzho006 as root for pipeline outputs.\n",
      "WARNING:absl:InteractiveContext metadata_connection_config not provided: using SQLite ML Metadata database at /tmp/tfx-interactive-2021-04-15T18_45_10.376606-jlzho006/metadata.sqlite.\n"
     ]
    }
   ],
   "source": [
    "context = InteractiveContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "young-start",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Running driver for BigQueryExampleGen\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running executor for BigQueryExampleGen\n",
      "INFO:absl:Generating examples.\n",
      "WARNING:apache_beam.utils.retry:Retry with exponential backoff: waiting for 2.8792603772341776 seconds before retrying _start_query_job because we caught exception: apitools.base.py.exceptions.InvalidUserInputError: Request missing required parameter projectId\n",
      " Traceback for above exception (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apache_beam/utils/retry.py\", line 260, in wrapper\n",
      "    return fun(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery_tools.py\", line 501, in _start_query_job\n",
      "    return self._start_job(request)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery_tools.py\", line 449, in _start_job\n",
      "    response = self.client.jobs.Insert(request)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/internal/clients/bigquery/bigquery_v2_client.py\", line 347, in Insert\n",
      "    upload=upload, upload_config=upload_config)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apitools/base/py/base_api.py\", line 703, in _RunMethod\n",
      "    download)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apitools/base/py/base_api.py\", line 684, in PrepareHttpRequest\n",
      "    method_config, request, relative_path=url_builder.relative_path)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apitools/base/py/base_api.py\", line 584, in __ConstructRelativePath\n",
      "    relative_path=relative_path)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apitools/base/py/util.py\", line 130, in ExpandRelativePath\n",
      "    'Request missing required parameter %s' % param)\n",
      "\n",
      "WARNING:apache_beam.utils.retry:Retry with exponential backoff: waiting for 6.076272075516826 seconds before retrying _start_query_job because we caught exception: apitools.base.py.exceptions.InvalidUserInputError: Request missing required parameter projectId\n",
      " Traceback for above exception (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apache_beam/utils/retry.py\", line 260, in wrapper\n",
      "    return fun(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery_tools.py\", line 501, in _start_query_job\n",
      "    return self._start_job(request)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery_tools.py\", line 449, in _start_job\n",
      "    response = self.client.jobs.Insert(request)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/internal/clients/bigquery/bigquery_v2_client.py\", line 347, in Insert\n",
      "    upload=upload, upload_config=upload_config)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apitools/base/py/base_api.py\", line 703, in _RunMethod\n",
      "    download)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apitools/base/py/base_api.py\", line 684, in PrepareHttpRequest\n",
      "    method_config, request, relative_path=url_builder.relative_path)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apitools/base/py/base_api.py\", line 584, in __ConstructRelativePath\n",
      "    relative_path=relative_path)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apitools/base/py/util.py\", line 130, in ExpandRelativePath\n",
      "    'Request missing required parameter %s' % param)\n",
      "\n",
      "WARNING:apache_beam.utils.retry:Retry with exponential backoff: waiting for 18.18441151575216 seconds before retrying _start_query_job because we caught exception: apitools.base.py.exceptions.InvalidUserInputError: Request missing required parameter projectId\n",
      " Traceback for above exception (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apache_beam/utils/retry.py\", line 260, in wrapper\n",
      "    return fun(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery_tools.py\", line 501, in _start_query_job\n",
      "    return self._start_job(request)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery_tools.py\", line 449, in _start_job\n",
      "    response = self.client.jobs.Insert(request)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/internal/clients/bigquery/bigquery_v2_client.py\", line 347, in Insert\n",
      "    upload=upload, upload_config=upload_config)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apitools/base/py/base_api.py\", line 703, in _RunMethod\n",
      "    download)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apitools/base/py/base_api.py\", line 684, in PrepareHttpRequest\n",
      "    method_config, request, relative_path=url_builder.relative_path)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apitools/base/py/base_api.py\", line 584, in __ConstructRelativePath\n",
      "    relative_path=relative_path)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apitools/base/py/util.py\", line 130, in ExpandRelativePath\n",
      "    'Request missing required parameter %s' % param)\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidUserInputError",
     "evalue": "Request missing required parameter projectId [while running 'InputToRecord/QueryTable/ReadFromBigQuery/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/SplitAndSizeRestriction']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/utils/retry.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m               \u001b[0msleep_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_intervals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidUserInputError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputProcessor.process_outputs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/bundle_processor.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, element_restriction, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1446\u001b[0m       for part, size in self.restriction_provider.split_and_size(\n\u001b[0;32m-> 1447\u001b[0;31m           element, restriction):\n\u001b[0m\u001b[1;32m   1448\u001b[0m         estimator_state = (\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/transforms/core.py\u001b[0m in \u001b[0;36msplit_and_size\u001b[0;34m(self, element, restriction)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \"\"\"\n\u001b[0;32m--> 333\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestriction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestriction_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/io/iobase.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, element, restriction)\u001b[0m\n\u001b[1;32m   1558\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1559\u001b[0;31m         \u001b[0mestimated_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestriction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1560\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py\u001b[0m in \u001b[0;36mestimate_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    751\u001b[0m           job_labels=self._get_bq_metadata().add_additional_bq_job_labels(\n\u001b[0;32m--> 752\u001b[0;31m               self.bigquery_job_labels))\n\u001b[0m\u001b[1;32m    753\u001b[0m       \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotalBytesProcessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/utils/retry.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m               \u001b[0;31m# Re-raise the original exception since we finished the retries.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m               \u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexn_traceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/future/utils/__init__.py\u001b[0m in \u001b[0;36mraise_with_traceback\u001b[0;34m(exc, traceback)\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/utils/retry.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexn\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery_tools.py\u001b[0m in \u001b[0;36m_start_query_job\u001b[0;34m(self, project_id, query, use_legacy_sql, flatten_results, job_id, dry_run, kms_key, job_labels)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery_tools.py\u001b[0m in \u001b[0;36m_start_job\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m       \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m       _LOGGER.info(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/internal/clients/bigquery/bigquery_v2_client.py\u001b[0m in \u001b[0;36mInsert\u001b[0;34m(self, request, global_params, upload)\u001b[0m\n\u001b[1;32m    346\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m           upload=upload, upload_config=upload_config)\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apitools/base/py/base_api.py\u001b[0m in \u001b[0;36m_RunMethod\u001b[0;34m(self, method_config, request, global_params, upload, upload_config, download)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mmethod_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             download)\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apitools/base/py/base_api.py\u001b[0m in \u001b[0;36mPrepareHttpRequest\u001b[0;34m(self, method_config, request, global_params, upload, upload_config, download)\u001b[0m\n\u001b[1;32m    683\u001b[0m         url_builder.relative_path = self.__ConstructRelativePath(\n\u001b[0;32m--> 684\u001b[0;31m             method_config, request, relative_path=url_builder.relative_path)\n\u001b[0m\u001b[1;32m    685\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__FinalizeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_builder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apitools/base/py/base_api.py\u001b[0m in \u001b[0;36m__ConstructRelativePath\u001b[0;34m(self, method_config, request, relative_path)\u001b[0m\n\u001b[1;32m    583\u001b[0m         return util.ExpandRelativePath(method_config, params,\n\u001b[0;32m--> 584\u001b[0;31m                                        relative_path=relative_path)\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apitools/base/py/util.py\u001b[0m in \u001b[0;36mExpandRelativePath\u001b[0;34m(method_config, params, relative_path)\u001b[0m\n\u001b[1;32m    129\u001b[0m             raise exceptions.InvalidUserInputError(\n\u001b[0;32m--> 130\u001b[0;31m                 'Request missing required parameter %s' % param)\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidUserInputError\u001b[0m: Request missing required parameter projectId",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidUserInputError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-b075cfa333e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tfx/orchestration/experimental/interactive/interactive_context.py\u001b[0m in \u001b[0;36mrun_if_ipython\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0;31m# __IPYTHON__ variable is set by IPython, see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0;31m# https://ipython.org/ipython-doc/rel-0.10.2/html/interactive/reference.html#embedding-ipython.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       absl.logging.warning(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tfx/orchestration/experimental/interactive/interactive_context.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, component, enable_cache, beam_pipeline_args)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mtelemetry_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLABEL_TFX_RUNNER\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrunner_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     }):\n\u001b[0;32m--> 182\u001b[0;31m       \u001b[0mexecution_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     return execution_result.ExecutionResult(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tfx/orchestration/launcher/base_component_launcher.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_decision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                          \u001b[0mexecution_decision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                          copy.deepcopy(execution_decision.exec_properties))\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     absl.logging.info('Running publisher for %s',\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tfx/orchestration/launcher/in_process_component_launcher.py\u001b[0m in \u001b[0;36m_run_executor\u001b[0;34m(self, execution_id, input_dict, output_dict, exec_properties)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# output_dict can still be changed, specifically properties.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     executor.Do(\n\u001b[0;32m---> 72\u001b[0;31m         copy.deepcopy(input_dict), output_dict, copy.deepcopy(exec_properties))\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tfx/components/example_gen/base_example_gen_executor.py\u001b[0m in \u001b[0;36mDo\u001b[0;34m(self, input_dict, output_dict, exec_properties)\u001b[0m\n\u001b[1;32m    322\u001b[0m              artifact_utils.get_split_uri(\n\u001b[1;32m    323\u001b[0m                  \u001b[0moutput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstandard_component_specs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXAMPLES_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                  split_name)))\n\u001b[0m\u001b[1;32m    325\u001b[0m       \u001b[0;31m# pylint: enable=expression-not-assigned, no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_until_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/pipeline.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, test_runner_api)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m           \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmpdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m       \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_tempdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/direct/direct_runner.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(self, pipeline, options)\u001b[0m\n\u001b[1;32m    131\u001b[0m       \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBundleBasedDirectRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(self, pipeline, options)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     self._latest_run_result = self.run_via_runner_api(\n\u001b[0;32m--> 183\u001b[0;31m         pipeline.to_runner_api(default_environment=self._default_environment))\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_latest_run_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mrun_via_runner_api\u001b[0;34m(self, pipeline_proto)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# TODO(pabloem, BEAM-7514): Create a watermark manager (that has access to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;31m#   the teststream (if any), and all the stages).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mrun_stages\u001b[0;34m(self, stage_context, stages)\u001b[0m\n\u001b[1;32m    357\u001b[0m           stage_results = self._run_stage(\n\u001b[1;32m    358\u001b[0m               \u001b[0mrunner_execution_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m               \u001b[0mbundle_context_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m           )\n\u001b[1;32m    361\u001b[0m           monitoring_infos_by_stage[stage.name] = (\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self, runner_execution_context, bundle_context_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m               \u001b[0minput_timers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m               \u001b[0mexpected_timer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m               bundle_manager)\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m       \u001b[0mfinal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36m_run_bundle\u001b[0;34m(self, runner_execution_context, bundle_context_manager, data_input, data_output, input_timers, expected_timer_output, bundle_manager)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     result, splits = bundle_manager.process_bundle(\n\u001b[0;32m--> 595\u001b[0;31m         data_input, data_output, input_timers, expected_timer_output)\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[0;31m# Now we collect all the deferred inputs remaining from bundle execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0;31m# Deferred inputs can be:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mprocess_bundle\u001b[0;34m(self, inputs, expected_outputs, fired_timers, expected_output_timers, dry_run)\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mprocess_bundle_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             cache_tokens=[next(self._cache_token_generator)]))\n\u001b[0;32m--> 896\u001b[0;31m     \u001b[0mresult_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_bundle_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0msplit_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: List[beam_fn_api_pb2.ProcessBundleSplitResponse]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/worker_handlers.py\u001b[0m in \u001b[0;36mpush\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    378\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uid_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstruction_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'control_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uid_counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_instruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mControlFuture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstruction_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py\u001b[0m in \u001b[0;36mdo_instruction\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# E.g. if register is set, this will call self.register(request.register))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m       return getattr(self, request_type)(\n\u001b[0;32m--> 607\u001b[0;31m           getattr(request, request_type), request.instruction_id)\n\u001b[0m\u001b[1;32m    608\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py\u001b[0m in \u001b[0;36mprocess_bundle\u001b[0;34m(self, request, instruction_id)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m           delayed_applications, requests_finalization = (\n\u001b[0;32m--> 644\u001b[0;31m               bundle_processor.process_bundle(instruction_id))\n\u001b[0m\u001b[1;32m    645\u001b[0m           \u001b[0mmonitoring_infos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbundle_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitoring_infos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m           \u001b[0mmonitoring_infos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_cache_metrics_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/bundle_processor.py\u001b[0m in \u001b[0;36mprocess_bundle\u001b[0;34m(self, instruction_id)\u001b[0m\n\u001b[1;32m    998\u001b[0m           \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_fn_api_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mElements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             input_op_by_transform_id[element.transform_id].process_encoded(\n\u001b[0;32m-> 1000\u001b[0;31m                 element.data)\n\u001b[0m\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m       \u001b[0;31m# Finish all operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/bundle_processor.py\u001b[0m in \u001b[0;36mprocess_encoded\u001b[0;34m(self, encoded_windowed_values)\u001b[0m\n\u001b[1;32m    226\u001b[0m       decoded_value = self.windowed_coder_impl.decode_from_stream(\n\u001b[1;32m    227\u001b[0m           input_stream, True)\n\u001b[0;32m--> 228\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmonitoring_infos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_to_pcollection_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.Operation.output\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.Operation.output\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputProcessor.process_outputs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputProcessor.process_outputs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/future/utils/__init__.py\u001b[0m in \u001b[0;36mraise_with_traceback\u001b[0;34m(exc, traceback)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEllipsis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputProcessor.process_outputs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/runners/worker/bundle_processor.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, element_restriction, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m       \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrestriction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement_restriction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m       for part, size in self.restriction_provider.split_and_size(\n\u001b[0;32m-> 1447\u001b[0;31m           element, restriction):\n\u001b[0m\u001b[1;32m   1448\u001b[0m         estimator_state = (\n\u001b[1;32m   1449\u001b[0m             self.watermark_estimator_provider.initial_estimator_state(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/transforms/core.py\u001b[0m in \u001b[0;36msplit_and_size\u001b[0;34m(self, element, restriction)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0mimplemented\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \"\"\"\n\u001b[0;32m--> 333\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestriction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestriction_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/io/iobase.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, element, restriction)\u001b[0m\n\u001b[1;32m   1557\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_desired_chunk_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1559\u001b[0;31m         \u001b[0mestimated_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestriction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1560\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m         \u001b[0mestimated_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py\u001b[0m in \u001b[0;36mestimate_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    750\u001b[0m           \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m           job_labels=self._get_bq_metadata().add_additional_bq_job_labels(\n\u001b[0;32m--> 752\u001b[0;31m               self.bigquery_job_labels))\n\u001b[0m\u001b[1;32m    753\u001b[0m       \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotalBytesProcessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/utils/retry.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m               \u001b[0;31m# Re-raise the original exception since we finished the retries.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m               \u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexn_traceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             logger(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/future/utils/__init__.py\u001b[0m in \u001b[0;36mraise_with_traceback\u001b[0;34m(exc, traceback)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEllipsis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/utils/retry.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexn\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mretry_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery_tools.py\u001b[0m in \u001b[0;36m_start_query_job\u001b[0;34m(self, project_id, query, use_legacy_sql, flatten_results, job_id, dry_run, kms_key, job_labels)\u001b[0m\n\u001b[1;32m    499\u001b[0m             jobReference=reference))\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait_for_bq_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_reference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msleep_duration_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery_tools.py\u001b[0m in \u001b[0;36m_start_job\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \"\"\"\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m       \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m       _LOGGER.info(\n\u001b[1;32m    451\u001b[0m           \u001b[0;34m\"Stated BigQuery job: %s\\n \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/internal/clients/bigquery/bigquery_v2_client.py\u001b[0m in \u001b[0;36mInsert\u001b[0;34m(self, request, global_params, upload)\u001b[0m\n\u001b[1;32m    345\u001b[0m       return self._RunMethod(\n\u001b[1;32m    346\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m           upload=upload, upload_config=upload_config)\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     Insert.method_config = lambda: base_api.ApiMethodInfo(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apitools/base/py/base_api.py\u001b[0m in \u001b[0;36m_RunMethod\u001b[0;34m(self, method_config, request, global_params, upload, upload_config, download)\u001b[0m\n\u001b[1;32m    701\u001b[0m         http_request = self.PrepareHttpRequest(\n\u001b[1;32m    702\u001b[0m             \u001b[0mmethod_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             download)\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# TODO(craigcitro): Make num_retries customizable on Transfer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apitools/base/py/base_api.py\u001b[0m in \u001b[0;36mPrepareHttpRequest\u001b[0;34m(self, method_config, request, global_params, upload, upload_config, download)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         url_builder.relative_path = self.__ConstructRelativePath(\n\u001b[0;32m--> 684\u001b[0;31m             method_config, request, relative_path=url_builder.relative_path)\n\u001b[0m\u001b[1;32m    685\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__FinalizeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_builder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apitools/base/py/base_api.py\u001b[0m in \u001b[0;36m__ConstructRelativePath\u001b[0;34m(self, method_config, request, relative_path)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapRequestParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         return util.ExpandRelativePath(method_config, params,\n\u001b[0;32m--> 584\u001b[0;31m                                        relative_path=relative_path)\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__FinalizeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_builder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/apitools/base/py/util.py\u001b[0m in \u001b[0;36mExpandRelativePath\u001b[0;34m(method_config, params, relative_path)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             raise exceptions.InvalidUserInputError(\n\u001b[0;32m--> 130\u001b[0;31m                 'Request missing required parameter %s' % param)\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidUserInputError\u001b[0m: Request missing required parameter projectId [while running 'InputToRecord/QueryTable/ReadFromBigQuery/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/SplitAndSizeRestriction']"
     ]
    }
   ],
   "source": [
    "context.run(example_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-aquatic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-respect",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
