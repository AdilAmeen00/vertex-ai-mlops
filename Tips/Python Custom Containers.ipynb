{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11f5c7a1-37b6-4bae-8e4a-89b4d8bd7af7",
   "metadata": {},
   "source": [
    "# Python Client for Cloud Build\n",
    "### IN ACTIVE DEVELOPMENT - not complete\n",
    "\n",
    "Containers are helpful.\n",
    "\n",
    "> TL;DR\n",
    "> Use containers to bring together **software** and training **code** so that you can easily launch jobs on different **compute** with different **parameters** to simplify the operations of ML training.\n",
    "\n",
    "At the moment we train an ML model a lot of things come together to make it happen:\n",
    "- **compute** in running: CPUs, memory, networking, GPUs on one or more instances\n",
    "- **software** is running on the compute\n",
    "    - the required packages are installed with the software\n",
    "- training **code**/script is launched with the software\n",
    "- training **data** is read by the training code\n",
    "- **parameters** that the code uses to configure the training run\n",
    "\n",
    "It's tempting to develop in an IDE, like JupyterLab here, and then just make the VM behind it much larger.  This note book here is running in JupyterLab hosted on **compute** running **software** and is being used to author **code** that reads **data** using **parameters** set as Python variables.  One of the issues with that is that typing these words just cost `$$$$` and this instance might not be able to run this notebook 10 times in parallel with different **parameters**.  \n",
    "\n",
    "A better way?  Keep using an enviorment like this to develop our **code** and make sure it works. Just use smaller **compute** and **data** during this development process.  Then, launch a sepearate, managed job, that runs the full training.  How? What if we could instruct a service to take the list of inputs above and run a job and only charge for the compute used for the duration of training? That is exactly what Vertex AI Training is used for.  With that in mind it also helps scale the usefulness of training as a next step:\n",
    "- specify distributed training, pools of compute instances\n",
    "- manage hyperparameter tuning with multiple parallel training jobs focusing in on the right values for hyperparameters\n",
    "- run many training jobs at the same time without managing compute but also controling cost of this scale\n",
    "\n",
    "Vertex AI has a [list of provided pre-built training containers](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers) for the most popular frameworks.  They are made available in multiple release versions of the frameworks and with/without [CUDA](https://developer.nvidia.com/cuda-toolkit) already configured and setup for GPU based training.\n",
    "\n",
    "For Vertex AI Training Custom Jobs you:\n",
    "- specify the **compute** to use in parameters or as worker pool specs\n",
    "- provide a URI for a container with the **software** to use\n",
    "- provide training **code** in one of three ways\n",
    "    - as a link to a Python script (file.py)\n",
    "    - as URI to GCS for a Python Source Distribution\n",
    "    - as a starting point to code already included on the container with the **software**\n",
    "- provide **data**\n",
    "    - as a **parameter** specifying the location the **code** can use to retrieve it\n",
    "    - or build the logic for connecting to the data source into the **code**\n",
    "\n",
    "If we learn the skill of building a derivative containers that packages our desired **software** and install additional packages while also holding a copy of our **code** and maybe even our **parameters** then this ML training jobs become very simple to incorporate in our workflow!\n",
    "\n",
    "That is this notebooks goal.\n",
    "\n",
    "---\n",
    "**We will use [Cloud Build](https://cloud.google.com/build) to construct containers.**\n",
    "\n",
    "- [API Overview](https://cloud.google.com/build/docs/api)\n",
    "    - REST API, gcloud CLI, and Client Libraries for Go, Java, Node.js, and Python\n",
    "- [Python Client for Cloud Build API](https://github.com/googleapis/python-cloudbuild)\n",
    "- [Python Client Library Documentation](https://cloud.google.com/python/docs/reference/cloudbuild/latest)\n",
    "\n",
    "---\n",
    "**We will store built containers in [Artifact Registry](https://cloud.google.com/artifact-registry).**\n",
    "\n",
    "- [API Overview](https://cloud.google.com/artifact-registry/docs/apis)\n",
    "- [Python Client for Artifact Registry API](https://github.com/googleapis/python-artifact-registry)\n",
    "- [Python Client Library Documentation](https://cloud.google.com/python/docs/reference/artifactregistry/latest)\n",
    "\n",
    "---\n",
    "**Notes on Python and Google Cloud:**\n",
    "\n",
    "Google Cloud APIs can be used with the [Google Cloud Python Client](https://github.com/googleapis/google-cloud-python).  The client has [libraries](https://github.com/googleapis/google-cloud-python#libraries) for Google Cloud services.  The documentation for each library is centralized in the [Python Cloud Client Libraries](https://cloud.google.com/python/docs/reference) reference documentation.\n",
    "- Also helpful: [Getting started with Python](https://cloud.google.com/python/docs/getting-started) in Google Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6084a455-7eb6-4173-ac0d-b908a5f34123",
   "metadata": {},
   "source": [
    "---\n",
    "## Package Installs (if needed)\n",
    "\n",
    "This notebook uses the Python Clients for\n",
    "- Google Service Usage\n",
    "    - to enable APIs (Artifact Registry and Cloud Build)\n",
    "- Artifact Registry\n",
    "    - to create repositories for Python packages and Docker containers\n",
    "- Cloud Build\n",
    "    - To build custom Docker containers\n",
    "\n",
    "The cells below check to see if the required Python libraries are installed.  If any are not it will print a message to do the install with the associated pip command to use.  These installs must be completed before continuing this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e517d857-e3fb-431a-a426-bcad424353d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.cloud.service_usage_v1\n",
    "except ImportError:\n",
    "    print('You need to pip install google-cloud-service-usage')\n",
    "    !pip install google-cloud-service-usage -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "18845f24-9ddf-4b64-9eb6-40c77783136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.cloud.artifactregistry_v1\n",
    "except ImportError:\n",
    "    print('You need to pip install google-cloud-artifact-registry')\n",
    "    !pip install google-cloud-artifact-registry -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2c0b4b36-b779-4d57-a4a3-bb87a862892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.cloud.devtools.cloudbuild\n",
    "except ImportError:\n",
    "    print('You need to pip install google-cloud-build')\n",
    "    !pip install google-cloud-build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1414d7-e68f-44b9-a331-4fb9a04e2538",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed111b6-43f9-49e7-9770-63d2359779b2",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09680104-3052-4adb-b247-8ecaa4672a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2a88a5e-0238-47ac-9e70-c761892c602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = 'build'\n",
    "SERIES = 'tips'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7510728-c1d5-4015-b692-9867e894daa1",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7629a781-519d-48b7-a135-812b31dea62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "from google.cloud import service_usage_v1\n",
    "from google.cloud.devtools import cloudbuild_v1\n",
    "from google.cloud import artifactregistry_v1\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94eba86-0904-47f4-b818-ac140346303f",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "31447726-a55a-4ef5-bd2d-2465215d22a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "su_client = service_usage_v1.ServiceUsageClient()\n",
    "ar_client = artifactregistry_v1.ArtifactRegistryClient()\n",
    "cb_client = cloudbuild_v1.CloudBuildClient()\n",
    "aiplatform.init(project = PROJECT_ID, location = REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a5cfbe-2353-4418-901d-fa291c408233",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f01a4cfe-8ade-4272-92a2-d78bc532cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = f'temp/{EXPERIMENT}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe1aaa9-983b-4ae8-a604-1f0993c7a159",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3d3912e8-7365-4bda-8105-88f8fa298524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['job-parms', 'tips_build', '.ipynb_checkpoints', 'multi', 'gcs']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove directory named DIR if exists\n",
    "shutil.rmtree(DIR, ignore_errors = True)\n",
    "\n",
    "# create directory DIR\n",
    "os.makedirs(DIR)\n",
    "\n",
    "# check for existance of DIR\n",
    "print('DIR exists? ', os.path.exists(DIR))\n",
    "\n",
    "# list contents of directory one level higher than DIR\n",
    "os.listdir(DIR + '/../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b67477-62b0-44ee-bfd5-c562d2622dbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Enable APIs\n",
    "\n",
    "Using Cloud Build and Artifact Registry requires enabling these APIs for the Google Cloud Project.\n",
    "\n",
    "Options for enabeling these.  In this notebook (2) is used.\n",
    " 1. Use the APIs & Services page in the console: https://console.cloud.google.com/apis\n",
    "     - `+ Enable APIs and Services`\n",
    "     - Search for Cloud Build and Enable\n",
    "     - Search for Artifact Registry and Enable\n",
    " 2. Use [Google Service Usage](https://cloud.google.com/service-usage/docs) API from Python\n",
    "     - [Python Client For Service Usage](https://github.com/googleapis/python-service-usage)\n",
    "     - [Python Client Library Documentation](https://cloud.google.com/python/docs/reference/serviceusage/latest)\n",
    "     \n",
    "The following code cells use the Service Usage Client to:\n",
    "- get the state of the service\n",
    "- if 'DISABLED':\n",
    "    - Try enabling the service and return the state after trying\n",
    "- if 'ENABLED' print the state for confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c486d8c-e051-4412-9da3-9cbcd3d8c786",
   "metadata": {},
   "source": [
    "### Artifact Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "139c385c-4b8b-46d7-8adc-9cad30562385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifact Registry already enabled for project: statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "artifactregistry = su_client.get_service(\n",
    "    request = service_usage_v1.GetServiceRequest(\n",
    "        name = f'projects/{PROJECT_ID}/services/artifactregistry.googleapis.com'\n",
    "    )\n",
    ").state.name\n",
    "\n",
    "\n",
    "if artifactregistry == 'DISABLED':\n",
    "    print(f'Artifact Registry is currently {artifactregistry} for project: {PROJECT_ID}')\n",
    "    print(f'Trying to Enable...')\n",
    "    operation = su_client.enable_service(\n",
    "        request = service_usage_v1.EnableServiceRequest(\n",
    "            name = f'projects/{PROJECT_ID}/services/artifactregistry.googleapis.com'\n",
    "        )\n",
    "    )\n",
    "    response = operation.result()\n",
    "    if response.service.state.name == 'ENABLED':\n",
    "        print(f'Artifact Registry is now enabled for project: {PROJECT_ID}')\n",
    "    else:\n",
    "        print(response)\n",
    "else:\n",
    "    print(f'Artifact Registry already enabled for project: {PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e416ccf7-8817-486f-a42d-09769e087fa0",
   "metadata": {},
   "source": [
    "### Cloud Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1c4464c-0ede-4961-9759-21a2b3e11f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloud Build already enabled for project: statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "cloudbuild = su_client.get_service(\n",
    "    request = service_usage_v1.GetServiceRequest(\n",
    "        name = f'projects/{PROJECT_ID}/services/cloudbuild.googleapis.com'\n",
    "    )\n",
    ").state.name\n",
    "\n",
    "\n",
    "if cloudbuild == 'DISABLED':\n",
    "    print(f'Cloud Build is currently {cloudbuild} for project: {PROJECT_ID}')\n",
    "    print(f'Trying to Enable...')\n",
    "    operation = su_client.enable_service(\n",
    "        request = service_usage_v1.EnableServiceRequest(\n",
    "            name = f'projects/{PROJECT_ID}/services/cloudbuild.googleapis.com'\n",
    "        )\n",
    "    )\n",
    "    response = operation.result()\n",
    "    if response.service.state.name == 'ENABLED':\n",
    "        print(f'Cloud Build is now enabled for project: {PROJECT_ID}')\n",
    "    else:\n",
    "        print(response)\n",
    "else:\n",
    "    print(f'Cloud Build already enabled for project: {PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d021aab2-f348-432a-be9a-648428132ed7",
   "metadata": {},
   "source": [
    "## Setup Artifact Registry\n",
    "\n",
    "Artifact registry organizes artifacts with repositories.  Each repository contains packages and is designated to hold a partifcular format of package: Docker images, Python Packages and [others](https://cloud.google.com/artifact-registry/docs/supported-formats#package)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e64b5-e813-4f51-add1-63292d5f227e",
   "metadata": {},
   "source": [
    "### List Repositories\n",
    "\n",
    "This may be empty if no repositories have been created for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37d928c9-4968-4e8a-84f5-2c0e1cd67cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "for repo in ar_client.list_repositories(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n",
    "    print(repo.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e69c2a28-2c2d-4499-aa88-387f4ac5c7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915\"\n",
       "format_: DOCKER\n",
       "description: \"Vertex AI Training Custom Containers\"\n",
       "create_time {\n",
       "  seconds: 1655254405\n",
       "  nanos: 113143000\n",
       "}\n",
       "update_time {\n",
       "  seconds: 1663071981\n",
       "  nanos: 599247000\n",
       "}\n",
       "maven_config {\n",
       "}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e12ea93-29e5-4b97-a8ae-6758006db523",
   "metadata": {},
   "source": [
    "### Create Docker Image Repository\n",
    "\n",
    "Create an Artifact Registry Repository to hold Docker Images crated by this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "00dbbac5-ab76-4bfc-83ec-71a4d7e0ca80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved existing repo: projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915-tips-build-docker\n"
     ]
    }
   ],
   "source": [
    "docker_repo = None\n",
    "for repo in ar_client.list_repositories(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n",
    "    if f'{PROJECT_ID}-{SERIES}-{EXPERIMENT}-docker' in repo.name:\n",
    "        docker_repo = repo\n",
    "        print(f'Retrieved existing repo: {docker_repo.name}')\n",
    "\n",
    "if not docker_repo:\n",
    "    operation = ar_client.create_repository(\n",
    "        request = artifactregistry_v1.CreateRepositoryRequest(\n",
    "            parent = f'projects/{PROJECT_ID}/locations/{REGION}',\n",
    "            repository_id = f'{PROJECT_ID}-{SERIES}-{EXPERIMENT}-docker',\n",
    "            repository = artifactregistry_v1.Repository(\n",
    "                description = f'A repository for the {EXPERIMENT} experiment that holds docker images.',\n",
    "                name = f'{PROJECT_ID}-{SERIES}-{EXPERIMENT}-docker',\n",
    "                format_ = artifactregistry_v1.Repository.Format.DOCKER,\n",
    "                labels = {'series': SERIES, 'experiment': EXPERIMENT}\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print('Creating Repository ...')\n",
    "    response = operation.result()\n",
    "    print(f'Completed creating repo: {response.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9d29aa6f-ff91-473a-97f3-b7c04ce0c9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915-tips-build-docker',\n",
       " 'DOCKER')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docker_repo.name, docker_repo.format_.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f3e6f-d5b5-4bdf-bd3d-85f93c0fecac",
   "metadata": {},
   "source": [
    "### Create Python Package Repository\n",
    "\n",
    "Create an Artifact Registry Repository to hold Python Packages created by this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2739bb70-6bb3-4c86-bd4e-6930b9217560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Repository ...\n",
      "Completed Creating repo: projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915-tips-build-python\n"
     ]
    }
   ],
   "source": [
    "python_repo = None\n",
    "for repo in ar_client.list_repositories(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n",
    "    if f'{PROJECT_ID}-{SERIES}-{EXPERIMENT}-python' in repo.name:\n",
    "        python_repo = repo\n",
    "        print(f'Retrieved existing repo: {python_repo.name}')\n",
    "\n",
    "if not python_repo:\n",
    "    operation = ar_client.create_repository(\n",
    "        request = artifactregistry_v1.CreateRepositoryRequest(\n",
    "            parent = f'projects/{PROJECT_ID}/locations/{REGION}',\n",
    "            repository_id = f'{PROJECT_ID}-{SERIES}-{EXPERIMENT}-python',\n",
    "            repository = artifactregistry_v1.Repository(\n",
    "                description = f'A repository for the {EXPERIMENT} experiment that holds Python Packages.',\n",
    "                name = f'{PROJECT_ID}-{SERIES}-{EXPERIMENT}-python',\n",
    "                format_ = artifactregistry_v1.Repository.Format.PYTHON,\n",
    "                labels = {'series': SERIES, 'experiment': EXPERIMENT}\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print('Creating Repository ...')\n",
    "    python_repo = operation.result()\n",
    "    print(f'Completed creating repo: {python_repo.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "36ab9f9d-7a2a-4f48-b3d2-c279f93247a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915-tips-build-python',\n",
       " 'PYTHON')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_repo.name, python_repo.format_.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35f1519-0d36-48d0-822a-78084b5d1b5d",
   "metadata": {},
   "source": [
    "### List Repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "814c8ba4-556f-41be-ad24-4aebf360f983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915-tips-build-docker\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915-tips-build-python\n"
     ]
    }
   ],
   "source": [
    "for repo in ar_client.list_repositories(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n",
    "    print(repo.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5382175c-d5a3-46d2-90d8-0c4b2e282676",
   "metadata": {},
   "source": [
    "## Training Code\n",
    "\n",
    "brief description here\n",
    "\n",
    "link to other tip that created file here\n",
    "\n",
    "need to specify requirement for other tip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535e3190-75f5-4276-8737-003f418f24fb",
   "metadata": {},
   "source": [
    "list directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "38ad28d9-7e9a-4b0e-9292-16bd9502e219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp/tips_build/trainer\n",
      "temp/tips_build/trainer/.ipynb_checkpoints\n",
      "temp/tips_build/trainer/src\n",
      "temp/tips_build/trainer/dist\n",
      "temp/tips_build/trainer/dist/pyproject.toml\n",
      "temp/tips_build/trainer/src/trainer.egg-info\n",
      "temp/tips_build/trainer/src/trainer\n",
      "temp/tips_build/trainer/src/trainer.egg-info/trainer/top_level.txt\n",
      "temp/tips_build/trainer/src/trainer.egg-info/trainer/SOURCES.txt\n",
      "temp/tips_build/trainer/src/trainer.egg-info/trainer/requires.txt\n",
      "temp/tips_build/trainer/src/trainer.egg-info/trainer/dependency_links.txt\n",
      "temp/tips_build/trainer/src/trainer.egg-info/trainer/PKG-INFO\n",
      "temp/tips_build/trainer/src/trainer/trainer/__init__.py\n",
      "temp/tips_build/trainer/src/trainer/trainer/train.py\n",
      "temp/tips_build/trainer/dist/trainer/trainer-0.1-py3-none-any.whl\n",
      "temp/tips_build/trainer/dist/trainer/trainer-0.1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(DIR):\n",
    "    for d in dirs:\n",
    "        print(os.path.join(root, d))\n",
    "    for f in files:\n",
    "        print(os.path.join(root, d, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e641a996-8bff-4943-ad84-c09aafc76b79",
   "metadata": {},
   "source": [
    "This directory now has three key items:\n",
    "- a single training file: {DIR}/training/src/trainer/train.py\n",
    "- a folder of training code: {DIR}/training/src/trainer*\n",
    "    - with a starting point of train.py\n",
    "- a source distribution: {DIR}/training/dist/trainer-0.1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ece7da3-df94-4c24-b5d9-99f5c5b62d29",
   "metadata": {},
   "source": [
    "## Python Packages in Artifact Registry\n",
    "\n",
    "The goal is to show multiple way of getting training Code into custom containers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca1bcfd-0ff0-46ef-a24f-fc0528340115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa480f1-f031-4dab-ab25-51f8b4c50ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bea205-be92-4e32-8943-1c2c14c7810f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa3013-348c-42c9-8a1e-a9d0bffb7202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6fa23b-cd0e-443c-9c6f-c3551a6c4b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a865b7-c33d-4867-a8c7-d958ae7a420b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a4f3b-769f-49f7-b732-174580185130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f615030b-c7ea-42a5-96e4-8ae889617b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fef6db-4b1e-4ec5-a687-c32ff366befb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e5e2b-6dfd-4732-a6b2-edddb097388e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27597f2-6d01-4de9-ad03-8c7ce83c1707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdcd513-db7d-401d-900e-4c6bd1626304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad673a-b7ad-4994-a493-65af9670b37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa8ee339-435d-47f1-a788-648dae703cdf",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove\n",
    "\n",
    "Artifact Registry Repositories\n",
    "Cloud Build Assets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21a88e0-95f8-4a14-8281-019a93074d65",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "enable cloud build\n",
    "    list?\n",
    "enable cloud artifact registry\n",
    "    list, create registry\n",
    "\n",
    "build container with pip installs\n",
    "run with script on aiplatform\n",
    "\n",
    "build container with pip and copy of script\n",
    "run on aiplatform\n",
    "\n",
    "build source distro from code\n",
    "build containerr with source distro\n",
    "run on aiplatform\n",
    "\n",
    "build container from GitHub repo + folder + commitID\n",
    "run on aiplatform\n",
    "\n",
    "\n",
    "paths\n",
    "- local > container\n",
    "- local > package > AR > container\n",
    "- GitHub > container\n",
    "- GitHub > local > container\n",
    "\n",
    "thoughts:\n",
    "- container with file\n",
    "- container with distro, install\n",
    "- basically copy in versus pip install in dockerfile\n",
    "\n",
    "\n",
    "separate python package to new tip\n",
    "- results: file, folder, distro\n",
    "- store in local, gcs\n",
    "- run aiplatform custom jobs:\n",
    "    - file from local\n",
    "    - source from gcs\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d4b4c9-9116-4c1c-9fab-b51ed26a9490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
