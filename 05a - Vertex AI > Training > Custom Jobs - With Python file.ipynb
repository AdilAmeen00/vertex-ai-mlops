{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14c3fa3d",
   "metadata": {},
   "source": [
    "# 05a - Vertex AI > Training > Custom Jobs - With Python file\n",
    "\n",
    "### 05 Series Overview\n",
    "Where a model gets trained is where it consumes computing resources.  With Vertex AI, you have choices for configuring the computing resources available at training.  This notebook is an example of an execution environment.  When it was set up there were choices for machine type and accelerators (GPUs).  \n",
    "\n",
    "In the `05` notebook, the model training happened directly in the notebook.  The models were then imported to Vertex AI and deployed to an endpoint for online predictions. \n",
    "\n",
    "In this `05a-05i` series of demonstrations, the same model is trained using managed computing resources in Vertex AI as custom training jobs.  These jobs will be demonstrated as:\n",
    "\n",
    "-  Custom Job from a python script (`05a`), python source distribution (`05b`), and custom container (`05c`)\n",
    "-  Training Pipeline that trains and saves models from a python script (`05d`), python source distribution (`05e`), and custom container (`05f`)\n",
    "-  Hyperparameter Tuning Jobs from a python script (`05g`), python source distribution (`05h`), and custom container (`05i`)\n",
    "\n",
    "### This Notebook (`05a`): An extension of `05` that saves the notebook code for the model as a Python script\n",
    "This notebook trains the same Tensorflow Keras model from `05` by first modifying and saving the training code to a python script.  The script is then used as an input for a Vertex AI > Training > Custom Job that is also assigned compute resources and a [pre-built container for custom training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers) for executing the training in a managed service. This is done with the [Vertex AI Python SDK](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#) using the class [`aiplatform.CustomJob.from_local_script()`](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.CustomJob.from_local_script).\n",
    "\n",
    "The training can be reviewed with Vertex AI's managed Tensorboard under Vertex AI > Experiments > Experiments, or by clicking on the `05a...` custom job under Vertex AI > Training > Custom Jobs and then clicking the 'Open Tensorboard' link.\n",
    "\n",
    "<img src=\"architectures/overview/Training.png\">\n",
    "\n",
    "### Prerequisites:\n",
    "-  01 - BigQuery - Table Data Source\n",
    "-  Understanding:\n",
    "    -  05 - Vertex AI > Notebooks - Models Built in Notebooks with Tensorflow\n",
    "        -  Contains a more granular review of the Tensorflow model training\n",
    "\n",
    "### Resources:\n",
    "-  [BigQuery Tensorflow Reader](https://www.tensorflow.org/io/tutorials/bigquery)\n",
    "-  [Keras Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)\n",
    "   -  [Keras API](https://www.tensorflow.org/api_docs/python/tf/keras)\n",
    "-  [Python Client For Google BigQuery](https://googleapis.dev/python/bigquery/latest/index.html)\n",
    "-  [Tensorflow Python Client](https://www.tensorflow.org/api_docs/python/tf)\n",
    "-  [Tensorflow I/O Python Client](https://www.tensorflow.org/io/api_docs/python/tfio/bigquery)\n",
    "-  [Python Client for Vertex AI](https://googleapis.dev/python/aiplatform/latest/aiplatform.html)\n",
    "-  Containers for training (Pre-Built)\n",
    "   -  [Overview](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container)\n",
    "    - Pre-built Containers for Vertex AI\n",
    "        - [Training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers)\n",
    "        - [Prediction & Explaination](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c78485",
   "metadata": {},
   "source": [
    "---\n",
    "## Vertex AI - Conceptual Flow\n",
    "\n",
    "<img src=\"architectures/slides/05a_arch.png\">\n",
    "\n",
    "---\n",
    "## Vertex AI - Workflow\n",
    "\n",
    "<img src=\"architectures/slides/05a_console.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe7eba1",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae2fa7",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b7c610a-c325-4975-a4ec-425dc6eae1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54eea9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "DATANAME = 'fraud'\n",
    "NOTEBOOK = '05a'\n",
    "SERIES = '05'\n",
    "\n",
    "# Resources\n",
    "TRAIN_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-7:latest'\n",
    "DEPLOY_IMAGE ='us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest'\n",
    "TRAIN_COMPUTE = 'n1-standard-4'\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id' # add more variables to the string with space delimiters\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7253fe4",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d13322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d19b58",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23a2b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project = PROJECT_ID, location = REGION)\n",
    "bigquery = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac43d0",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc1c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = PROJECT_ID\n",
    "URI = f\"gs://{BUCKET}/{DATANAME}/models/{NOTEBOOK}\"\n",
    "DIR = f\"temp/{NOTEBOOK}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31a082ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1026793852137-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Give service account roles/storage.objectAdmin permissions\n",
    "# Console > IMA > Select Account <projectnumber>-compute@developer.gserviceaccount.com > edit - give role\n",
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f3430",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb70c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bde8db-df0c-4b94-a8f7-5717166fa2c3",
   "metadata": {},
   "source": [
    "Experiment Tracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a193ab9-2d7e-4c58-9eaa-b93c6e242fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = 'classification'\n",
    "MODEL_TYPE = 'dnn'\n",
    "EXPERIMENT_NAME = f'{SERIES}-{NOTEBOOK}-{TASK}-{MODEL_TYPE}'\n",
    "RUN_NAME = f'run-{TIMESTAMP}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f450631f",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Get Vertex AI Experiments Tensorboard Instance Name\n",
    "[Vertex AI Experiments](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview) has managed [Tensorboard](https://www.tensorflow.org/tensorboard) instances that you can track Tensorboard Experiments (a training run or hyperparameter tuning sweep).  \n",
    "\n",
    "The training job will show up as an experiment for the Tensorboard instance and have the same name as the training job ID.\n",
    "\n",
    "This code checks to see if a Tensorboard Instance has been created in the project, retrieves it if so, creates it otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c0cfc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = aiplatform.Tensorboard.list(filter=f'display_name={DATANAME}')\n",
    "if tb:\n",
    "    tb = tb[0]\n",
    "else:\n",
    "    tb = aiplatform.Tensorboard.create(display_name = DATANAME, labels = {'notebook':f'{DATANAME}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7bdbeab-553f-4715-980e-da14bd9c264a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/1026793852137/locations/us-central1/tensorboards/1212224763762573312'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4336405b-e02b-40e9-a988-12f4ebf6ef60",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup Vertex AI Experiments\n",
    "\n",
    "The code in this section initializes the experiment and starts a run that represents this notebook.  Throughout the notebook sections for model training and evaluation information will be logged to the experiment using:\n",
    "- [.log_params](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_params)\n",
    "- [.log_metrics](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_metrics)\n",
    "- [.log_time_series_metrics](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_time_series_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b50688f8-8c11-462a-9a37-6f503a7cd85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(experiment = EXPERIMENT_NAME, experiment_tensorboard = tb.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9385d1e5-e71e-41ce-ae04-992ad6248976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/1026793852137/locations/us-central1/metadataStores/default/contexts/05-05a-classification-dnn-run-20220818224910 to Experiment: 05-05a-classification-dnn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.metadata.experiment_run_resource.ExperimentRun at 0x7feb1ae028d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.start_run(run = RUN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5c1be5c-7639-4347-ac3c-75b7be9b52fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.log_params({'DATANAME': DATANAME, 'NOTEBOOK': NOTEBOOK, 'SERIES': SERIES, 'PROJECT_ID': PROJECT_ID, 'VAR_TARGET': VAR_TARGET})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a1832f6-b65e-444d-8a7e-5a8f8d790cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8612af3c-3dc4-41f9-af44-c6d7a299e109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>run_type</th>\n",
       "      <th>state</th>\n",
       "      <th>param.NOTEBOOK</th>\n",
       "      <th>param.SERIES</th>\n",
       "      <th>param.DATANAME</th>\n",
       "      <th>param.VAR_TARGET</th>\n",
       "      <th>param.PROJECT_ID</th>\n",
       "      <th>param.MODEL_DISPLAY_NAME</th>\n",
       "      <th>...</th>\n",
       "      <th>metric.val_auprc</th>\n",
       "      <th>metric.test_accuracy</th>\n",
       "      <th>metric.val_loss</th>\n",
       "      <th>metric.test_auprc</th>\n",
       "      <th>time_series_metric.val_loss</th>\n",
       "      <th>time_series_metric.val_auprc</th>\n",
       "      <th>time_series_metric.train_auprc</th>\n",
       "      <th>time_series_metric.val_accuracy</th>\n",
       "      <th>time_series_metric.train_accuracy</th>\n",
       "      <th>time_series_metric.train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05-05a-classification-dnn</td>\n",
       "      <td>run-20220818212823</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>05a</td>\n",
       "      <td>05</td>\n",
       "      <td>fraud</td>\n",
       "      <td>Class</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-05a-classification-dnn</td>\n",
       "      <td>run-20220818191710</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>05a</td>\n",
       "      <td>05</td>\n",
       "      <td>fraud</td>\n",
       "      <td>Class</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>05a_fraud</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.999299</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.999628</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.999709</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>0.999359</td>\n",
       "      <td>0.003268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             experiment_name            run_name              run_type  \\\n",
       "0  05-05a-classification-dnn  run-20220818212823  system.ExperimentRun   \n",
       "1  05-05a-classification-dnn  run-20220818191710  system.ExperimentRun   \n",
       "\n",
       "      state param.NOTEBOOK param.SERIES param.DATANAME param.VAR_TARGET  \\\n",
       "0  COMPLETE            05a           05          fraud            Class   \n",
       "1  COMPLETE            05a           05          fraud            Class   \n",
       "\n",
       "        param.PROJECT_ID param.MODEL_DISPLAY_NAME  ... metric.val_auprc  \\\n",
       "0  statmike-mlops-349915                      NaN  ...              NaN   \n",
       "1  statmike-mlops-349915                05a_fraud  ...         0.999627   \n",
       "\n",
       "   metric.test_accuracy  metric.val_loss  metric.test_auprc  \\\n",
       "0                   NaN              NaN                NaN   \n",
       "1              0.999299         0.004269           0.999628   \n",
       "\n",
       "  time_series_metric.val_loss time_series_metric.val_auprc  \\\n",
       "0                         NaN                          NaN   \n",
       "1                    0.004269                     0.999627   \n",
       "\n",
       "  time_series_metric.train_auprc  time_series_metric.val_accuracy  \\\n",
       "0                            NaN                              NaN   \n",
       "1                       0.999709                         0.999368   \n",
       "\n",
       "   time_series_metric.train_accuracy time_series_metric.train_loss  \n",
       "0                                NaN                           NaN  \n",
       "1                           0.999359                      0.003268  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.get_experiment_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd86168",
   "metadata": {},
   "source": [
    "---\n",
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3570cd60",
   "metadata": {},
   "source": [
    "### Assemble Python File for Training\n",
    "\n",
    "Create the main python trainer file as `/train.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9cca0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting temp/05a/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/train.py\n",
    "\n",
    "# package import\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "import tensorflow as tf\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import aiplatform\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# import argument to local variables\n",
    "parser = argparse.ArgumentParser()\n",
    "# the passed param, dest: a name for the param, default: if absent fetch this param from the OS, type: type to convert to, help: description of argument\n",
    "parser.add_argument('--epochs', dest = 'epochs', default = 10, type = int, help = 'Number of Epochs')\n",
    "parser.add_argument('--batch_size', dest = 'batch_size', default = 32, type = int, help = 'Batch Size')\n",
    "parser.add_argument('--var_target', dest = 'var_target', type=str)\n",
    "parser.add_argument('--var_omit', dest = 'var_omit', type=str, nargs='*')\n",
    "parser.add_argument('--project_id', dest = 'project_id', type=str)\n",
    "parser.add_argument('--dataname', dest = 'dataname', type=str)\n",
    "parser.add_argument('--region', dest = 'region', type=str)\n",
    "parser.add_argument('--notebook', dest = 'notebook', type=str)\n",
    "parser.add_argument('--experiment_name', dest = 'experiment_name', type=str)\n",
    "parser.add_argument('--run_name', dest = 'run_name', type=str)\n",
    "args = parser.parse_args()\n",
    "\n",
    "# built in parameters for data source:\n",
    "PROJECT_ID = args.project_id\n",
    "DATANAME = args.dataname\n",
    "REGION = args.region\n",
    "NOTEBOOK = args.notebook\n",
    "\n",
    "# clients\n",
    "bigquery = bigquery.Client(project = PROJECT_ID)\n",
    "aiplatform.init(project = PROJECT_ID, location = REGION)\n",
    "\n",
    "# Vertex AI Experiment\n",
    "expRun = aiplatform.ExperimentRun(run_name = args.run_name, experiment = args.experiment_name)\n",
    "\n",
    "# get schema from bigquery source\n",
    "query = f\"SELECT * FROM {DATANAME}.INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{DATANAME}_prepped'\"\n",
    "schema = bigquery.query(query).to_dataframe()\n",
    "\n",
    "# get number of classes from bigquery source\n",
    "nclasses = bigquery.query(query = f'SELECT DISTINCT {args.var_target} FROM {DATANAME}.{DATANAME}_prepped WHERE {args.var_target} is not null').to_dataframe()\n",
    "nclasses = nclasses.shape[0]\n",
    "expRun.log_params({'data_source': f'bq://{DATANAME}.{DATANAME}_prepped', 'nclasses': nclasses, 'var_split': 'splits'})\n",
    "\n",
    "# Make a list of columns to omit\n",
    "OMIT = args.var_omit + ['splits']\n",
    "\n",
    "# use schema to prepare a list of columns to read from BigQuery\n",
    "selected_fields = schema[~schema.column_name.isin(OMIT)].column_name.tolist()\n",
    "\n",
    "# all the columns in this data source are either float64 or int64\n",
    "output_types = [dtypes.float64 if x=='FLOAT64' else dtypes.int64 for x in schema[~schema.column_name.isin(OMIT)].data_type.tolist()]\n",
    "\n",
    "# remap input data to Tensorflow inputs of features and target\n",
    "def transTable(row_dict):\n",
    "    target=row_dict.pop(args.var_target)\n",
    "    target = tf.one_hot(tf.cast(target,tf.int64), nclasses)\n",
    "    target = tf.cast(target, tf.float32)\n",
    "    return(row_dict,target)\n",
    "\n",
    "# function to setup a bigquery reader with Tensorflow I/O\n",
    "def bq_reader(split):\n",
    "    reader = BigQueryClient()\n",
    "\n",
    "    training = reader.read_session(\n",
    "        parent = f\"projects/{PROJECT_ID}\",\n",
    "        project_id = PROJECT_ID,\n",
    "        table_id = f\"{DATANAME}_prepped\",\n",
    "        dataset_id = DATANAME,\n",
    "        selected_fields = selected_fields,\n",
    "        output_types = output_types,\n",
    "        row_restriction = f\"splits='{split}'\",\n",
    "        requested_streams = 3\n",
    "    )\n",
    "    \n",
    "    return training\n",
    "\n",
    "train = bq_reader('TRAIN').parallel_read_rows().prefetch(1).map(transTable).shuffle(args.batch_size*10).batch(args.batch_size)\n",
    "validate = bq_reader('VALIDATE').parallel_read_rows().prefetch(1).map(transTable).batch(args.batch_size)\n",
    "test = bq_reader('TEST').parallel_read_rows().prefetch(1).map(transTable).batch(args.batch_size)\n",
    "expRun.log_params({'BATCH_SIZE': args.batch_size, 'SHUFFLE': 10*args.batch_size, 'PREFETCH': 1})\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "# model input definitions\n",
    "feature_columns = {header: tf.feature_column.numeric_column(header) for header in selected_fields if header != args.var_target}\n",
    "feature_layer_inputs = {header: tf.keras.layers.Input(shape = (1,), name = header) for header in selected_fields if header != args.var_target}\n",
    "\n",
    "# feature columns to a Dense Feature Layer\n",
    "feature_layer_outputs = tf.keras.layers.DenseFeatures(feature_columns.values(), name = 'feature_layer')(feature_layer_inputs)\n",
    "\n",
    "# batch normalization then Dense with softmax activation to nclasses\n",
    "layers = tf.keras.layers.BatchNormalization(name = 'batch_normalization_layer')(feature_layer_outputs)\n",
    "layers = tf.keras.layers.Dense(64, activation = 'relu', name = 'hidden_layer')(layers)\n",
    "layers = tf.keras.layers.Dense(32, activation = 'relu', name = 'embedding_layer')(layers)\n",
    "layers = tf.keras.layers.Dense(nclasses, activation = tf.nn.softmax, name = 'prediction_layer')(layers)\n",
    "\n",
    "# the model\n",
    "model = tf.keras.Model(\n",
    "    inputs = feature_layer_inputs,\n",
    "    outputs = layers,\n",
    "    name = f'{DATANAME}'\n",
    ")\n",
    "opt = tf.keras.optimizers.SGD() #SGD or Adam\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "model.compile(\n",
    "    optimizer = opt,\n",
    "    loss = loss,\n",
    "    metrics = ['accuracy', tf.keras.metrics.AUC(curve='PR', name = 'auprc')]\n",
    ")\n",
    "\n",
    "# setup tensorboard logs and train\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=os.environ['AIP_TENSORBOARD_LOG_DIR'], histogram_freq=1)\n",
    "history = model.fit(train, epochs = args.epochs, callbacks = [tensorboard_callback], validation_data = validate)\n",
    "expRun.log_params({'epochs': history.params['epochs']})\n",
    "for e in range(0, history.params['epochs']):\n",
    "    expRun.log_time_series_metrics(\n",
    "        {\n",
    "            'train_loss': history.history['loss'][e],\n",
    "            'train_accuracy': history.history['accuracy'][e],\n",
    "            'train_auprc': history.history['auprc'][e],\n",
    "            'val_loss': history.history['val_loss'][e],\n",
    "            'val_accuracy': history.history['val_accuracy'][e],\n",
    "            'val_auprc': history.history['val_auprc'][e]\n",
    "        }\n",
    "    )\n",
    "\n",
    "# evaluations:\n",
    "loss, accuracy, auprc = model.evaluate(test)\n",
    "expRun.log_metrics({'test_loss': loss, 'test_accuracy': accuracy, 'test_auprc': auprc})\n",
    "loss, accuracy, auprc = model.evaluate(validate)\n",
    "expRun.log_metrics({'val_loss': loss, 'val_accuracy': accuracy, 'val_auprc': auprc})\n",
    "loss, accuracy, auprc = model.evaluate(train)\n",
    "expRun.log_metrics({'train_loss': loss, 'train_accuracy': accuracy, 'train_auprc': auprc})\n",
    "\n",
    "# output the model save files\n",
    "model.save(os.getenv(\"AIP_MODEL_DIR\"))\n",
    "expRun.log_params({'MODEL_URI': os.getenv(\"AIP_MODEL_DIR\")})\n",
    "expRun.update_state(state = aiplatform.gapic.Execution.State.COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440e1238",
   "metadata": {},
   "source": [
    "### Setup Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c305011",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMDARGS = [\n",
    "    \"--epochs=\" + str(EPOCHS),\n",
    "    \"--batch_size=\" + str(BATCH_SIZE),\n",
    "    \"--var_target=\" + VAR_TARGET,\n",
    "    \"--var_omit=\" + VAR_OMIT,\n",
    "    \"--project_id=\" + PROJECT_ID,\n",
    "    \"--dataname=\" + DATANAME,\n",
    "    \"--region=\" + REGION,\n",
    "    \"--notebook=\" + NOTEBOOK,\n",
    "    \"--experiment_name=\" + EXPERIMENT_NAME,\n",
    "    \"--run_name=\" + RUN_NAME\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a5c364a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training script copied to:\n",
      "gs://statmike-mlops-349915/fraud/models/05a/20220818224910/aiplatform-2022-08-18-22:50:13.891-aiplatform_custom_trainer_script-0.1.tar.gz.\n"
     ]
    }
   ],
   "source": [
    "customJob = aiplatform.CustomJob.from_local_script(\n",
    "    display_name = f'{NOTEBOOK}_{DATANAME}_{TIMESTAMP}',\n",
    "    script_path = f\"{DIR}/train.py\",\n",
    "    container_uri = TRAIN_IMAGE,\n",
    "    args = CMDARGS,\n",
    "    requirements = ['tensorflow_io', f'google-cloud-aiplatform>={aiplatform.__version__}'],\n",
    "    replica_count = 1,\n",
    "    machine_type = TRAIN_COMPUTE,\n",
    "    accelerator_count = 0,\n",
    "    base_output_dir = f\"{URI}/{TIMESTAMP}\",\n",
    "    staging_bucket = f\"{URI}/{TIMESTAMP}\",\n",
    "    labels = {'notebook':f'{NOTEBOOK}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e0e344",
   "metadata": {},
   "source": [
    "### Run Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f75aeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CustomJob\n",
      "CustomJob created. Resource name: projects/1026793852137/locations/us-central1/customJobs/4240479073140211712\n",
      "To use this CustomJob in another session:\n",
      "custom_job = aiplatform.CustomJob.get('projects/1026793852137/locations/us-central1/customJobs/4240479073140211712')\n",
      "View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/4240479073140211712?project=1026793852137\n",
      "View Tensorboard:\n",
      "https://us-central1.tensorboard.googleusercontent.com/experiment/projects+1026793852137+locations+us-central1+tensorboards+1212224763762573312+experiments+4240479073140211712\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/1026793852137/locations/us-central1/customJobs/4240479073140211712 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "CustomJob run completed. Resource name: projects/1026793852137/locations/us-central1/customJobs/4240479073140211712\n"
     ]
    }
   ],
   "source": [
    "customJob.run(\n",
    "    service_account = SERVICE_ACCOUNT,\n",
    "    tensorboard = tb.resource_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df3733c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05a_fraud_20220818212823'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customJob.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59b8bc85-064e-4af4-be7a-86f73c91cabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/1026793852137/locations/us-central1/customJobs/3847821480628846592'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customJob.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7359cf-9c8d-4d25-8091-0c69d6824fa4",
   "metadata": {},
   "source": [
    "log parameters, create hyperlines to job and tensorboard here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2373fd9-f25b-4377-9022-f72127b14c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun = aiplatform.ExperimentRun(run_name = RUN_NAME, experiment = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16fa4d2e-fb8f-4d9f-b4f5-1af3a1644347",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = aiplatform.Experiment(experiment_name = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b07cdab-db96-4969-a443-0dece4746b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun.log_params({\n",
    "    'JobType': 'aiplatform.CustomJob.from_local_script()',\n",
    "    'CustomJob.display_name': customJob.display_name,\n",
    "    'CustomJob.resource_name': customJob.resource_name\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b926f13e-593a-49c8-ac32-d877fef73015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the Job here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/training/4240479073140211712/cpu?cloudshell=false&project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f\"Review the Job here:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/training/{customJob.resource_name.split('/')[-1]}/cpu?cloudshell=false&project={PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34db0abb-af3d-48c8-97d8-f17ac8dd6457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the TensorBoard From the Job here:\n",
      "https://us-central1.tensorboard.googleusercontent.com/experiment/projects+1026793852137+locations+us-central1+tensorboards+1212224763762573312+experiments+4240479073140211712\n"
     ]
    }
   ],
   "source": [
    "print(f\"Review the TensorBoard From the Job here:\\nhttps://{REGION}.tensorboard.googleusercontent.com/experiment/{tb.resource_name.replace('/', '+')}+experiments+{customJob.resource_name.split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a809833",
   "metadata": {},
   "source": [
    "---\n",
    "## Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fd1f7c",
   "metadata": {},
   "source": [
    "### Upload The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40653522-1017-45a0-94d7-2995c7e8374a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Already in Registry:\n",
      "Loading model as new default version.\n",
      "Creating Model\n",
      "Create Model backing LRO: projects/1026793852137/locations/us-central1/models/model_05a_fraud/operations/7689500883146506240\n",
      "Model created. Resource name: projects/1026793852137/locations/us-central1/models/2624978458198933504@8\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/1026793852137/locations/us-central1/models/2624978458198933504@8')\n"
     ]
    }
   ],
   "source": [
    "modelmatch = aiplatform.Model.list(filter = f'display_name=\"{NOTEBOOK}_{DATANAME}\"')\n",
    "if modelmatch:\n",
    "    print(\"Model Already in Registry:\")\n",
    "    if f'time-{TIMESTAMP}' in modelmatch[0].version_aliases:\n",
    "        print(\"This version already loaded, no action taken.\")\n",
    "        model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n",
    "    else:\n",
    "        print('Loading model as new default version.')\n",
    "        model = aiplatform.Model.upload(\n",
    "            display_name = f'{NOTEBOOK}_{DATANAME}',\n",
    "            model_id = f'model_{NOTEBOOK}_{DATANAME}',\n",
    "            parent_model =  modelmatch[0].resource_name,\n",
    "            serving_container_image_uri = DEPLOY_IMAGE,\n",
    "            artifact_uri = f\"{URI}/{TIMESTAMP}/model\",\n",
    "            is_default_version = True,\n",
    "            version_aliases = [f'run-{TIMESTAMP}'],\n",
    "            version_description = f'run-{TIMESTAMP}',\n",
    "            labels = {'notebook':f'{NOTEBOOK}'}        \n",
    "        )\n",
    "else:\n",
    "    print('This is a new model, creating in model registry')\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name = f'{NOTEBOOK}_{DATANAME}',\n",
    "        model_id = f'model_{NOTEBOOK}_{DATANAME}',\n",
    "        serving_container_image_uri = DEPLOY_IMAGE,\n",
    "        artifact_uri = f\"{URI}/{TIMESTAMP}/model\",\n",
    "        is_default_version = True,\n",
    "        version_aliases = [f'run-{TIMESTAMP}'],\n",
    "        version_description = f'run-{TIMESTAMP}',\n",
    "        labels = {'notebook':f'{NOTEBOOK}'}\n",
    "    )    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aec367e-16a2-478a-8d56-5b849e258c3e",
   "metadata": {},
   "source": [
    "**Note** on Version Aliases:\n",
    ">Expectation is a name starting with `a-z` that can include `[a-zA-Z0-9-]`\n",
    "\n",
    "**Retrieve a Model Resource**\n",
    "\n",
    "[Resource](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Model)\n",
    "```Python\n",
    "model = aiplatform.Model(model_name = f'model_{NOTEBOOK}_{DATANAME}') # retrieves default version\n",
    "model = aiplatform.Model(model_name = f'model_{NOTEBOOK}_{DATANAME}@time-{TIMESTAMP}') # retrieves specific version\n",
    "model = aiplatform.Model(model_name = f'model_{NOTEBOOK}_{DATANAME}', version = f'time-{TIMESTAMP}') # retrieves specific version\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9ffc84-db1e-419b-8cd5-9cfcf027523f",
   "metadata": {},
   "source": [
    "### Vertex AI Experiment Update and Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e798f2f5-5c78-44d8-978f-cbb15e9eca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun.log_params({'MODEL_DISPLAY_NAME': model.display_name, 'MODEL_VERSIONED_RESOURCE_NAME': model.versioned_resource_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a9a7877-f492-4685-b297-a8902fc3e887",
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun.update_state(state = aiplatform.gapic.Execution.State.COMPLETE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3506e605-af6a-4e5d-aee9-7577ea488b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>run_type</th>\n",
       "      <th>state</th>\n",
       "      <th>param.VAR_TARGET</th>\n",
       "      <th>param.epochs</th>\n",
       "      <th>param.JobType</th>\n",
       "      <th>param.CustomJob.display_name</th>\n",
       "      <th>param.DATANAME</th>\n",
       "      <th>param.SERIES</th>\n",
       "      <th>...</th>\n",
       "      <th>metric.test_auprc</th>\n",
       "      <th>metric.test_loss</th>\n",
       "      <th>metric.val_loss</th>\n",
       "      <th>metric.train_auprc</th>\n",
       "      <th>time_series_metric.val_loss</th>\n",
       "      <th>time_series_metric.train_loss</th>\n",
       "      <th>time_series_metric.train_auprc</th>\n",
       "      <th>time_series_metric.train_accuracy</th>\n",
       "      <th>time_series_metric.val_auprc</th>\n",
       "      <th>time_series_metric.val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05-05a-classification-dnn</td>\n",
       "      <td>run-20220818224910</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>Class</td>\n",
       "      <td>10.0</td>\n",
       "      <td>aiplatform.CustomJob.from_local_script()</td>\n",
       "      <td>05a_fraud_20220818224910</td>\n",
       "      <td>fraud</td>\n",
       "      <td>05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>0.004302</td>\n",
       "      <td>0.999662</td>\n",
       "      <td>0.004302</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>0.999744</td>\n",
       "      <td>0.999416</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>0.999438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-05a-classification-dnn</td>\n",
       "      <td>run-20220818212823</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>Class</td>\n",
       "      <td>10.0</td>\n",
       "      <td>aiplatform.CustomJob.from_local_script()</td>\n",
       "      <td>05a_fraud_20220818212823</td>\n",
       "      <td>fraud</td>\n",
       "      <td>05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.999709</td>\n",
       "      <td>0.999429</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.999368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05-05a-classification-dnn</td>\n",
       "      <td>run-20220818191710</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>Class</td>\n",
       "      <td>10.0</td>\n",
       "      <td>aiplatform.CustomJob.from_local_script()</td>\n",
       "      <td>05a_fraud_20220818191710</td>\n",
       "      <td>fraud</td>\n",
       "      <td>05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999628</td>\n",
       "      <td>0.004074</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.999639</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>0.999709</td>\n",
       "      <td>0.999359</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.999368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             experiment_name            run_name              run_type  \\\n",
       "0  05-05a-classification-dnn  run-20220818224910  system.ExperimentRun   \n",
       "1  05-05a-classification-dnn  run-20220818212823  system.ExperimentRun   \n",
       "2  05-05a-classification-dnn  run-20220818191710  system.ExperimentRun   \n",
       "\n",
       "      state param.VAR_TARGET  param.epochs  \\\n",
       "0  COMPLETE            Class          10.0   \n",
       "1  COMPLETE            Class          10.0   \n",
       "2  COMPLETE            Class          10.0   \n",
       "\n",
       "                              param.JobType param.CustomJob.display_name  \\\n",
       "0  aiplatform.CustomJob.from_local_script()     05a_fraud_20220818224910   \n",
       "1  aiplatform.CustomJob.from_local_script()     05a_fraud_20220818212823   \n",
       "2  aiplatform.CustomJob.from_local_script()     05a_fraud_20220818191710   \n",
       "\n",
       "  param.DATANAME param.SERIES  ...  metric.test_auprc  metric.test_loss  \\\n",
       "0          fraud           05  ...           0.999627          0.003938   \n",
       "1          fraud           05  ...           0.999580          0.004556   \n",
       "2          fraud           05  ...           0.999628          0.004074   \n",
       "\n",
       "  metric.val_loss metric.train_auprc time_series_metric.val_loss  \\\n",
       "0        0.004302           0.999662                    0.004302   \n",
       "1        0.004658           0.999579                    0.004658   \n",
       "2        0.004269           0.999639                    0.004269   \n",
       "\n",
       "  time_series_metric.train_loss time_series_metric.train_auprc  \\\n",
       "0                      0.003036                       0.999744   \n",
       "1                      0.003162                       0.999709   \n",
       "2                      0.003268                       0.999709   \n",
       "\n",
       "  time_series_metric.train_accuracy  time_series_metric.val_auprc  \\\n",
       "0                          0.999416                      0.999580   \n",
       "1                          0.999429                      0.999487   \n",
       "2                          0.999359                      0.999627   \n",
       "\n",
       "  time_series_metric.val_accuracy  \n",
       "0                        0.999438  \n",
       "1                        0.999368  \n",
       "2                        0.999368  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.get_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dea7c8",
   "metadata": {},
   "source": [
    "### Create An Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "b740cd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Exists: projects/1026793852137/locations/us-central1/endpoints/7252545822577917952\n"
     ]
    }
   ],
   "source": [
    "endpoints = aiplatform.Endpoint.list(filter = f\"display_name={SERIES}_{DATANAME}\")\n",
    "if endpoints:\n",
    "    endpoint = endpoints[0]\n",
    "    print(f\"Endpoint Exists: {endpoints[0].resource_name}\")\n",
    "else:\n",
    "    endpoint = aiplatform.Endpoint.create(\n",
    "        display_name = f\"{SERIES}_{DATANAME}\",\n",
    "        labels = {'notebook':f\"{SERIES}\"}    \n",
    "    )\n",
    "    print(f\"Endpoint Created: {endpoint.resource_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "183d85c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05_fraud'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8852a1",
   "metadata": {},
   "source": [
    "### Deploy Model To Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "3533d934-2c70-4340-8afa-f5b1930bb5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model with 100% of traffic...\n",
      "Deploying Model projects/1026793852137/locations/us-central1/models/2624978458198933504 to Endpoint : projects/1026793852137/locations/us-central1/endpoints/7252545822577917952\n",
      "Deploy Endpoint model backing LRO: projects/1026793852137/locations/us-central1/endpoints/7252545822577917952/operations/8996115696496672768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/proto/marshal/rules/enums.py:40: UserWarning: Unrecognized DeploymentResourcesType enum value: 3\n",
      "  value=value,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint model deployed. Resource name: projects/1026793852137/locations/us-central1/endpoints/7252545822577917952\n"
     ]
    }
   ],
   "source": [
    "dmodels = endpoint.list_models()\n",
    "\n",
    "check = 0\n",
    "if dmodels:\n",
    "    for dmodel in dmodels:\n",
    "        if dmodel.model == model.resource_name and dmodel.model_version_id == model.version_id and dmodel.id in endpoint.traffic_split:\n",
    "            print(f'This model (and version) already deployed with {endpoint.traffic_split[dmodel.id]}% of traffic')\n",
    "            check = 1\n",
    "    \n",
    "if check == 0:\n",
    "    print(f'Deploying model with 100% of traffic...')\n",
    "    endpoint.deploy(\n",
    "        model = model,\n",
    "        deployed_model_display_name = f'{NOTEBOOK}_{DATANAME}',\n",
    "        traffic_percentage = 100,\n",
    "        machine_type = DEPLOY_COMPUTE,\n",
    "        min_replica_count = 1,\n",
    "        max_replica_count = 1\n",
    "    )     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023dcd5e-33af-4dd8-9fe4-ef0ab3078460",
   "metadata": {},
   "source": [
    "### Remove Deployed Models without Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "6945f51a-0c06-4760-bbfe-f2b9d1e7d38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 05a_fraud has traffic = 100\n",
      "Undeploying Endpoint model: projects/1026793852137/locations/us-central1/endpoints/7252545822577917952\n",
      "Undeploy Endpoint model backing LRO: projects/1026793852137/locations/us-central1/endpoints/7252545822577917952/operations/7122618251510546432\n",
      "Endpoint model undeployed. Resource name: projects/1026793852137/locations/us-central1/endpoints/7252545822577917952\n",
      "Undeployed 05a_fraud version 4 as it has no traffic.\n"
     ]
    }
   ],
   "source": [
    "for dmodel in endpoint.list_models():\n",
    "    if dmodel.id in endpoint.traffic_split:\n",
    "        print(f\"Model {dmodel.display_name} has traffic = {endpoint.traffic_split[dmodel.id]}\")\n",
    "    else:\n",
    "        endpoint.undeploy(deployed_model_id = dmodel.id)\n",
    "        print(f\"Undeployed {dmodel.display_name} version {dmodel.model_version_id} as it has no traffic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "d90c6900-de81-4fcd-af0b-ba6b3925724d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1628935272643166208': 100}"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "14cbf4a3-9e32-4158-a9ee-0cfca92e8574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"1628935272643166208\"\n",
       " model: \"projects/1026793852137/locations/us-central1/models/model_05a_fraud\"\n",
       " display_name: \"05a_fraud\"\n",
       " create_time {\n",
       "   seconds: 1659050517\n",
       "   nanos: 981042000\n",
       " }\n",
       " dedicated_resources {\n",
       "   machine_spec {\n",
       "     machine_type: \"n1-standard-4\"\n",
       "   }\n",
       "   min_replica_count: 1\n",
       "   max_replica_count: 1\n",
       " }\n",
       " model_version_id: \"5\"]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dac1d9",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c3acf",
   "metadata": {},
   "source": [
    "### Prepare a record for prediction: instance and parameters lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "c2588145",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bigquery.query(query = f\"SELECT * FROM {DATANAME}.{DATANAME}_prepped WHERE splits='TEST' LIMIT 10\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "6a19c2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32799</td>\n",
       "      <td>1.153477</td>\n",
       "      <td>-0.047859</td>\n",
       "      <td>1.358363</td>\n",
       "      <td>1.480620</td>\n",
       "      <td>-1.222598</td>\n",
       "      <td>-0.481690</td>\n",
       "      <td>-0.654461</td>\n",
       "      <td>0.128115</td>\n",
       "      <td>0.907095</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025964</td>\n",
       "      <td>0.701843</td>\n",
       "      <td>0.417245</td>\n",
       "      <td>-0.257691</td>\n",
       "      <td>0.060115</td>\n",
       "      <td>0.035332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>e9d16028-4b41-4753-87ee-041d33642ae9</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35483</td>\n",
       "      <td>1.286640</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>0.212182</td>\n",
       "      <td>-0.269732</td>\n",
       "      <td>-0.283961</td>\n",
       "      <td>-0.663306</td>\n",
       "      <td>-0.016385</td>\n",
       "      <td>-0.120297</td>\n",
       "      <td>-0.135962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052674</td>\n",
       "      <td>0.076792</td>\n",
       "      <td>0.209208</td>\n",
       "      <td>0.847617</td>\n",
       "      <td>-0.086559</td>\n",
       "      <td>-0.008262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8b319d3a-2b2d-445b-a9a2-0da3d664ec2a</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163935</td>\n",
       "      <td>1.961967</td>\n",
       "      <td>-0.247295</td>\n",
       "      <td>-1.751841</td>\n",
       "      <td>-0.268689</td>\n",
       "      <td>0.956431</td>\n",
       "      <td>0.707211</td>\n",
       "      <td>0.020675</td>\n",
       "      <td>0.189433</td>\n",
       "      <td>0.455055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186420</td>\n",
       "      <td>-1.621368</td>\n",
       "      <td>-0.131098</td>\n",
       "      <td>0.034276</td>\n",
       "      <td>-0.004909</td>\n",
       "      <td>-0.090859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>788afb87-60aa-4482-8b48-c924bec634aa</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30707</td>\n",
       "      <td>-0.964364</td>\n",
       "      <td>0.176372</td>\n",
       "      <td>2.464128</td>\n",
       "      <td>2.672539</td>\n",
       "      <td>0.145676</td>\n",
       "      <td>-0.152913</td>\n",
       "      <td>-0.591983</td>\n",
       "      <td>0.305066</td>\n",
       "      <td>-0.148034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024200</td>\n",
       "      <td>0.365226</td>\n",
       "      <td>-0.745369</td>\n",
       "      <td>-0.060544</td>\n",
       "      <td>0.095692</td>\n",
       "      <td>0.217639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>473d0936-1974-4ae8-ab70-230e7599bd3f</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0   32799  1.153477 -0.047859  1.358363  1.480620 -1.222598 -0.481690   \n",
       "1   35483  1.286640  0.072917  0.212182 -0.269732 -0.283961 -0.663306   \n",
       "2  163935  1.961967 -0.247295 -1.751841 -0.268689  0.956431  0.707211   \n",
       "3   30707 -0.964364  0.176372  2.464128  2.672539  0.145676 -0.152913   \n",
       "\n",
       "         V7        V8        V9  ...       V23       V24       V25       V26  \\\n",
       "0 -0.654461  0.128115  0.907095  ... -0.025964  0.701843  0.417245 -0.257691   \n",
       "1 -0.016385 -0.120297 -0.135962  ...  0.052674  0.076792  0.209208  0.847617   \n",
       "2  0.020675  0.189433  0.455055  ...  0.186420 -1.621368 -0.131098  0.034276   \n",
       "3 -0.591983  0.305066 -0.148034  ... -0.024200  0.365226 -0.745369 -0.060544   \n",
       "\n",
       "        V27       V28  Amount  Class                        transaction_id  \\\n",
       "0  0.060115  0.035332     0.0      0  e9d16028-4b41-4753-87ee-041d33642ae9   \n",
       "1 -0.086559 -0.008262     0.0      0  8b319d3a-2b2d-445b-a9a2-0da3d664ec2a   \n",
       "2 -0.004909 -0.090859     0.0      0  788afb87-60aa-4482-8b48-c924bec634aa   \n",
       "3  0.095692  0.217639     0.0      0  473d0936-1974-4ae8-ab70-230e7599bd3f   \n",
       "\n",
       "   splits  \n",
       "0    TEST  \n",
       "1    TEST  \n",
       "2    TEST  \n",
       "3    TEST  \n",
       "\n",
       "[4 rows x 33 columns]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "40711e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "newob = pred[pred.columns[~pred.columns.isin(VAR_OMIT.split()+[VAR_TARGET, 'splits'])]].to_dict(orient='records')[0]\n",
    "#newob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "5950e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [json_format.ParseDict(newob, Value())]\n",
    "parameters = json_format.ParseDict({}, Value())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b06fdf2",
   "metadata": {},
   "source": [
    "### Get Predictions: Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "5fc3b01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[[0.999751031, 0.000248962489]], deployed_model_id='1628935272643166208', model_version_id='', model_resource_name='projects/1026793852137/locations/us-central1/models/model_05a_fraud', explanations=None)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = endpoint.predict(instances=instances, parameters=parameters)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "e3f07649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.999751031, 0.000248962489]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "5f5912e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction.predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c1436",
   "metadata": {},
   "source": [
    "### Get Predictions: REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "b86b74d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DIR}/request.json','w') as file:\n",
    "    file.write(json.dumps({\"instances\": [newob]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "8a7681f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    [\n",
      "      0.999751031,\n",
      "      0.000248962489\n",
      "    ]\n",
      "  ],\n",
      "  \"deployedModelId\": \"1628935272643166208\",\n",
      "  \"model\": \"projects/1026793852137/locations/us-central1/models/model_05a_fraud\",\n",
      "  \"modelDisplayName\": \"05a_fraud\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST \\\n",
    "-H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
    "-H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "-d @{DIR}/request.json \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bfa394",
   "metadata": {},
   "source": [
    "### Get Predictions: gcloud (CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "393f535d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n",
      "[[0.999751031, 0.000248962489]]\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta ai endpoints predict {endpoint.name.rsplit('/',1)[-1]} --region={REGION} --json-request={DIR}/request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b16d8e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"99 - Cleanup\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
